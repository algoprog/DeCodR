{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackoverflowDataProcessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"\" "
      ],
      "metadata": {
        "id": "4jos_GW_ctlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0YxPfiEbuQI"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = bigquery.Client()"
      ],
      "metadata": {
        "id": "KnWYnKj8b7Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkDs5rmldESv",
        "outputId": "d0d3e47e-05a8-43f2-c05a-b06bf6734752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/maximal-centaur-120203-f1fd85adc57c.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "    SELECT Id FROM `sotorrent-org.2020_12_31.Tags`\n",
        "    WHERE TagName = \"python\"\n",
        "    LIMIT 20\n",
        "\"\"\"\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "print(\"The query data:\")\n",
        "for row in query_job:\n",
        "  print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wql5ne0b9Tt",
        "outputId": "5aca114d-3e52-4e4e-bebf-8b2dd1623afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The query data:\n",
            "Row((16,), {'Id': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QqzUQb0IVyjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a265722-abaf-4020-95a7-708303946653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tag_id(tag_name: str):\n",
        "  query = f\"\"\"\n",
        "      SELECT Id FROM `sotorrent-org.2020_12_31.Tags`\n",
        "      WHERE TagName = \"{tag_name}\"\n",
        "      LIMIT 1\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)  # Make an API request.\n",
        "\n",
        "  for row in query_job:\n",
        "    return row[0]\n",
        "\n",
        "\n",
        "def get_overlapping_tags(tag_id: int, num_tags: int = 200):\n",
        "  query = f\"\"\"\n",
        "    WITH newIds AS (\n",
        "      WITH ids AS \n",
        "      (SELECT PostId FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "      WHERE TagId = {tag_id})\n",
        "      SELECT TagId, COUNT(*) AS count FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "      JOIN ids\n",
        "        ON ids.PostId = `sotorrent-org.2020_12_31.PostTags`.PostId\n",
        "      GROUP BY TagId)\n",
        "      \n",
        "    SELECT * FROM `sotorrent-org.2020_12_31.Tags`\n",
        "    JOIN newIds\n",
        "      ON newIds.TagId = `sotorrent-org.2020_12_31.Tags`.Id\n",
        "    ORDER BY newIds.count DESC\n",
        "    LIMIT {num_tags};\n",
        "  \"\"\"\n",
        "\n",
        "  query_job = client.query(query)\n",
        "  data = []\n",
        "  for row in query_job:\n",
        "    data.append(row)\n",
        "  return data\n",
        "\n",
        "def get_post_by_id(post_id):\n",
        "  query = f\"\"\"\n",
        "    SELECT Tags FROM `sotorrent-org.2020_12_31.Posts`\n",
        "    WHERE Id = {post_id}\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  data = []\n",
        "  for row in query_job:\n",
        "    print(row)\n",
        "\n",
        "\n",
        "def download_relevant_posts(relevant_tag_ids, irrelevant_tag_ids):\n",
        "  relevant_tag_str = ' '.join([f'OR {tag} IN UNNEST(ids.arr)' for tag in relevant_tag_ids])\n",
        "  irrelevant_tag_str = ' '.join([f'AND {tag} NOT IN UNNEST(ids.arr)' for tag in irrelevant_tag_ids])\n",
        "  query = f\"\"\"\n",
        "        WITH proper_ids AS (\n",
        "          WITH ids AS (\n",
        "            SELECT PostId, ARRAY_AGG(TagId) AS arr \n",
        "            FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "            GROUP BY PostId\n",
        "          )  \n",
        "          SELECT PostId \n",
        "          FROM ids \n",
        "          WHERE (16 IN UNNEST(ids.arr) {relevant_tag_str})\n",
        "          {irrelevant_tag_str}\n",
        "        )\n",
        "\n",
        "        SELECT Id, Title, Tags, Body, AcceptedAnswerId, Score, ViewCount FROM `sotorrent-org.2020_12_31.Posts`\n",
        "        JOIN proper_ids\n",
        "          ON proper_ids.PostId = `sotorrent-org.2020_12_31.Posts`.Id\n",
        "        WHERE `sotorrent-org.2020_12_31.Posts`.PostTypeId = 1\n",
        "        ORDER BY `sotorrent-org.2020_12_31.Posts`.Score DESC\n",
        "        LIMIT 100000;\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  data = []\n",
        "  for i, row in enumerate(query_job):\n",
        "    if i % 100_000 == 0:\n",
        "      print(i)\n",
        "    data.append(list(row))\n",
        "\n",
        "  save_data('questions_small.csv', data)\n",
        "\n",
        "def create_table_relevant_questions(relevant_tag_ids, irrelevant_tag_ids):\n",
        "  relevant_tag_str = ' '.join([f'OR {tag} IN UNNEST(ids.arr)' for tag in relevant_tag_ids])\n",
        "  irrelevant_tag_str = ' '.join([f'AND {tag} NOT IN UNNEST(ids.arr)' for tag in irrelevant_tag_ids])\n",
        "  query = f\"\"\"\n",
        "        CREATE TABLE\n",
        "        maximal-centaur-120203.stack_overflow_ir.large_questions (\n",
        "          Id INTEGER, \n",
        "          Title STRING, \n",
        "          Tags STRING, \n",
        "          Body STRING, \n",
        "          AcceptedAnswerId INTEGER, \n",
        "          Score INTEGER, \n",
        "          ViewCount INTEGER\n",
        "        ) AS \n",
        "        WITH proper_ids AS (\n",
        "          WITH ids AS (\n",
        "            SELECT PostId, ARRAY_AGG(TagId) AS arr \n",
        "            FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "            GROUP BY PostId\n",
        "          )  \n",
        "          SELECT PostId \n",
        "          FROM ids \n",
        "          WHERE (16 IN UNNEST(ids.arr) {relevant_tag_str})\n",
        "          {irrelevant_tag_str}\n",
        "        )\n",
        "        SELECT Id, Title, Tags, Body, AcceptedAnswerId, Score, ViewCount FROM `sotorrent-org.2020_12_31.Posts`\n",
        "        JOIN proper_ids\n",
        "          ON proper_ids.PostId = `sotorrent-org.2020_12_31.Posts`.Id\n",
        "        WHERE `sotorrent-org.2020_12_31.Posts`.PostTypeId = 1\n",
        "        ORDER BY `sotorrent-org.2020_12_31.Posts`.Score DESC;\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  for i, row in enumerate(query_job):\n",
        "    if i % 100_000 == 0:\n",
        "      print(i)\n",
        "    print(row)\n",
        "\n",
        "\n",
        "def create_table_relevant_answers():\n",
        "  query = f\"\"\"\n",
        "        CREATE TABLE\n",
        "        maximal-centaur-120203.stack_overflow_ir.large_answers (\n",
        "          Id INTEGER, \n",
        "          QuestionId INTEGER,\n",
        "          Body STRING, \n",
        "          Score INTEGER, \n",
        "        ) AS \n",
        "        SELECT `sotorrent-org.2020_12_31.Posts`.Id, `sotorrent-org.2020_12_31.Posts`.ParentId, `sotorrent-org.2020_12_31.Posts`.Body, `sotorrent-org.2020_12_31.Posts`.Score FROM `sotorrent-org.2020_12_31.Posts`\n",
        "        JOIN `maximal-centaur-120203.stack_overflow_ir.large_questions`\n",
        "          ON `maximal-centaur-120203.stack_overflow_ir.large_questions`.Id = `sotorrent-org.2020_12_31.Posts`.ParentId\n",
        "        ORDER BY `sotorrent-org.2020_12_31.Posts`.Score DESC;\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  for i, row in enumerate(query_job):\n",
        "    if i % 100_000 == 0:\n",
        "      print(i)\n",
        "    print(row)\n",
        "\n",
        "def download_answers():\n",
        "  query = f\"\"\"\n",
        "    SELECT * FROM `maximal-centaur-120203.stack_overflow_ir.large_answers`;\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  data = []\n",
        "  for i, row in enumerate(query_job):\n",
        "    if i % 100_000 == 0:\n",
        "      print(i)\n",
        "    data.append(list(row))\n",
        "  save_data('large_answers.csv', data)\n",
        "\n",
        "\n",
        "def download_questions():\n",
        "  query = f\"\"\"\n",
        "    SELECT * FROM `maximal-centaur-120203.stack_overflow_ir.large_questions`;\n",
        "  \"\"\"\n",
        "  query_job = client.query(query)\n",
        "  data = []\n",
        "  for i, row in enumerate(query_job):\n",
        "    if i % 100_000 == 0:\n",
        "      print(i)\n",
        "    data.append(list(row))\n",
        "  save_data('large_questions.csv', data)\n",
        "\n",
        "def load_answer_ids(path):\n",
        "  ids = []\n",
        "  with open(path) as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "      ids.append(row[0])\n",
        "  return ids\n",
        "\n",
        "def save_data(filename, data):\n",
        "  with open(f'/content/drive/My Drive/CS 685/Final Project/Data/{filename}', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for i, row in enumerate(data):\n",
        "      if i % 1_000 == 0:\n",
        "        print(i, len(data))\n",
        "      writer.writerow(row)"
      ],
      "metadata": {
        "id": "enp696pgW04x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = \"{}.stack_overflow_ir\".format(client.project)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "dataset.location = \"US\"\n",
        "dataset = client.create_dataset(dataset)\n",
        "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slfb8YIFX1Xm",
        "outputId": "21ce7a19-9f47-40fe-90c1-2724160a31b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset maximal-centaur-120203.stack_overflow_ir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_answers()\n",
        "download_questions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP1ne3k1jpU0",
        "outputId": "d4270600-f996-4d5b-e956-5467cc3b95ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "1600000\n",
            "1700000\n",
            "1800000\n",
            "1900000\n",
            "2000000\n",
            "2100000\n",
            "2200000\n",
            "0 2273845\n",
            "1000 2273845\n",
            "2000 2273845\n",
            "3000 2273845\n",
            "4000 2273845\n",
            "5000 2273845\n",
            "6000 2273845\n",
            "7000 2273845\n",
            "8000 2273845\n",
            "9000 2273845\n",
            "10000 2273845\n",
            "11000 2273845\n",
            "12000 2273845\n",
            "13000 2273845\n",
            "14000 2273845\n",
            "15000 2273845\n",
            "16000 2273845\n",
            "17000 2273845\n",
            "18000 2273845\n",
            "19000 2273845\n",
            "20000 2273845\n",
            "21000 2273845\n",
            "22000 2273845\n",
            "23000 2273845\n",
            "24000 2273845\n",
            "25000 2273845\n",
            "26000 2273845\n",
            "27000 2273845\n",
            "28000 2273845\n",
            "29000 2273845\n",
            "30000 2273845\n",
            "31000 2273845\n",
            "32000 2273845\n",
            "33000 2273845\n",
            "34000 2273845\n",
            "35000 2273845\n",
            "36000 2273845\n",
            "37000 2273845\n",
            "38000 2273845\n",
            "39000 2273845\n",
            "40000 2273845\n",
            "41000 2273845\n",
            "42000 2273845\n",
            "43000 2273845\n",
            "44000 2273845\n",
            "45000 2273845\n",
            "46000 2273845\n",
            "47000 2273845\n",
            "48000 2273845\n",
            "49000 2273845\n",
            "50000 2273845\n",
            "51000 2273845\n",
            "52000 2273845\n",
            "53000 2273845\n",
            "54000 2273845\n",
            "55000 2273845\n",
            "56000 2273845\n",
            "57000 2273845\n",
            "58000 2273845\n",
            "59000 2273845\n",
            "60000 2273845\n",
            "61000 2273845\n",
            "62000 2273845\n",
            "63000 2273845\n",
            "64000 2273845\n",
            "65000 2273845\n",
            "66000 2273845\n",
            "67000 2273845\n",
            "68000 2273845\n",
            "69000 2273845\n",
            "70000 2273845\n",
            "71000 2273845\n",
            "72000 2273845\n",
            "73000 2273845\n",
            "74000 2273845\n",
            "75000 2273845\n",
            "76000 2273845\n",
            "77000 2273845\n",
            "78000 2273845\n",
            "79000 2273845\n",
            "80000 2273845\n",
            "81000 2273845\n",
            "82000 2273845\n",
            "83000 2273845\n",
            "84000 2273845\n",
            "85000 2273845\n",
            "86000 2273845\n",
            "87000 2273845\n",
            "88000 2273845\n",
            "89000 2273845\n",
            "90000 2273845\n",
            "91000 2273845\n",
            "92000 2273845\n",
            "93000 2273845\n",
            "94000 2273845\n",
            "95000 2273845\n",
            "96000 2273845\n",
            "97000 2273845\n",
            "98000 2273845\n",
            "99000 2273845\n",
            "100000 2273845\n",
            "101000 2273845\n",
            "102000 2273845\n",
            "103000 2273845\n",
            "104000 2273845\n",
            "105000 2273845\n",
            "106000 2273845\n",
            "107000 2273845\n",
            "108000 2273845\n",
            "109000 2273845\n",
            "110000 2273845\n",
            "111000 2273845\n",
            "112000 2273845\n",
            "113000 2273845\n",
            "114000 2273845\n",
            "115000 2273845\n",
            "116000 2273845\n",
            "117000 2273845\n",
            "118000 2273845\n",
            "119000 2273845\n",
            "120000 2273845\n",
            "121000 2273845\n",
            "122000 2273845\n",
            "123000 2273845\n",
            "124000 2273845\n",
            "125000 2273845\n",
            "126000 2273845\n",
            "127000 2273845\n",
            "128000 2273845\n",
            "129000 2273845\n",
            "130000 2273845\n",
            "131000 2273845\n",
            "132000 2273845\n",
            "133000 2273845\n",
            "134000 2273845\n",
            "135000 2273845\n",
            "136000 2273845\n",
            "137000 2273845\n",
            "138000 2273845\n",
            "139000 2273845\n",
            "140000 2273845\n",
            "141000 2273845\n",
            "142000 2273845\n",
            "143000 2273845\n",
            "144000 2273845\n",
            "145000 2273845\n",
            "146000 2273845\n",
            "147000 2273845\n",
            "148000 2273845\n",
            "149000 2273845\n",
            "150000 2273845\n",
            "151000 2273845\n",
            "152000 2273845\n",
            "153000 2273845\n",
            "154000 2273845\n",
            "155000 2273845\n",
            "156000 2273845\n",
            "157000 2273845\n",
            "158000 2273845\n",
            "159000 2273845\n",
            "160000 2273845\n",
            "161000 2273845\n",
            "162000 2273845\n",
            "163000 2273845\n",
            "164000 2273845\n",
            "165000 2273845\n",
            "166000 2273845\n",
            "167000 2273845\n",
            "168000 2273845\n",
            "169000 2273845\n",
            "170000 2273845\n",
            "171000 2273845\n",
            "172000 2273845\n",
            "173000 2273845\n",
            "174000 2273845\n",
            "175000 2273845\n",
            "176000 2273845\n",
            "177000 2273845\n",
            "178000 2273845\n",
            "179000 2273845\n",
            "180000 2273845\n",
            "181000 2273845\n",
            "182000 2273845\n",
            "183000 2273845\n",
            "184000 2273845\n",
            "185000 2273845\n",
            "186000 2273845\n",
            "187000 2273845\n",
            "188000 2273845\n",
            "189000 2273845\n",
            "190000 2273845\n",
            "191000 2273845\n",
            "192000 2273845\n",
            "193000 2273845\n",
            "194000 2273845\n",
            "195000 2273845\n",
            "196000 2273845\n",
            "197000 2273845\n",
            "198000 2273845\n",
            "199000 2273845\n",
            "200000 2273845\n",
            "201000 2273845\n",
            "202000 2273845\n",
            "203000 2273845\n",
            "204000 2273845\n",
            "205000 2273845\n",
            "206000 2273845\n",
            "207000 2273845\n",
            "208000 2273845\n",
            "209000 2273845\n",
            "210000 2273845\n",
            "211000 2273845\n",
            "212000 2273845\n",
            "213000 2273845\n",
            "214000 2273845\n",
            "215000 2273845\n",
            "216000 2273845\n",
            "217000 2273845\n",
            "218000 2273845\n",
            "219000 2273845\n",
            "220000 2273845\n",
            "221000 2273845\n",
            "222000 2273845\n",
            "223000 2273845\n",
            "224000 2273845\n",
            "225000 2273845\n",
            "226000 2273845\n",
            "227000 2273845\n",
            "228000 2273845\n",
            "229000 2273845\n",
            "230000 2273845\n",
            "231000 2273845\n",
            "232000 2273845\n",
            "233000 2273845\n",
            "234000 2273845\n",
            "235000 2273845\n",
            "236000 2273845\n",
            "237000 2273845\n",
            "238000 2273845\n",
            "239000 2273845\n",
            "240000 2273845\n",
            "241000 2273845\n",
            "242000 2273845\n",
            "243000 2273845\n",
            "244000 2273845\n",
            "245000 2273845\n",
            "246000 2273845\n",
            "247000 2273845\n",
            "248000 2273845\n",
            "249000 2273845\n",
            "250000 2273845\n",
            "251000 2273845\n",
            "252000 2273845\n",
            "253000 2273845\n",
            "254000 2273845\n",
            "255000 2273845\n",
            "256000 2273845\n",
            "257000 2273845\n",
            "258000 2273845\n",
            "259000 2273845\n",
            "260000 2273845\n",
            "261000 2273845\n",
            "262000 2273845\n",
            "263000 2273845\n",
            "264000 2273845\n",
            "265000 2273845\n",
            "266000 2273845\n",
            "267000 2273845\n",
            "268000 2273845\n",
            "269000 2273845\n",
            "270000 2273845\n",
            "271000 2273845\n",
            "272000 2273845\n",
            "273000 2273845\n",
            "274000 2273845\n",
            "275000 2273845\n",
            "276000 2273845\n",
            "277000 2273845\n",
            "278000 2273845\n",
            "279000 2273845\n",
            "280000 2273845\n",
            "281000 2273845\n",
            "282000 2273845\n",
            "283000 2273845\n",
            "284000 2273845\n",
            "285000 2273845\n",
            "286000 2273845\n",
            "287000 2273845\n",
            "288000 2273845\n",
            "289000 2273845\n",
            "290000 2273845\n",
            "291000 2273845\n",
            "292000 2273845\n",
            "293000 2273845\n",
            "294000 2273845\n",
            "295000 2273845\n",
            "296000 2273845\n",
            "297000 2273845\n",
            "298000 2273845\n",
            "299000 2273845\n",
            "300000 2273845\n",
            "301000 2273845\n",
            "302000 2273845\n",
            "303000 2273845\n",
            "304000 2273845\n",
            "305000 2273845\n",
            "306000 2273845\n",
            "307000 2273845\n",
            "308000 2273845\n",
            "309000 2273845\n",
            "310000 2273845\n",
            "311000 2273845\n",
            "312000 2273845\n",
            "313000 2273845\n",
            "314000 2273845\n",
            "315000 2273845\n",
            "316000 2273845\n",
            "317000 2273845\n",
            "318000 2273845\n",
            "319000 2273845\n",
            "320000 2273845\n",
            "321000 2273845\n",
            "322000 2273845\n",
            "323000 2273845\n",
            "324000 2273845\n",
            "325000 2273845\n",
            "326000 2273845\n",
            "327000 2273845\n",
            "328000 2273845\n",
            "329000 2273845\n",
            "330000 2273845\n",
            "331000 2273845\n",
            "332000 2273845\n",
            "333000 2273845\n",
            "334000 2273845\n",
            "335000 2273845\n",
            "336000 2273845\n",
            "337000 2273845\n",
            "338000 2273845\n",
            "339000 2273845\n",
            "340000 2273845\n",
            "341000 2273845\n",
            "342000 2273845\n",
            "343000 2273845\n",
            "344000 2273845\n",
            "345000 2273845\n",
            "346000 2273845\n",
            "347000 2273845\n",
            "348000 2273845\n",
            "349000 2273845\n",
            "350000 2273845\n",
            "351000 2273845\n",
            "352000 2273845\n",
            "353000 2273845\n",
            "354000 2273845\n",
            "355000 2273845\n",
            "356000 2273845\n",
            "357000 2273845\n",
            "358000 2273845\n",
            "359000 2273845\n",
            "360000 2273845\n",
            "361000 2273845\n",
            "362000 2273845\n",
            "363000 2273845\n",
            "364000 2273845\n",
            "365000 2273845\n",
            "366000 2273845\n",
            "367000 2273845\n",
            "368000 2273845\n",
            "369000 2273845\n",
            "370000 2273845\n",
            "371000 2273845\n",
            "372000 2273845\n",
            "373000 2273845\n",
            "374000 2273845\n",
            "375000 2273845\n",
            "376000 2273845\n",
            "377000 2273845\n",
            "378000 2273845\n",
            "379000 2273845\n",
            "380000 2273845\n",
            "381000 2273845\n",
            "382000 2273845\n",
            "383000 2273845\n",
            "384000 2273845\n",
            "385000 2273845\n",
            "386000 2273845\n",
            "387000 2273845\n",
            "388000 2273845\n",
            "389000 2273845\n",
            "390000 2273845\n",
            "391000 2273845\n",
            "392000 2273845\n",
            "393000 2273845\n",
            "394000 2273845\n",
            "395000 2273845\n",
            "396000 2273845\n",
            "397000 2273845\n",
            "398000 2273845\n",
            "399000 2273845\n",
            "400000 2273845\n",
            "401000 2273845\n",
            "402000 2273845\n",
            "403000 2273845\n",
            "404000 2273845\n",
            "405000 2273845\n",
            "406000 2273845\n",
            "407000 2273845\n",
            "408000 2273845\n",
            "409000 2273845\n",
            "410000 2273845\n",
            "411000 2273845\n",
            "412000 2273845\n",
            "413000 2273845\n",
            "414000 2273845\n",
            "415000 2273845\n",
            "416000 2273845\n",
            "417000 2273845\n",
            "418000 2273845\n",
            "419000 2273845\n",
            "420000 2273845\n",
            "421000 2273845\n",
            "422000 2273845\n",
            "423000 2273845\n",
            "424000 2273845\n",
            "425000 2273845\n",
            "426000 2273845\n",
            "427000 2273845\n",
            "428000 2273845\n",
            "429000 2273845\n",
            "430000 2273845\n",
            "431000 2273845\n",
            "432000 2273845\n",
            "433000 2273845\n",
            "434000 2273845\n",
            "435000 2273845\n",
            "436000 2273845\n",
            "437000 2273845\n",
            "438000 2273845\n",
            "439000 2273845\n",
            "440000 2273845\n",
            "441000 2273845\n",
            "442000 2273845\n",
            "443000 2273845\n",
            "444000 2273845\n",
            "445000 2273845\n",
            "446000 2273845\n",
            "447000 2273845\n",
            "448000 2273845\n",
            "449000 2273845\n",
            "450000 2273845\n",
            "451000 2273845\n",
            "452000 2273845\n",
            "453000 2273845\n",
            "454000 2273845\n",
            "455000 2273845\n",
            "456000 2273845\n",
            "457000 2273845\n",
            "458000 2273845\n",
            "459000 2273845\n",
            "460000 2273845\n",
            "461000 2273845\n",
            "462000 2273845\n",
            "463000 2273845\n",
            "464000 2273845\n",
            "465000 2273845\n",
            "466000 2273845\n",
            "467000 2273845\n",
            "468000 2273845\n",
            "469000 2273845\n",
            "470000 2273845\n",
            "471000 2273845\n",
            "472000 2273845\n",
            "473000 2273845\n",
            "474000 2273845\n",
            "475000 2273845\n",
            "476000 2273845\n",
            "477000 2273845\n",
            "478000 2273845\n",
            "479000 2273845\n",
            "480000 2273845\n",
            "481000 2273845\n",
            "482000 2273845\n",
            "483000 2273845\n",
            "484000 2273845\n",
            "485000 2273845\n",
            "486000 2273845\n",
            "487000 2273845\n",
            "488000 2273845\n",
            "489000 2273845\n",
            "490000 2273845\n",
            "491000 2273845\n",
            "492000 2273845\n",
            "493000 2273845\n",
            "494000 2273845\n",
            "495000 2273845\n",
            "496000 2273845\n",
            "497000 2273845\n",
            "498000 2273845\n",
            "499000 2273845\n",
            "500000 2273845\n",
            "501000 2273845\n",
            "502000 2273845\n",
            "503000 2273845\n",
            "504000 2273845\n",
            "505000 2273845\n",
            "506000 2273845\n",
            "507000 2273845\n",
            "508000 2273845\n",
            "509000 2273845\n",
            "510000 2273845\n",
            "511000 2273845\n",
            "512000 2273845\n",
            "513000 2273845\n",
            "514000 2273845\n",
            "515000 2273845\n",
            "516000 2273845\n",
            "517000 2273845\n",
            "518000 2273845\n",
            "519000 2273845\n",
            "520000 2273845\n",
            "521000 2273845\n",
            "522000 2273845\n",
            "523000 2273845\n",
            "524000 2273845\n",
            "525000 2273845\n",
            "526000 2273845\n",
            "527000 2273845\n",
            "528000 2273845\n",
            "529000 2273845\n",
            "530000 2273845\n",
            "531000 2273845\n",
            "532000 2273845\n",
            "533000 2273845\n",
            "534000 2273845\n",
            "535000 2273845\n",
            "536000 2273845\n",
            "537000 2273845\n",
            "538000 2273845\n",
            "539000 2273845\n",
            "540000 2273845\n",
            "541000 2273845\n",
            "542000 2273845\n",
            "543000 2273845\n",
            "544000 2273845\n",
            "545000 2273845\n",
            "546000 2273845\n",
            "547000 2273845\n",
            "548000 2273845\n",
            "549000 2273845\n",
            "550000 2273845\n",
            "551000 2273845\n",
            "552000 2273845\n",
            "553000 2273845\n",
            "554000 2273845\n",
            "555000 2273845\n",
            "556000 2273845\n",
            "557000 2273845\n",
            "558000 2273845\n",
            "559000 2273845\n",
            "560000 2273845\n",
            "561000 2273845\n",
            "562000 2273845\n",
            "563000 2273845\n",
            "564000 2273845\n",
            "565000 2273845\n",
            "566000 2273845\n",
            "567000 2273845\n",
            "568000 2273845\n",
            "569000 2273845\n",
            "570000 2273845\n",
            "571000 2273845\n",
            "572000 2273845\n",
            "573000 2273845\n",
            "574000 2273845\n",
            "575000 2273845\n",
            "576000 2273845\n",
            "577000 2273845\n",
            "578000 2273845\n",
            "579000 2273845\n",
            "580000 2273845\n",
            "581000 2273845\n",
            "582000 2273845\n",
            "583000 2273845\n",
            "584000 2273845\n",
            "585000 2273845\n",
            "586000 2273845\n",
            "587000 2273845\n",
            "588000 2273845\n",
            "589000 2273845\n",
            "590000 2273845\n",
            "591000 2273845\n",
            "592000 2273845\n",
            "593000 2273845\n",
            "594000 2273845\n",
            "595000 2273845\n",
            "596000 2273845\n",
            "597000 2273845\n",
            "598000 2273845\n",
            "599000 2273845\n",
            "600000 2273845\n",
            "601000 2273845\n",
            "602000 2273845\n",
            "603000 2273845\n",
            "604000 2273845\n",
            "605000 2273845\n",
            "606000 2273845\n",
            "607000 2273845\n",
            "608000 2273845\n",
            "609000 2273845\n",
            "610000 2273845\n",
            "611000 2273845\n",
            "612000 2273845\n",
            "613000 2273845\n",
            "614000 2273845\n",
            "615000 2273845\n",
            "616000 2273845\n",
            "617000 2273845\n",
            "618000 2273845\n",
            "619000 2273845\n",
            "620000 2273845\n",
            "621000 2273845\n",
            "622000 2273845\n",
            "623000 2273845\n",
            "624000 2273845\n",
            "625000 2273845\n",
            "626000 2273845\n",
            "627000 2273845\n",
            "628000 2273845\n",
            "629000 2273845\n",
            "630000 2273845\n",
            "631000 2273845\n",
            "632000 2273845\n",
            "633000 2273845\n",
            "634000 2273845\n",
            "635000 2273845\n",
            "636000 2273845\n",
            "637000 2273845\n",
            "638000 2273845\n",
            "639000 2273845\n",
            "640000 2273845\n",
            "641000 2273845\n",
            "642000 2273845\n",
            "643000 2273845\n",
            "644000 2273845\n",
            "645000 2273845\n",
            "646000 2273845\n",
            "647000 2273845\n",
            "648000 2273845\n",
            "649000 2273845\n",
            "650000 2273845\n",
            "651000 2273845\n",
            "652000 2273845\n",
            "653000 2273845\n",
            "654000 2273845\n",
            "655000 2273845\n",
            "656000 2273845\n",
            "657000 2273845\n",
            "658000 2273845\n",
            "659000 2273845\n",
            "660000 2273845\n",
            "661000 2273845\n",
            "662000 2273845\n",
            "663000 2273845\n",
            "664000 2273845\n",
            "665000 2273845\n",
            "666000 2273845\n",
            "667000 2273845\n",
            "668000 2273845\n",
            "669000 2273845\n",
            "670000 2273845\n",
            "671000 2273845\n",
            "672000 2273845\n",
            "673000 2273845\n",
            "674000 2273845\n",
            "675000 2273845\n",
            "676000 2273845\n",
            "677000 2273845\n",
            "678000 2273845\n",
            "679000 2273845\n",
            "680000 2273845\n",
            "681000 2273845\n",
            "682000 2273845\n",
            "683000 2273845\n",
            "684000 2273845\n",
            "685000 2273845\n",
            "686000 2273845\n",
            "687000 2273845\n",
            "688000 2273845\n",
            "689000 2273845\n",
            "690000 2273845\n",
            "691000 2273845\n",
            "692000 2273845\n",
            "693000 2273845\n",
            "694000 2273845\n",
            "695000 2273845\n",
            "696000 2273845\n",
            "697000 2273845\n",
            "698000 2273845\n",
            "699000 2273845\n",
            "700000 2273845\n",
            "701000 2273845\n",
            "702000 2273845\n",
            "703000 2273845\n",
            "704000 2273845\n",
            "705000 2273845\n",
            "706000 2273845\n",
            "707000 2273845\n",
            "708000 2273845\n",
            "709000 2273845\n",
            "710000 2273845\n",
            "711000 2273845\n",
            "712000 2273845\n",
            "713000 2273845\n",
            "714000 2273845\n",
            "715000 2273845\n",
            "716000 2273845\n",
            "717000 2273845\n",
            "718000 2273845\n",
            "719000 2273845\n",
            "720000 2273845\n",
            "721000 2273845\n",
            "722000 2273845\n",
            "723000 2273845\n",
            "724000 2273845\n",
            "725000 2273845\n",
            "726000 2273845\n",
            "727000 2273845\n",
            "728000 2273845\n",
            "729000 2273845\n",
            "730000 2273845\n",
            "731000 2273845\n",
            "732000 2273845\n",
            "733000 2273845\n",
            "734000 2273845\n",
            "735000 2273845\n",
            "736000 2273845\n",
            "737000 2273845\n",
            "738000 2273845\n",
            "739000 2273845\n",
            "740000 2273845\n",
            "741000 2273845\n",
            "742000 2273845\n",
            "743000 2273845\n",
            "744000 2273845\n",
            "745000 2273845\n",
            "746000 2273845\n",
            "747000 2273845\n",
            "748000 2273845\n",
            "749000 2273845\n",
            "750000 2273845\n",
            "751000 2273845\n",
            "752000 2273845\n",
            "753000 2273845\n",
            "754000 2273845\n",
            "755000 2273845\n",
            "756000 2273845\n",
            "757000 2273845\n",
            "758000 2273845\n",
            "759000 2273845\n",
            "760000 2273845\n",
            "761000 2273845\n",
            "762000 2273845\n",
            "763000 2273845\n",
            "764000 2273845\n",
            "765000 2273845\n",
            "766000 2273845\n",
            "767000 2273845\n",
            "768000 2273845\n",
            "769000 2273845\n",
            "770000 2273845\n",
            "771000 2273845\n",
            "772000 2273845\n",
            "773000 2273845\n",
            "774000 2273845\n",
            "775000 2273845\n",
            "776000 2273845\n",
            "777000 2273845\n",
            "778000 2273845\n",
            "779000 2273845\n",
            "780000 2273845\n",
            "781000 2273845\n",
            "782000 2273845\n",
            "783000 2273845\n",
            "784000 2273845\n",
            "785000 2273845\n",
            "786000 2273845\n",
            "787000 2273845\n",
            "788000 2273845\n",
            "789000 2273845\n",
            "790000 2273845\n",
            "791000 2273845\n",
            "792000 2273845\n",
            "793000 2273845\n",
            "794000 2273845\n",
            "795000 2273845\n",
            "796000 2273845\n",
            "797000 2273845\n",
            "798000 2273845\n",
            "799000 2273845\n",
            "800000 2273845\n",
            "801000 2273845\n",
            "802000 2273845\n",
            "803000 2273845\n",
            "804000 2273845\n",
            "805000 2273845\n",
            "806000 2273845\n",
            "807000 2273845\n",
            "808000 2273845\n",
            "809000 2273845\n",
            "810000 2273845\n",
            "811000 2273845\n",
            "812000 2273845\n",
            "813000 2273845\n",
            "814000 2273845\n",
            "815000 2273845\n",
            "816000 2273845\n",
            "817000 2273845\n",
            "818000 2273845\n",
            "819000 2273845\n",
            "820000 2273845\n",
            "821000 2273845\n",
            "822000 2273845\n",
            "823000 2273845\n",
            "824000 2273845\n",
            "825000 2273845\n",
            "826000 2273845\n",
            "827000 2273845\n",
            "828000 2273845\n",
            "829000 2273845\n",
            "830000 2273845\n",
            "831000 2273845\n",
            "832000 2273845\n",
            "833000 2273845\n",
            "834000 2273845\n",
            "835000 2273845\n",
            "836000 2273845\n",
            "837000 2273845\n",
            "838000 2273845\n",
            "839000 2273845\n",
            "840000 2273845\n",
            "841000 2273845\n",
            "842000 2273845\n",
            "843000 2273845\n",
            "844000 2273845\n",
            "845000 2273845\n",
            "846000 2273845\n",
            "847000 2273845\n",
            "848000 2273845\n",
            "849000 2273845\n",
            "850000 2273845\n",
            "851000 2273845\n",
            "852000 2273845\n",
            "853000 2273845\n",
            "854000 2273845\n",
            "855000 2273845\n",
            "856000 2273845\n",
            "857000 2273845\n",
            "858000 2273845\n",
            "859000 2273845\n",
            "860000 2273845\n",
            "861000 2273845\n",
            "862000 2273845\n",
            "863000 2273845\n",
            "864000 2273845\n",
            "865000 2273845\n",
            "866000 2273845\n",
            "867000 2273845\n",
            "868000 2273845\n",
            "869000 2273845\n",
            "870000 2273845\n",
            "871000 2273845\n",
            "872000 2273845\n",
            "873000 2273845\n",
            "874000 2273845\n",
            "875000 2273845\n",
            "876000 2273845\n",
            "877000 2273845\n",
            "878000 2273845\n",
            "879000 2273845\n",
            "880000 2273845\n",
            "881000 2273845\n",
            "882000 2273845\n",
            "883000 2273845\n",
            "884000 2273845\n",
            "885000 2273845\n",
            "886000 2273845\n",
            "887000 2273845\n",
            "888000 2273845\n",
            "889000 2273845\n",
            "890000 2273845\n",
            "891000 2273845\n",
            "892000 2273845\n",
            "893000 2273845\n",
            "894000 2273845\n",
            "895000 2273845\n",
            "896000 2273845\n",
            "897000 2273845\n",
            "898000 2273845\n",
            "899000 2273845\n",
            "900000 2273845\n",
            "901000 2273845\n",
            "902000 2273845\n",
            "903000 2273845\n",
            "904000 2273845\n",
            "905000 2273845\n",
            "906000 2273845\n",
            "907000 2273845\n",
            "908000 2273845\n",
            "909000 2273845\n",
            "910000 2273845\n",
            "911000 2273845\n",
            "912000 2273845\n",
            "913000 2273845\n",
            "914000 2273845\n",
            "915000 2273845\n",
            "916000 2273845\n",
            "917000 2273845\n",
            "918000 2273845\n",
            "919000 2273845\n",
            "920000 2273845\n",
            "921000 2273845\n",
            "922000 2273845\n",
            "923000 2273845\n",
            "924000 2273845\n",
            "925000 2273845\n",
            "926000 2273845\n",
            "927000 2273845\n",
            "928000 2273845\n",
            "929000 2273845\n",
            "930000 2273845\n",
            "931000 2273845\n",
            "932000 2273845\n",
            "933000 2273845\n",
            "934000 2273845\n",
            "935000 2273845\n",
            "936000 2273845\n",
            "937000 2273845\n",
            "938000 2273845\n",
            "939000 2273845\n",
            "940000 2273845\n",
            "941000 2273845\n",
            "942000 2273845\n",
            "943000 2273845\n",
            "944000 2273845\n",
            "945000 2273845\n",
            "946000 2273845\n",
            "947000 2273845\n",
            "948000 2273845\n",
            "949000 2273845\n",
            "950000 2273845\n",
            "951000 2273845\n",
            "952000 2273845\n",
            "953000 2273845\n",
            "954000 2273845\n",
            "955000 2273845\n",
            "956000 2273845\n",
            "957000 2273845\n",
            "958000 2273845\n",
            "959000 2273845\n",
            "960000 2273845\n",
            "961000 2273845\n",
            "962000 2273845\n",
            "963000 2273845\n",
            "964000 2273845\n",
            "965000 2273845\n",
            "966000 2273845\n",
            "967000 2273845\n",
            "968000 2273845\n",
            "969000 2273845\n",
            "970000 2273845\n",
            "971000 2273845\n",
            "972000 2273845\n",
            "973000 2273845\n",
            "974000 2273845\n",
            "975000 2273845\n",
            "976000 2273845\n",
            "977000 2273845\n",
            "978000 2273845\n",
            "979000 2273845\n",
            "980000 2273845\n",
            "981000 2273845\n",
            "982000 2273845\n",
            "983000 2273845\n",
            "984000 2273845\n",
            "985000 2273845\n",
            "986000 2273845\n",
            "987000 2273845\n",
            "988000 2273845\n",
            "989000 2273845\n",
            "990000 2273845\n",
            "991000 2273845\n",
            "992000 2273845\n",
            "993000 2273845\n",
            "994000 2273845\n",
            "995000 2273845\n",
            "996000 2273845\n",
            "997000 2273845\n",
            "998000 2273845\n",
            "999000 2273845\n",
            "1000000 2273845\n",
            "1001000 2273845\n",
            "1002000 2273845\n",
            "1003000 2273845\n",
            "1004000 2273845\n",
            "1005000 2273845\n",
            "1006000 2273845\n",
            "1007000 2273845\n",
            "1008000 2273845\n",
            "1009000 2273845\n",
            "1010000 2273845\n",
            "1011000 2273845\n",
            "1012000 2273845\n",
            "1013000 2273845\n",
            "1014000 2273845\n",
            "1015000 2273845\n",
            "1016000 2273845\n",
            "1017000 2273845\n",
            "1018000 2273845\n",
            "1019000 2273845\n",
            "1020000 2273845\n",
            "1021000 2273845\n",
            "1022000 2273845\n",
            "1023000 2273845\n",
            "1024000 2273845\n",
            "1025000 2273845\n",
            "1026000 2273845\n",
            "1027000 2273845\n",
            "1028000 2273845\n",
            "1029000 2273845\n",
            "1030000 2273845\n",
            "1031000 2273845\n",
            "1032000 2273845\n",
            "1033000 2273845\n",
            "1034000 2273845\n",
            "1035000 2273845\n",
            "1036000 2273845\n",
            "1037000 2273845\n",
            "1038000 2273845\n",
            "1039000 2273845\n",
            "1040000 2273845\n",
            "1041000 2273845\n",
            "1042000 2273845\n",
            "1043000 2273845\n",
            "1044000 2273845\n",
            "1045000 2273845\n",
            "1046000 2273845\n",
            "1047000 2273845\n",
            "1048000 2273845\n",
            "1049000 2273845\n",
            "1050000 2273845\n",
            "1051000 2273845\n",
            "1052000 2273845\n",
            "1053000 2273845\n",
            "1054000 2273845\n",
            "1055000 2273845\n",
            "1056000 2273845\n",
            "1057000 2273845\n",
            "1058000 2273845\n",
            "1059000 2273845\n",
            "1060000 2273845\n",
            "1061000 2273845\n",
            "1062000 2273845\n",
            "1063000 2273845\n",
            "1064000 2273845\n",
            "1065000 2273845\n",
            "1066000 2273845\n",
            "1067000 2273845\n",
            "1068000 2273845\n",
            "1069000 2273845\n",
            "1070000 2273845\n",
            "1071000 2273845\n",
            "1072000 2273845\n",
            "1073000 2273845\n",
            "1074000 2273845\n",
            "1075000 2273845\n",
            "1076000 2273845\n",
            "1077000 2273845\n",
            "1078000 2273845\n",
            "1079000 2273845\n",
            "1080000 2273845\n",
            "1081000 2273845\n",
            "1082000 2273845\n",
            "1083000 2273845\n",
            "1084000 2273845\n",
            "1085000 2273845\n",
            "1086000 2273845\n",
            "1087000 2273845\n",
            "1088000 2273845\n",
            "1089000 2273845\n",
            "1090000 2273845\n",
            "1091000 2273845\n",
            "1092000 2273845\n",
            "1093000 2273845\n",
            "1094000 2273845\n",
            "1095000 2273845\n",
            "1096000 2273845\n",
            "1097000 2273845\n",
            "1098000 2273845\n",
            "1099000 2273845\n",
            "1100000 2273845\n",
            "1101000 2273845\n",
            "1102000 2273845\n",
            "1103000 2273845\n",
            "1104000 2273845\n",
            "1105000 2273845\n",
            "1106000 2273845\n",
            "1107000 2273845\n",
            "1108000 2273845\n",
            "1109000 2273845\n",
            "1110000 2273845\n",
            "1111000 2273845\n",
            "1112000 2273845\n",
            "1113000 2273845\n",
            "1114000 2273845\n",
            "1115000 2273845\n",
            "1116000 2273845\n",
            "1117000 2273845\n",
            "1118000 2273845\n",
            "1119000 2273845\n",
            "1120000 2273845\n",
            "1121000 2273845\n",
            "1122000 2273845\n",
            "1123000 2273845\n",
            "1124000 2273845\n",
            "1125000 2273845\n",
            "1126000 2273845\n",
            "1127000 2273845\n",
            "1128000 2273845\n",
            "1129000 2273845\n",
            "1130000 2273845\n",
            "1131000 2273845\n",
            "1132000 2273845\n",
            "1133000 2273845\n",
            "1134000 2273845\n",
            "1135000 2273845\n",
            "1136000 2273845\n",
            "1137000 2273845\n",
            "1138000 2273845\n",
            "1139000 2273845\n",
            "1140000 2273845\n",
            "1141000 2273845\n",
            "1142000 2273845\n",
            "1143000 2273845\n",
            "1144000 2273845\n",
            "1145000 2273845\n",
            "1146000 2273845\n",
            "1147000 2273845\n",
            "1148000 2273845\n",
            "1149000 2273845\n",
            "1150000 2273845\n",
            "1151000 2273845\n",
            "1152000 2273845\n",
            "1153000 2273845\n",
            "1154000 2273845\n",
            "1155000 2273845\n",
            "1156000 2273845\n",
            "1157000 2273845\n",
            "1158000 2273845\n",
            "1159000 2273845\n",
            "1160000 2273845\n",
            "1161000 2273845\n",
            "1162000 2273845\n",
            "1163000 2273845\n",
            "1164000 2273845\n",
            "1165000 2273845\n",
            "1166000 2273845\n",
            "1167000 2273845\n",
            "1168000 2273845\n",
            "1169000 2273845\n",
            "1170000 2273845\n",
            "1171000 2273845\n",
            "1172000 2273845\n",
            "1173000 2273845\n",
            "1174000 2273845\n",
            "1175000 2273845\n",
            "1176000 2273845\n",
            "1177000 2273845\n",
            "1178000 2273845\n",
            "1179000 2273845\n",
            "1180000 2273845\n",
            "1181000 2273845\n",
            "1182000 2273845\n",
            "1183000 2273845\n",
            "1184000 2273845\n",
            "1185000 2273845\n",
            "1186000 2273845\n",
            "1187000 2273845\n",
            "1188000 2273845\n",
            "1189000 2273845\n",
            "1190000 2273845\n",
            "1191000 2273845\n",
            "1192000 2273845\n",
            "1193000 2273845\n",
            "1194000 2273845\n",
            "1195000 2273845\n",
            "1196000 2273845\n",
            "1197000 2273845\n",
            "1198000 2273845\n",
            "1199000 2273845\n",
            "1200000 2273845\n",
            "1201000 2273845\n",
            "1202000 2273845\n",
            "1203000 2273845\n",
            "1204000 2273845\n",
            "1205000 2273845\n",
            "1206000 2273845\n",
            "1207000 2273845\n",
            "1208000 2273845\n",
            "1209000 2273845\n",
            "1210000 2273845\n",
            "1211000 2273845\n",
            "1212000 2273845\n",
            "1213000 2273845\n",
            "1214000 2273845\n",
            "1215000 2273845\n",
            "1216000 2273845\n",
            "1217000 2273845\n",
            "1218000 2273845\n",
            "1219000 2273845\n",
            "1220000 2273845\n",
            "1221000 2273845\n",
            "1222000 2273845\n",
            "1223000 2273845\n",
            "1224000 2273845\n",
            "1225000 2273845\n",
            "1226000 2273845\n",
            "1227000 2273845\n",
            "1228000 2273845\n",
            "1229000 2273845\n",
            "1230000 2273845\n",
            "1231000 2273845\n",
            "1232000 2273845\n",
            "1233000 2273845\n",
            "1234000 2273845\n",
            "1235000 2273845\n",
            "1236000 2273845\n",
            "1237000 2273845\n",
            "1238000 2273845\n",
            "1239000 2273845\n",
            "1240000 2273845\n",
            "1241000 2273845\n",
            "1242000 2273845\n",
            "1243000 2273845\n",
            "1244000 2273845\n",
            "1245000 2273845\n",
            "1246000 2273845\n",
            "1247000 2273845\n",
            "1248000 2273845\n",
            "1249000 2273845\n",
            "1250000 2273845\n",
            "1251000 2273845\n",
            "1252000 2273845\n",
            "1253000 2273845\n",
            "1254000 2273845\n",
            "1255000 2273845\n",
            "1256000 2273845\n",
            "1257000 2273845\n",
            "1258000 2273845\n",
            "1259000 2273845\n",
            "1260000 2273845\n",
            "1261000 2273845\n",
            "1262000 2273845\n",
            "1263000 2273845\n",
            "1264000 2273845\n",
            "1265000 2273845\n",
            "1266000 2273845\n",
            "1267000 2273845\n",
            "1268000 2273845\n",
            "1269000 2273845\n",
            "1270000 2273845\n",
            "1271000 2273845\n",
            "1272000 2273845\n",
            "1273000 2273845\n",
            "1274000 2273845\n",
            "1275000 2273845\n",
            "1276000 2273845\n",
            "1277000 2273845\n",
            "1278000 2273845\n",
            "1279000 2273845\n",
            "1280000 2273845\n",
            "1281000 2273845\n",
            "1282000 2273845\n",
            "1283000 2273845\n",
            "1284000 2273845\n",
            "1285000 2273845\n",
            "1286000 2273845\n",
            "1287000 2273845\n",
            "1288000 2273845\n",
            "1289000 2273845\n",
            "1290000 2273845\n",
            "1291000 2273845\n",
            "1292000 2273845\n",
            "1293000 2273845\n",
            "1294000 2273845\n",
            "1295000 2273845\n",
            "1296000 2273845\n",
            "1297000 2273845\n",
            "1298000 2273845\n",
            "1299000 2273845\n",
            "1300000 2273845\n",
            "1301000 2273845\n",
            "1302000 2273845\n",
            "1303000 2273845\n",
            "1304000 2273845\n",
            "1305000 2273845\n",
            "1306000 2273845\n",
            "1307000 2273845\n",
            "1308000 2273845\n",
            "1309000 2273845\n",
            "1310000 2273845\n",
            "1311000 2273845\n",
            "1312000 2273845\n",
            "1313000 2273845\n",
            "1314000 2273845\n",
            "1315000 2273845\n",
            "1316000 2273845\n",
            "1317000 2273845\n",
            "1318000 2273845\n",
            "1319000 2273845\n",
            "1320000 2273845\n",
            "1321000 2273845\n",
            "1322000 2273845\n",
            "1323000 2273845\n",
            "1324000 2273845\n",
            "1325000 2273845\n",
            "1326000 2273845\n",
            "1327000 2273845\n",
            "1328000 2273845\n",
            "1329000 2273845\n",
            "1330000 2273845\n",
            "1331000 2273845\n",
            "1332000 2273845\n",
            "1333000 2273845\n",
            "1334000 2273845\n",
            "1335000 2273845\n",
            "1336000 2273845\n",
            "1337000 2273845\n",
            "1338000 2273845\n",
            "1339000 2273845\n",
            "1340000 2273845\n",
            "1341000 2273845\n",
            "1342000 2273845\n",
            "1343000 2273845\n",
            "1344000 2273845\n",
            "1345000 2273845\n",
            "1346000 2273845\n",
            "1347000 2273845\n",
            "1348000 2273845\n",
            "1349000 2273845\n",
            "1350000 2273845\n",
            "1351000 2273845\n",
            "1352000 2273845\n",
            "1353000 2273845\n",
            "1354000 2273845\n",
            "1355000 2273845\n",
            "1356000 2273845\n",
            "1357000 2273845\n",
            "1358000 2273845\n",
            "1359000 2273845\n",
            "1360000 2273845\n",
            "1361000 2273845\n",
            "1362000 2273845\n",
            "1363000 2273845\n",
            "1364000 2273845\n",
            "1365000 2273845\n",
            "1366000 2273845\n",
            "1367000 2273845\n",
            "1368000 2273845\n",
            "1369000 2273845\n",
            "1370000 2273845\n",
            "1371000 2273845\n",
            "1372000 2273845\n",
            "1373000 2273845\n",
            "1374000 2273845\n",
            "1375000 2273845\n",
            "1376000 2273845\n",
            "1377000 2273845\n",
            "1378000 2273845\n",
            "1379000 2273845\n",
            "1380000 2273845\n",
            "1381000 2273845\n",
            "1382000 2273845\n",
            "1383000 2273845\n",
            "1384000 2273845\n",
            "1385000 2273845\n",
            "1386000 2273845\n",
            "1387000 2273845\n",
            "1388000 2273845\n",
            "1389000 2273845\n",
            "1390000 2273845\n",
            "1391000 2273845\n",
            "1392000 2273845\n",
            "1393000 2273845\n",
            "1394000 2273845\n",
            "1395000 2273845\n",
            "1396000 2273845\n",
            "1397000 2273845\n",
            "1398000 2273845\n",
            "1399000 2273845\n",
            "1400000 2273845\n",
            "1401000 2273845\n",
            "1402000 2273845\n",
            "1403000 2273845\n",
            "1404000 2273845\n",
            "1405000 2273845\n",
            "1406000 2273845\n",
            "1407000 2273845\n",
            "1408000 2273845\n",
            "1409000 2273845\n",
            "1410000 2273845\n",
            "1411000 2273845\n",
            "1412000 2273845\n",
            "1413000 2273845\n",
            "1414000 2273845\n",
            "1415000 2273845\n",
            "1416000 2273845\n",
            "1417000 2273845\n",
            "1418000 2273845\n",
            "1419000 2273845\n",
            "1420000 2273845\n",
            "1421000 2273845\n",
            "1422000 2273845\n",
            "1423000 2273845\n",
            "1424000 2273845\n",
            "1425000 2273845\n",
            "1426000 2273845\n",
            "1427000 2273845\n",
            "1428000 2273845\n",
            "1429000 2273845\n",
            "1430000 2273845\n",
            "1431000 2273845\n",
            "1432000 2273845\n",
            "1433000 2273845\n",
            "1434000 2273845\n",
            "1435000 2273845\n",
            "1436000 2273845\n",
            "1437000 2273845\n",
            "1438000 2273845\n",
            "1439000 2273845\n",
            "1440000 2273845\n",
            "1441000 2273845\n",
            "1442000 2273845\n",
            "1443000 2273845\n",
            "1444000 2273845\n",
            "1445000 2273845\n",
            "1446000 2273845\n",
            "1447000 2273845\n",
            "1448000 2273845\n",
            "1449000 2273845\n",
            "1450000 2273845\n",
            "1451000 2273845\n",
            "1452000 2273845\n",
            "1453000 2273845\n",
            "1454000 2273845\n",
            "1455000 2273845\n",
            "1456000 2273845\n",
            "1457000 2273845\n",
            "1458000 2273845\n",
            "1459000 2273845\n",
            "1460000 2273845\n",
            "1461000 2273845\n",
            "1462000 2273845\n",
            "1463000 2273845\n",
            "1464000 2273845\n",
            "1465000 2273845\n",
            "1466000 2273845\n",
            "1467000 2273845\n",
            "1468000 2273845\n",
            "1469000 2273845\n",
            "1470000 2273845\n",
            "1471000 2273845\n",
            "1472000 2273845\n",
            "1473000 2273845\n",
            "1474000 2273845\n",
            "1475000 2273845\n",
            "1476000 2273845\n",
            "1477000 2273845\n",
            "1478000 2273845\n",
            "1479000 2273845\n",
            "1480000 2273845\n",
            "1481000 2273845\n",
            "1482000 2273845\n",
            "1483000 2273845\n",
            "1484000 2273845\n",
            "1485000 2273845\n",
            "1486000 2273845\n",
            "1487000 2273845\n",
            "1488000 2273845\n",
            "1489000 2273845\n",
            "1490000 2273845\n",
            "1491000 2273845\n",
            "1492000 2273845\n",
            "1493000 2273845\n",
            "1494000 2273845\n",
            "1495000 2273845\n",
            "1496000 2273845\n",
            "1497000 2273845\n",
            "1498000 2273845\n",
            "1499000 2273845\n",
            "1500000 2273845\n",
            "1501000 2273845\n",
            "1502000 2273845\n",
            "1503000 2273845\n",
            "1504000 2273845\n",
            "1505000 2273845\n",
            "1506000 2273845\n",
            "1507000 2273845\n",
            "1508000 2273845\n",
            "1509000 2273845\n",
            "1510000 2273845\n",
            "1511000 2273845\n",
            "1512000 2273845\n",
            "1513000 2273845\n",
            "1514000 2273845\n",
            "1515000 2273845\n",
            "1516000 2273845\n",
            "1517000 2273845\n",
            "1518000 2273845\n",
            "1519000 2273845\n",
            "1520000 2273845\n",
            "1521000 2273845\n",
            "1522000 2273845\n",
            "1523000 2273845\n",
            "1524000 2273845\n",
            "1525000 2273845\n",
            "1526000 2273845\n",
            "1527000 2273845\n",
            "1528000 2273845\n",
            "1529000 2273845\n",
            "1530000 2273845\n",
            "1531000 2273845\n",
            "1532000 2273845\n",
            "1533000 2273845\n",
            "1534000 2273845\n",
            "1535000 2273845\n",
            "1536000 2273845\n",
            "1537000 2273845\n",
            "1538000 2273845\n",
            "1539000 2273845\n",
            "1540000 2273845\n",
            "1541000 2273845\n",
            "1542000 2273845\n",
            "1543000 2273845\n",
            "1544000 2273845\n",
            "1545000 2273845\n",
            "1546000 2273845\n",
            "1547000 2273845\n",
            "1548000 2273845\n",
            "1549000 2273845\n",
            "1550000 2273845\n",
            "1551000 2273845\n",
            "1552000 2273845\n",
            "1553000 2273845\n",
            "1554000 2273845\n",
            "1555000 2273845\n",
            "1556000 2273845\n",
            "1557000 2273845\n",
            "1558000 2273845\n",
            "1559000 2273845\n",
            "1560000 2273845\n",
            "1561000 2273845\n",
            "1562000 2273845\n",
            "1563000 2273845\n",
            "1564000 2273845\n",
            "1565000 2273845\n",
            "1566000 2273845\n",
            "1567000 2273845\n",
            "1568000 2273845\n",
            "1569000 2273845\n",
            "1570000 2273845\n",
            "1571000 2273845\n",
            "1572000 2273845\n",
            "1573000 2273845\n",
            "1574000 2273845\n",
            "1575000 2273845\n",
            "1576000 2273845\n",
            "1577000 2273845\n",
            "1578000 2273845\n",
            "1579000 2273845\n",
            "1580000 2273845\n",
            "1581000 2273845\n",
            "1582000 2273845\n",
            "1583000 2273845\n",
            "1584000 2273845\n",
            "1585000 2273845\n",
            "1586000 2273845\n",
            "1587000 2273845\n",
            "1588000 2273845\n",
            "1589000 2273845\n",
            "1590000 2273845\n",
            "1591000 2273845\n",
            "1592000 2273845\n",
            "1593000 2273845\n",
            "1594000 2273845\n",
            "1595000 2273845\n",
            "1596000 2273845\n",
            "1597000 2273845\n",
            "1598000 2273845\n",
            "1599000 2273845\n",
            "1600000 2273845\n",
            "1601000 2273845\n",
            "1602000 2273845\n",
            "1603000 2273845\n",
            "1604000 2273845\n",
            "1605000 2273845\n",
            "1606000 2273845\n",
            "1607000 2273845\n",
            "1608000 2273845\n",
            "1609000 2273845\n",
            "1610000 2273845\n",
            "1611000 2273845\n",
            "1612000 2273845\n",
            "1613000 2273845\n",
            "1614000 2273845\n",
            "1615000 2273845\n",
            "1616000 2273845\n",
            "1617000 2273845\n",
            "1618000 2273845\n",
            "1619000 2273845\n",
            "1620000 2273845\n",
            "1621000 2273845\n",
            "1622000 2273845\n",
            "1623000 2273845\n",
            "1624000 2273845\n",
            "1625000 2273845\n",
            "1626000 2273845\n",
            "1627000 2273845\n",
            "1628000 2273845\n",
            "1629000 2273845\n",
            "1630000 2273845\n",
            "1631000 2273845\n",
            "1632000 2273845\n",
            "1633000 2273845\n",
            "1634000 2273845\n",
            "1635000 2273845\n",
            "1636000 2273845\n",
            "1637000 2273845\n",
            "1638000 2273845\n",
            "1639000 2273845\n",
            "1640000 2273845\n",
            "1641000 2273845\n",
            "1642000 2273845\n",
            "1643000 2273845\n",
            "1644000 2273845\n",
            "1645000 2273845\n",
            "1646000 2273845\n",
            "1647000 2273845\n",
            "1648000 2273845\n",
            "1649000 2273845\n",
            "1650000 2273845\n",
            "1651000 2273845\n",
            "1652000 2273845\n",
            "1653000 2273845\n",
            "1654000 2273845\n",
            "1655000 2273845\n",
            "1656000 2273845\n",
            "1657000 2273845\n",
            "1658000 2273845\n",
            "1659000 2273845\n",
            "1660000 2273845\n",
            "1661000 2273845\n",
            "1662000 2273845\n",
            "1663000 2273845\n",
            "1664000 2273845\n",
            "1665000 2273845\n",
            "1666000 2273845\n",
            "1667000 2273845\n",
            "1668000 2273845\n",
            "1669000 2273845\n",
            "1670000 2273845\n",
            "1671000 2273845\n",
            "1672000 2273845\n",
            "1673000 2273845\n",
            "1674000 2273845\n",
            "1675000 2273845\n",
            "1676000 2273845\n",
            "1677000 2273845\n",
            "1678000 2273845\n",
            "1679000 2273845\n",
            "1680000 2273845\n",
            "1681000 2273845\n",
            "1682000 2273845\n",
            "1683000 2273845\n",
            "1684000 2273845\n",
            "1685000 2273845\n",
            "1686000 2273845\n",
            "1687000 2273845\n",
            "1688000 2273845\n",
            "1689000 2273845\n",
            "1690000 2273845\n",
            "1691000 2273845\n",
            "1692000 2273845\n",
            "1693000 2273845\n",
            "1694000 2273845\n",
            "1695000 2273845\n",
            "1696000 2273845\n",
            "1697000 2273845\n",
            "1698000 2273845\n",
            "1699000 2273845\n",
            "1700000 2273845\n",
            "1701000 2273845\n",
            "1702000 2273845\n",
            "1703000 2273845\n",
            "1704000 2273845\n",
            "1705000 2273845\n",
            "1706000 2273845\n",
            "1707000 2273845\n",
            "1708000 2273845\n",
            "1709000 2273845\n",
            "1710000 2273845\n",
            "1711000 2273845\n",
            "1712000 2273845\n",
            "1713000 2273845\n",
            "1714000 2273845\n",
            "1715000 2273845\n",
            "1716000 2273845\n",
            "1717000 2273845\n",
            "1718000 2273845\n",
            "1719000 2273845\n",
            "1720000 2273845\n",
            "1721000 2273845\n",
            "1722000 2273845\n",
            "1723000 2273845\n",
            "1724000 2273845\n",
            "1725000 2273845\n",
            "1726000 2273845\n",
            "1727000 2273845\n",
            "1728000 2273845\n",
            "1729000 2273845\n",
            "1730000 2273845\n",
            "1731000 2273845\n",
            "1732000 2273845\n",
            "1733000 2273845\n",
            "1734000 2273845\n",
            "1735000 2273845\n",
            "1736000 2273845\n",
            "1737000 2273845\n",
            "1738000 2273845\n",
            "1739000 2273845\n",
            "1740000 2273845\n",
            "1741000 2273845\n",
            "1742000 2273845\n",
            "1743000 2273845\n",
            "1744000 2273845\n",
            "1745000 2273845\n",
            "1746000 2273845\n",
            "1747000 2273845\n",
            "1748000 2273845\n",
            "1749000 2273845\n",
            "1750000 2273845\n",
            "1751000 2273845\n",
            "1752000 2273845\n",
            "1753000 2273845\n",
            "1754000 2273845\n",
            "1755000 2273845\n",
            "1756000 2273845\n",
            "1757000 2273845\n",
            "1758000 2273845\n",
            "1759000 2273845\n",
            "1760000 2273845\n",
            "1761000 2273845\n",
            "1762000 2273845\n",
            "1763000 2273845\n",
            "1764000 2273845\n",
            "1765000 2273845\n",
            "1766000 2273845\n",
            "1767000 2273845\n",
            "1768000 2273845\n",
            "1769000 2273845\n",
            "1770000 2273845\n",
            "1771000 2273845\n",
            "1772000 2273845\n",
            "1773000 2273845\n",
            "1774000 2273845\n",
            "1775000 2273845\n",
            "1776000 2273845\n",
            "1777000 2273845\n",
            "1778000 2273845\n",
            "1779000 2273845\n",
            "1780000 2273845\n",
            "1781000 2273845\n",
            "1782000 2273845\n",
            "1783000 2273845\n",
            "1784000 2273845\n",
            "1785000 2273845\n",
            "1786000 2273845\n",
            "1787000 2273845\n",
            "1788000 2273845\n",
            "1789000 2273845\n",
            "1790000 2273845\n",
            "1791000 2273845\n",
            "1792000 2273845\n",
            "1793000 2273845\n",
            "1794000 2273845\n",
            "1795000 2273845\n",
            "1796000 2273845\n",
            "1797000 2273845\n",
            "1798000 2273845\n",
            "1799000 2273845\n",
            "1800000 2273845\n",
            "1801000 2273845\n",
            "1802000 2273845\n",
            "1803000 2273845\n",
            "1804000 2273845\n",
            "1805000 2273845\n",
            "1806000 2273845\n",
            "1807000 2273845\n",
            "1808000 2273845\n",
            "1809000 2273845\n",
            "1810000 2273845\n",
            "1811000 2273845\n",
            "1812000 2273845\n",
            "1813000 2273845\n",
            "1814000 2273845\n",
            "1815000 2273845\n",
            "1816000 2273845\n",
            "1817000 2273845\n",
            "1818000 2273845\n",
            "1819000 2273845\n",
            "1820000 2273845\n",
            "1821000 2273845\n",
            "1822000 2273845\n",
            "1823000 2273845\n",
            "1824000 2273845\n",
            "1825000 2273845\n",
            "1826000 2273845\n",
            "1827000 2273845\n",
            "1828000 2273845\n",
            "1829000 2273845\n",
            "1830000 2273845\n",
            "1831000 2273845\n",
            "1832000 2273845\n",
            "1833000 2273845\n",
            "1834000 2273845\n",
            "1835000 2273845\n",
            "1836000 2273845\n",
            "1837000 2273845\n",
            "1838000 2273845\n",
            "1839000 2273845\n",
            "1840000 2273845\n",
            "1841000 2273845\n",
            "1842000 2273845\n",
            "1843000 2273845\n",
            "1844000 2273845\n",
            "1845000 2273845\n",
            "1846000 2273845\n",
            "1847000 2273845\n",
            "1848000 2273845\n",
            "1849000 2273845\n",
            "1850000 2273845\n",
            "1851000 2273845\n",
            "1852000 2273845\n",
            "1853000 2273845\n",
            "1854000 2273845\n",
            "1855000 2273845\n",
            "1856000 2273845\n",
            "1857000 2273845\n",
            "1858000 2273845\n",
            "1859000 2273845\n",
            "1860000 2273845\n",
            "1861000 2273845\n",
            "1862000 2273845\n",
            "1863000 2273845\n",
            "1864000 2273845\n",
            "1865000 2273845\n",
            "1866000 2273845\n",
            "1867000 2273845\n",
            "1868000 2273845\n",
            "1869000 2273845\n",
            "1870000 2273845\n",
            "1871000 2273845\n",
            "1872000 2273845\n",
            "1873000 2273845\n",
            "1874000 2273845\n",
            "1875000 2273845\n",
            "1876000 2273845\n",
            "1877000 2273845\n",
            "1878000 2273845\n",
            "1879000 2273845\n",
            "1880000 2273845\n",
            "1881000 2273845\n",
            "1882000 2273845\n",
            "1883000 2273845\n",
            "1884000 2273845\n",
            "1885000 2273845\n",
            "1886000 2273845\n",
            "1887000 2273845\n",
            "1888000 2273845\n",
            "1889000 2273845\n",
            "1890000 2273845\n",
            "1891000 2273845\n",
            "1892000 2273845\n",
            "1893000 2273845\n",
            "1894000 2273845\n",
            "1895000 2273845\n",
            "1896000 2273845\n",
            "1897000 2273845\n",
            "1898000 2273845\n",
            "1899000 2273845\n",
            "1900000 2273845\n",
            "1901000 2273845\n",
            "1902000 2273845\n",
            "1903000 2273845\n",
            "1904000 2273845\n",
            "1905000 2273845\n",
            "1906000 2273845\n",
            "1907000 2273845\n",
            "1908000 2273845\n",
            "1909000 2273845\n",
            "1910000 2273845\n",
            "1911000 2273845\n",
            "1912000 2273845\n",
            "1913000 2273845\n",
            "1914000 2273845\n",
            "1915000 2273845\n",
            "1916000 2273845\n",
            "1917000 2273845\n",
            "1918000 2273845\n",
            "1919000 2273845\n",
            "1920000 2273845\n",
            "1921000 2273845\n",
            "1922000 2273845\n",
            "1923000 2273845\n",
            "1924000 2273845\n",
            "1925000 2273845\n",
            "1926000 2273845\n",
            "1927000 2273845\n",
            "1928000 2273845\n",
            "1929000 2273845\n",
            "1930000 2273845\n",
            "1931000 2273845\n",
            "1932000 2273845\n",
            "1933000 2273845\n",
            "1934000 2273845\n",
            "1935000 2273845\n",
            "1936000 2273845\n",
            "1937000 2273845\n",
            "1938000 2273845\n",
            "1939000 2273845\n",
            "1940000 2273845\n",
            "1941000 2273845\n",
            "1942000 2273845\n",
            "1943000 2273845\n",
            "1944000 2273845\n",
            "1945000 2273845\n",
            "1946000 2273845\n",
            "1947000 2273845\n",
            "1948000 2273845\n",
            "1949000 2273845\n",
            "1950000 2273845\n",
            "1951000 2273845\n",
            "1952000 2273845\n",
            "1953000 2273845\n",
            "1954000 2273845\n",
            "1955000 2273845\n",
            "1956000 2273845\n",
            "1957000 2273845\n",
            "1958000 2273845\n",
            "1959000 2273845\n",
            "1960000 2273845\n",
            "1961000 2273845\n",
            "1962000 2273845\n",
            "1963000 2273845\n",
            "1964000 2273845\n",
            "1965000 2273845\n",
            "1966000 2273845\n",
            "1967000 2273845\n",
            "1968000 2273845\n",
            "1969000 2273845\n",
            "1970000 2273845\n",
            "1971000 2273845\n",
            "1972000 2273845\n",
            "1973000 2273845\n",
            "1974000 2273845\n",
            "1975000 2273845\n",
            "1976000 2273845\n",
            "1977000 2273845\n",
            "1978000 2273845\n",
            "1979000 2273845\n",
            "1980000 2273845\n",
            "1981000 2273845\n",
            "1982000 2273845\n",
            "1983000 2273845\n",
            "1984000 2273845\n",
            "1985000 2273845\n",
            "1986000 2273845\n",
            "1987000 2273845\n",
            "1988000 2273845\n",
            "1989000 2273845\n",
            "1990000 2273845\n",
            "1991000 2273845\n",
            "1992000 2273845\n",
            "1993000 2273845\n",
            "1994000 2273845\n",
            "1995000 2273845\n",
            "1996000 2273845\n",
            "1997000 2273845\n",
            "1998000 2273845\n",
            "1999000 2273845\n",
            "2000000 2273845\n",
            "2001000 2273845\n",
            "2002000 2273845\n",
            "2003000 2273845\n",
            "2004000 2273845\n",
            "2005000 2273845\n",
            "2006000 2273845\n",
            "2007000 2273845\n",
            "2008000 2273845\n",
            "2009000 2273845\n",
            "2010000 2273845\n",
            "2011000 2273845\n",
            "2012000 2273845\n",
            "2013000 2273845\n",
            "2014000 2273845\n",
            "2015000 2273845\n",
            "2016000 2273845\n",
            "2017000 2273845\n",
            "2018000 2273845\n",
            "2019000 2273845\n",
            "2020000 2273845\n",
            "2021000 2273845\n",
            "2022000 2273845\n",
            "2023000 2273845\n",
            "2024000 2273845\n",
            "2025000 2273845\n",
            "2026000 2273845\n",
            "2027000 2273845\n",
            "2028000 2273845\n",
            "2029000 2273845\n",
            "2030000 2273845\n",
            "2031000 2273845\n",
            "2032000 2273845\n",
            "2033000 2273845\n",
            "2034000 2273845\n",
            "2035000 2273845\n",
            "2036000 2273845\n",
            "2037000 2273845\n",
            "2038000 2273845\n",
            "2039000 2273845\n",
            "2040000 2273845\n",
            "2041000 2273845\n",
            "2042000 2273845\n",
            "2043000 2273845\n",
            "2044000 2273845\n",
            "2045000 2273845\n",
            "2046000 2273845\n",
            "2047000 2273845\n",
            "2048000 2273845\n",
            "2049000 2273845\n",
            "2050000 2273845\n",
            "2051000 2273845\n",
            "2052000 2273845\n",
            "2053000 2273845\n",
            "2054000 2273845\n",
            "2055000 2273845\n",
            "2056000 2273845\n",
            "2057000 2273845\n",
            "2058000 2273845\n",
            "2059000 2273845\n",
            "2060000 2273845\n",
            "2061000 2273845\n",
            "2062000 2273845\n",
            "2063000 2273845\n",
            "2064000 2273845\n",
            "2065000 2273845\n",
            "2066000 2273845\n",
            "2067000 2273845\n",
            "2068000 2273845\n",
            "2069000 2273845\n",
            "2070000 2273845\n",
            "2071000 2273845\n",
            "2072000 2273845\n",
            "2073000 2273845\n",
            "2074000 2273845\n",
            "2075000 2273845\n",
            "2076000 2273845\n",
            "2077000 2273845\n",
            "2078000 2273845\n",
            "2079000 2273845\n",
            "2080000 2273845\n",
            "2081000 2273845\n",
            "2082000 2273845\n",
            "2083000 2273845\n",
            "2084000 2273845\n",
            "2085000 2273845\n",
            "2086000 2273845\n",
            "2087000 2273845\n",
            "2088000 2273845\n",
            "2089000 2273845\n",
            "2090000 2273845\n",
            "2091000 2273845\n",
            "2092000 2273845\n",
            "2093000 2273845\n",
            "2094000 2273845\n",
            "2095000 2273845\n",
            "2096000 2273845\n",
            "2097000 2273845\n",
            "2098000 2273845\n",
            "2099000 2273845\n",
            "2100000 2273845\n",
            "2101000 2273845\n",
            "2102000 2273845\n",
            "2103000 2273845\n",
            "2104000 2273845\n",
            "2105000 2273845\n",
            "2106000 2273845\n",
            "2107000 2273845\n",
            "2108000 2273845\n",
            "2109000 2273845\n",
            "2110000 2273845\n",
            "2111000 2273845\n",
            "2112000 2273845\n",
            "2113000 2273845\n",
            "2114000 2273845\n",
            "2115000 2273845\n",
            "2116000 2273845\n",
            "2117000 2273845\n",
            "2118000 2273845\n",
            "2119000 2273845\n",
            "2120000 2273845\n",
            "2121000 2273845\n",
            "2122000 2273845\n",
            "2123000 2273845\n",
            "2124000 2273845\n",
            "2125000 2273845\n",
            "2126000 2273845\n",
            "2127000 2273845\n",
            "2128000 2273845\n",
            "2129000 2273845\n",
            "2130000 2273845\n",
            "2131000 2273845\n",
            "2132000 2273845\n",
            "2133000 2273845\n",
            "2134000 2273845\n",
            "2135000 2273845\n",
            "2136000 2273845\n",
            "2137000 2273845\n",
            "2138000 2273845\n",
            "2139000 2273845\n",
            "2140000 2273845\n",
            "2141000 2273845\n",
            "2142000 2273845\n",
            "2143000 2273845\n",
            "2144000 2273845\n",
            "2145000 2273845\n",
            "2146000 2273845\n",
            "2147000 2273845\n",
            "2148000 2273845\n",
            "2149000 2273845\n",
            "2150000 2273845\n",
            "2151000 2273845\n",
            "2152000 2273845\n",
            "2153000 2273845\n",
            "2154000 2273845\n",
            "2155000 2273845\n",
            "2156000 2273845\n",
            "2157000 2273845\n",
            "2158000 2273845\n",
            "2159000 2273845\n",
            "2160000 2273845\n",
            "2161000 2273845\n",
            "2162000 2273845\n",
            "2163000 2273845\n",
            "2164000 2273845\n",
            "2165000 2273845\n",
            "2166000 2273845\n",
            "2167000 2273845\n",
            "2168000 2273845\n",
            "2169000 2273845\n",
            "2170000 2273845\n",
            "2171000 2273845\n",
            "2172000 2273845\n",
            "2173000 2273845\n",
            "2174000 2273845\n",
            "2175000 2273845\n",
            "2176000 2273845\n",
            "2177000 2273845\n",
            "2178000 2273845\n",
            "2179000 2273845\n",
            "2180000 2273845\n",
            "2181000 2273845\n",
            "2182000 2273845\n",
            "2183000 2273845\n",
            "2184000 2273845\n",
            "2185000 2273845\n",
            "2186000 2273845\n",
            "2187000 2273845\n",
            "2188000 2273845\n",
            "2189000 2273845\n",
            "2190000 2273845\n",
            "2191000 2273845\n",
            "2192000 2273845\n",
            "2193000 2273845\n",
            "2194000 2273845\n",
            "2195000 2273845\n",
            "2196000 2273845\n",
            "2197000 2273845\n",
            "2198000 2273845\n",
            "2199000 2273845\n",
            "2200000 2273845\n",
            "2201000 2273845\n",
            "2202000 2273845\n",
            "2203000 2273845\n",
            "2204000 2273845\n",
            "2205000 2273845\n",
            "2206000 2273845\n",
            "2207000 2273845\n",
            "2208000 2273845\n",
            "2209000 2273845\n",
            "2210000 2273845\n",
            "2211000 2273845\n",
            "2212000 2273845\n",
            "2213000 2273845\n",
            "2214000 2273845\n",
            "2215000 2273845\n",
            "2216000 2273845\n",
            "2217000 2273845\n",
            "2218000 2273845\n",
            "2219000 2273845\n",
            "2220000 2273845\n",
            "2221000 2273845\n",
            "2222000 2273845\n",
            "2223000 2273845\n",
            "2224000 2273845\n",
            "2225000 2273845\n",
            "2226000 2273845\n",
            "2227000 2273845\n",
            "2228000 2273845\n",
            "2229000 2273845\n",
            "2230000 2273845\n",
            "2231000 2273845\n",
            "2232000 2273845\n",
            "2233000 2273845\n",
            "2234000 2273845\n",
            "2235000 2273845\n",
            "2236000 2273845\n",
            "2237000 2273845\n",
            "2238000 2273845\n",
            "2239000 2273845\n",
            "2240000 2273845\n",
            "2241000 2273845\n",
            "2242000 2273845\n",
            "2243000 2273845\n",
            "2244000 2273845\n",
            "2245000 2273845\n",
            "2246000 2273845\n",
            "2247000 2273845\n",
            "2248000 2273845\n",
            "2249000 2273845\n",
            "2250000 2273845\n",
            "2251000 2273845\n",
            "2252000 2273845\n",
            "2253000 2273845\n",
            "2254000 2273845\n",
            "2255000 2273845\n",
            "2256000 2273845\n",
            "2257000 2273845\n",
            "2258000 2273845\n",
            "2259000 2273845\n",
            "2260000 2273845\n",
            "2261000 2273845\n",
            "2262000 2273845\n",
            "2263000 2273845\n",
            "2264000 2273845\n",
            "2265000 2273845\n",
            "2266000 2273845\n",
            "2267000 2273845\n",
            "2268000 2273845\n",
            "2269000 2273845\n",
            "2270000 2273845\n",
            "2271000 2273845\n",
            "2272000 2273845\n",
            "2273000 2273845\n",
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "0 1580093\n",
            "1000 1580093\n",
            "2000 1580093\n",
            "3000 1580093\n",
            "4000 1580093\n",
            "5000 1580093\n",
            "6000 1580093\n",
            "7000 1580093\n",
            "8000 1580093\n",
            "9000 1580093\n",
            "10000 1580093\n",
            "11000 1580093\n",
            "12000 1580093\n",
            "13000 1580093\n",
            "14000 1580093\n",
            "15000 1580093\n",
            "16000 1580093\n",
            "17000 1580093\n",
            "18000 1580093\n",
            "19000 1580093\n",
            "20000 1580093\n",
            "21000 1580093\n",
            "22000 1580093\n",
            "23000 1580093\n",
            "24000 1580093\n",
            "25000 1580093\n",
            "26000 1580093\n",
            "27000 1580093\n",
            "28000 1580093\n",
            "29000 1580093\n",
            "30000 1580093\n",
            "31000 1580093\n",
            "32000 1580093\n",
            "33000 1580093\n",
            "34000 1580093\n",
            "35000 1580093\n",
            "36000 1580093\n",
            "37000 1580093\n",
            "38000 1580093\n",
            "39000 1580093\n",
            "40000 1580093\n",
            "41000 1580093\n",
            "42000 1580093\n",
            "43000 1580093\n",
            "44000 1580093\n",
            "45000 1580093\n",
            "46000 1580093\n",
            "47000 1580093\n",
            "48000 1580093\n",
            "49000 1580093\n",
            "50000 1580093\n",
            "51000 1580093\n",
            "52000 1580093\n",
            "53000 1580093\n",
            "54000 1580093\n",
            "55000 1580093\n",
            "56000 1580093\n",
            "57000 1580093\n",
            "58000 1580093\n",
            "59000 1580093\n",
            "60000 1580093\n",
            "61000 1580093\n",
            "62000 1580093\n",
            "63000 1580093\n",
            "64000 1580093\n",
            "65000 1580093\n",
            "66000 1580093\n",
            "67000 1580093\n",
            "68000 1580093\n",
            "69000 1580093\n",
            "70000 1580093\n",
            "71000 1580093\n",
            "72000 1580093\n",
            "73000 1580093\n",
            "74000 1580093\n",
            "75000 1580093\n",
            "76000 1580093\n",
            "77000 1580093\n",
            "78000 1580093\n",
            "79000 1580093\n",
            "80000 1580093\n",
            "81000 1580093\n",
            "82000 1580093\n",
            "83000 1580093\n",
            "84000 1580093\n",
            "85000 1580093\n",
            "86000 1580093\n",
            "87000 1580093\n",
            "88000 1580093\n",
            "89000 1580093\n",
            "90000 1580093\n",
            "91000 1580093\n",
            "92000 1580093\n",
            "93000 1580093\n",
            "94000 1580093\n",
            "95000 1580093\n",
            "96000 1580093\n",
            "97000 1580093\n",
            "98000 1580093\n",
            "99000 1580093\n",
            "100000 1580093\n",
            "101000 1580093\n",
            "102000 1580093\n",
            "103000 1580093\n",
            "104000 1580093\n",
            "105000 1580093\n",
            "106000 1580093\n",
            "107000 1580093\n",
            "108000 1580093\n",
            "109000 1580093\n",
            "110000 1580093\n",
            "111000 1580093\n",
            "112000 1580093\n",
            "113000 1580093\n",
            "114000 1580093\n",
            "115000 1580093\n",
            "116000 1580093\n",
            "117000 1580093\n",
            "118000 1580093\n",
            "119000 1580093\n",
            "120000 1580093\n",
            "121000 1580093\n",
            "122000 1580093\n",
            "123000 1580093\n",
            "124000 1580093\n",
            "125000 1580093\n",
            "126000 1580093\n",
            "127000 1580093\n",
            "128000 1580093\n",
            "129000 1580093\n",
            "130000 1580093\n",
            "131000 1580093\n",
            "132000 1580093\n",
            "133000 1580093\n",
            "134000 1580093\n",
            "135000 1580093\n",
            "136000 1580093\n",
            "137000 1580093\n",
            "138000 1580093\n",
            "139000 1580093\n",
            "140000 1580093\n",
            "141000 1580093\n",
            "142000 1580093\n",
            "143000 1580093\n",
            "144000 1580093\n",
            "145000 1580093\n",
            "146000 1580093\n",
            "147000 1580093\n",
            "148000 1580093\n",
            "149000 1580093\n",
            "150000 1580093\n",
            "151000 1580093\n",
            "152000 1580093\n",
            "153000 1580093\n",
            "154000 1580093\n",
            "155000 1580093\n",
            "156000 1580093\n",
            "157000 1580093\n",
            "158000 1580093\n",
            "159000 1580093\n",
            "160000 1580093\n",
            "161000 1580093\n",
            "162000 1580093\n",
            "163000 1580093\n",
            "164000 1580093\n",
            "165000 1580093\n",
            "166000 1580093\n",
            "167000 1580093\n",
            "168000 1580093\n",
            "169000 1580093\n",
            "170000 1580093\n",
            "171000 1580093\n",
            "172000 1580093\n",
            "173000 1580093\n",
            "174000 1580093\n",
            "175000 1580093\n",
            "176000 1580093\n",
            "177000 1580093\n",
            "178000 1580093\n",
            "179000 1580093\n",
            "180000 1580093\n",
            "181000 1580093\n",
            "182000 1580093\n",
            "183000 1580093\n",
            "184000 1580093\n",
            "185000 1580093\n",
            "186000 1580093\n",
            "187000 1580093\n",
            "188000 1580093\n",
            "189000 1580093\n",
            "190000 1580093\n",
            "191000 1580093\n",
            "192000 1580093\n",
            "193000 1580093\n",
            "194000 1580093\n",
            "195000 1580093\n",
            "196000 1580093\n",
            "197000 1580093\n",
            "198000 1580093\n",
            "199000 1580093\n",
            "200000 1580093\n",
            "201000 1580093\n",
            "202000 1580093\n",
            "203000 1580093\n",
            "204000 1580093\n",
            "205000 1580093\n",
            "206000 1580093\n",
            "207000 1580093\n",
            "208000 1580093\n",
            "209000 1580093\n",
            "210000 1580093\n",
            "211000 1580093\n",
            "212000 1580093\n",
            "213000 1580093\n",
            "214000 1580093\n",
            "215000 1580093\n",
            "216000 1580093\n",
            "217000 1580093\n",
            "218000 1580093\n",
            "219000 1580093\n",
            "220000 1580093\n",
            "221000 1580093\n",
            "222000 1580093\n",
            "223000 1580093\n",
            "224000 1580093\n",
            "225000 1580093\n",
            "226000 1580093\n",
            "227000 1580093\n",
            "228000 1580093\n",
            "229000 1580093\n",
            "230000 1580093\n",
            "231000 1580093\n",
            "232000 1580093\n",
            "233000 1580093\n",
            "234000 1580093\n",
            "235000 1580093\n",
            "236000 1580093\n",
            "237000 1580093\n",
            "238000 1580093\n",
            "239000 1580093\n",
            "240000 1580093\n",
            "241000 1580093\n",
            "242000 1580093\n",
            "243000 1580093\n",
            "244000 1580093\n",
            "245000 1580093\n",
            "246000 1580093\n",
            "247000 1580093\n",
            "248000 1580093\n",
            "249000 1580093\n",
            "250000 1580093\n",
            "251000 1580093\n",
            "252000 1580093\n",
            "253000 1580093\n",
            "254000 1580093\n",
            "255000 1580093\n",
            "256000 1580093\n",
            "257000 1580093\n",
            "258000 1580093\n",
            "259000 1580093\n",
            "260000 1580093\n",
            "261000 1580093\n",
            "262000 1580093\n",
            "263000 1580093\n",
            "264000 1580093\n",
            "265000 1580093\n",
            "266000 1580093\n",
            "267000 1580093\n",
            "268000 1580093\n",
            "269000 1580093\n",
            "270000 1580093\n",
            "271000 1580093\n",
            "272000 1580093\n",
            "273000 1580093\n",
            "274000 1580093\n",
            "275000 1580093\n",
            "276000 1580093\n",
            "277000 1580093\n",
            "278000 1580093\n",
            "279000 1580093\n",
            "280000 1580093\n",
            "281000 1580093\n",
            "282000 1580093\n",
            "283000 1580093\n",
            "284000 1580093\n",
            "285000 1580093\n",
            "286000 1580093\n",
            "287000 1580093\n",
            "288000 1580093\n",
            "289000 1580093\n",
            "290000 1580093\n",
            "291000 1580093\n",
            "292000 1580093\n",
            "293000 1580093\n",
            "294000 1580093\n",
            "295000 1580093\n",
            "296000 1580093\n",
            "297000 1580093\n",
            "298000 1580093\n",
            "299000 1580093\n",
            "300000 1580093\n",
            "301000 1580093\n",
            "302000 1580093\n",
            "303000 1580093\n",
            "304000 1580093\n",
            "305000 1580093\n",
            "306000 1580093\n",
            "307000 1580093\n",
            "308000 1580093\n",
            "309000 1580093\n",
            "310000 1580093\n",
            "311000 1580093\n",
            "312000 1580093\n",
            "313000 1580093\n",
            "314000 1580093\n",
            "315000 1580093\n",
            "316000 1580093\n",
            "317000 1580093\n",
            "318000 1580093\n",
            "319000 1580093\n",
            "320000 1580093\n",
            "321000 1580093\n",
            "322000 1580093\n",
            "323000 1580093\n",
            "324000 1580093\n",
            "325000 1580093\n",
            "326000 1580093\n",
            "327000 1580093\n",
            "328000 1580093\n",
            "329000 1580093\n",
            "330000 1580093\n",
            "331000 1580093\n",
            "332000 1580093\n",
            "333000 1580093\n",
            "334000 1580093\n",
            "335000 1580093\n",
            "336000 1580093\n",
            "337000 1580093\n",
            "338000 1580093\n",
            "339000 1580093\n",
            "340000 1580093\n",
            "341000 1580093\n",
            "342000 1580093\n",
            "343000 1580093\n",
            "344000 1580093\n",
            "345000 1580093\n",
            "346000 1580093\n",
            "347000 1580093\n",
            "348000 1580093\n",
            "349000 1580093\n",
            "350000 1580093\n",
            "351000 1580093\n",
            "352000 1580093\n",
            "353000 1580093\n",
            "354000 1580093\n",
            "355000 1580093\n",
            "356000 1580093\n",
            "357000 1580093\n",
            "358000 1580093\n",
            "359000 1580093\n",
            "360000 1580093\n",
            "361000 1580093\n",
            "362000 1580093\n",
            "363000 1580093\n",
            "364000 1580093\n",
            "365000 1580093\n",
            "366000 1580093\n",
            "367000 1580093\n",
            "368000 1580093\n",
            "369000 1580093\n",
            "370000 1580093\n",
            "371000 1580093\n",
            "372000 1580093\n",
            "373000 1580093\n",
            "374000 1580093\n",
            "375000 1580093\n",
            "376000 1580093\n",
            "377000 1580093\n",
            "378000 1580093\n",
            "379000 1580093\n",
            "380000 1580093\n",
            "381000 1580093\n",
            "382000 1580093\n",
            "383000 1580093\n",
            "384000 1580093\n",
            "385000 1580093\n",
            "386000 1580093\n",
            "387000 1580093\n",
            "388000 1580093\n",
            "389000 1580093\n",
            "390000 1580093\n",
            "391000 1580093\n",
            "392000 1580093\n",
            "393000 1580093\n",
            "394000 1580093\n",
            "395000 1580093\n",
            "396000 1580093\n",
            "397000 1580093\n",
            "398000 1580093\n",
            "399000 1580093\n",
            "400000 1580093\n",
            "401000 1580093\n",
            "402000 1580093\n",
            "403000 1580093\n",
            "404000 1580093\n",
            "405000 1580093\n",
            "406000 1580093\n",
            "407000 1580093\n",
            "408000 1580093\n",
            "409000 1580093\n",
            "410000 1580093\n",
            "411000 1580093\n",
            "412000 1580093\n",
            "413000 1580093\n",
            "414000 1580093\n",
            "415000 1580093\n",
            "416000 1580093\n",
            "417000 1580093\n",
            "418000 1580093\n",
            "419000 1580093\n",
            "420000 1580093\n",
            "421000 1580093\n",
            "422000 1580093\n",
            "423000 1580093\n",
            "424000 1580093\n",
            "425000 1580093\n",
            "426000 1580093\n",
            "427000 1580093\n",
            "428000 1580093\n",
            "429000 1580093\n",
            "430000 1580093\n",
            "431000 1580093\n",
            "432000 1580093\n",
            "433000 1580093\n",
            "434000 1580093\n",
            "435000 1580093\n",
            "436000 1580093\n",
            "437000 1580093\n",
            "438000 1580093\n",
            "439000 1580093\n",
            "440000 1580093\n",
            "441000 1580093\n",
            "442000 1580093\n",
            "443000 1580093\n",
            "444000 1580093\n",
            "445000 1580093\n",
            "446000 1580093\n",
            "447000 1580093\n",
            "448000 1580093\n",
            "449000 1580093\n",
            "450000 1580093\n",
            "451000 1580093\n",
            "452000 1580093\n",
            "453000 1580093\n",
            "454000 1580093\n",
            "455000 1580093\n",
            "456000 1580093\n",
            "457000 1580093\n",
            "458000 1580093\n",
            "459000 1580093\n",
            "460000 1580093\n",
            "461000 1580093\n",
            "462000 1580093\n",
            "463000 1580093\n",
            "464000 1580093\n",
            "465000 1580093\n",
            "466000 1580093\n",
            "467000 1580093\n",
            "468000 1580093\n",
            "469000 1580093\n",
            "470000 1580093\n",
            "471000 1580093\n",
            "472000 1580093\n",
            "473000 1580093\n",
            "474000 1580093\n",
            "475000 1580093\n",
            "476000 1580093\n",
            "477000 1580093\n",
            "478000 1580093\n",
            "479000 1580093\n",
            "480000 1580093\n",
            "481000 1580093\n",
            "482000 1580093\n",
            "483000 1580093\n",
            "484000 1580093\n",
            "485000 1580093\n",
            "486000 1580093\n",
            "487000 1580093\n",
            "488000 1580093\n",
            "489000 1580093\n",
            "490000 1580093\n",
            "491000 1580093\n",
            "492000 1580093\n",
            "493000 1580093\n",
            "494000 1580093\n",
            "495000 1580093\n",
            "496000 1580093\n",
            "497000 1580093\n",
            "498000 1580093\n",
            "499000 1580093\n",
            "500000 1580093\n",
            "501000 1580093\n",
            "502000 1580093\n",
            "503000 1580093\n",
            "504000 1580093\n",
            "505000 1580093\n",
            "506000 1580093\n",
            "507000 1580093\n",
            "508000 1580093\n",
            "509000 1580093\n",
            "510000 1580093\n",
            "511000 1580093\n",
            "512000 1580093\n",
            "513000 1580093\n",
            "514000 1580093\n",
            "515000 1580093\n",
            "516000 1580093\n",
            "517000 1580093\n",
            "518000 1580093\n",
            "519000 1580093\n",
            "520000 1580093\n",
            "521000 1580093\n",
            "522000 1580093\n",
            "523000 1580093\n",
            "524000 1580093\n",
            "525000 1580093\n",
            "526000 1580093\n",
            "527000 1580093\n",
            "528000 1580093\n",
            "529000 1580093\n",
            "530000 1580093\n",
            "531000 1580093\n",
            "532000 1580093\n",
            "533000 1580093\n",
            "534000 1580093\n",
            "535000 1580093\n",
            "536000 1580093\n",
            "537000 1580093\n",
            "538000 1580093\n",
            "539000 1580093\n",
            "540000 1580093\n",
            "541000 1580093\n",
            "542000 1580093\n",
            "543000 1580093\n",
            "544000 1580093\n",
            "545000 1580093\n",
            "546000 1580093\n",
            "547000 1580093\n",
            "548000 1580093\n",
            "549000 1580093\n",
            "550000 1580093\n",
            "551000 1580093\n",
            "552000 1580093\n",
            "553000 1580093\n",
            "554000 1580093\n",
            "555000 1580093\n",
            "556000 1580093\n",
            "557000 1580093\n",
            "558000 1580093\n",
            "559000 1580093\n",
            "560000 1580093\n",
            "561000 1580093\n",
            "562000 1580093\n",
            "563000 1580093\n",
            "564000 1580093\n",
            "565000 1580093\n",
            "566000 1580093\n",
            "567000 1580093\n",
            "568000 1580093\n",
            "569000 1580093\n",
            "570000 1580093\n",
            "571000 1580093\n",
            "572000 1580093\n",
            "573000 1580093\n",
            "574000 1580093\n",
            "575000 1580093\n",
            "576000 1580093\n",
            "577000 1580093\n",
            "578000 1580093\n",
            "579000 1580093\n",
            "580000 1580093\n",
            "581000 1580093\n",
            "582000 1580093\n",
            "583000 1580093\n",
            "584000 1580093\n",
            "585000 1580093\n",
            "586000 1580093\n",
            "587000 1580093\n",
            "588000 1580093\n",
            "589000 1580093\n",
            "590000 1580093\n",
            "591000 1580093\n",
            "592000 1580093\n",
            "593000 1580093\n",
            "594000 1580093\n",
            "595000 1580093\n",
            "596000 1580093\n",
            "597000 1580093\n",
            "598000 1580093\n",
            "599000 1580093\n",
            "600000 1580093\n",
            "601000 1580093\n",
            "602000 1580093\n",
            "603000 1580093\n",
            "604000 1580093\n",
            "605000 1580093\n",
            "606000 1580093\n",
            "607000 1580093\n",
            "608000 1580093\n",
            "609000 1580093\n",
            "610000 1580093\n",
            "611000 1580093\n",
            "612000 1580093\n",
            "613000 1580093\n",
            "614000 1580093\n",
            "615000 1580093\n",
            "616000 1580093\n",
            "617000 1580093\n",
            "618000 1580093\n",
            "619000 1580093\n",
            "620000 1580093\n",
            "621000 1580093\n",
            "622000 1580093\n",
            "623000 1580093\n",
            "624000 1580093\n",
            "625000 1580093\n",
            "626000 1580093\n",
            "627000 1580093\n",
            "628000 1580093\n",
            "629000 1580093\n",
            "630000 1580093\n",
            "631000 1580093\n",
            "632000 1580093\n",
            "633000 1580093\n",
            "634000 1580093\n",
            "635000 1580093\n",
            "636000 1580093\n",
            "637000 1580093\n",
            "638000 1580093\n",
            "639000 1580093\n",
            "640000 1580093\n",
            "641000 1580093\n",
            "642000 1580093\n",
            "643000 1580093\n",
            "644000 1580093\n",
            "645000 1580093\n",
            "646000 1580093\n",
            "647000 1580093\n",
            "648000 1580093\n",
            "649000 1580093\n",
            "650000 1580093\n",
            "651000 1580093\n",
            "652000 1580093\n",
            "653000 1580093\n",
            "654000 1580093\n",
            "655000 1580093\n",
            "656000 1580093\n",
            "657000 1580093\n",
            "658000 1580093\n",
            "659000 1580093\n",
            "660000 1580093\n",
            "661000 1580093\n",
            "662000 1580093\n",
            "663000 1580093\n",
            "664000 1580093\n",
            "665000 1580093\n",
            "666000 1580093\n",
            "667000 1580093\n",
            "668000 1580093\n",
            "669000 1580093\n",
            "670000 1580093\n",
            "671000 1580093\n",
            "672000 1580093\n",
            "673000 1580093\n",
            "674000 1580093\n",
            "675000 1580093\n",
            "676000 1580093\n",
            "677000 1580093\n",
            "678000 1580093\n",
            "679000 1580093\n",
            "680000 1580093\n",
            "681000 1580093\n",
            "682000 1580093\n",
            "683000 1580093\n",
            "684000 1580093\n",
            "685000 1580093\n",
            "686000 1580093\n",
            "687000 1580093\n",
            "688000 1580093\n",
            "689000 1580093\n",
            "690000 1580093\n",
            "691000 1580093\n",
            "692000 1580093\n",
            "693000 1580093\n",
            "694000 1580093\n",
            "695000 1580093\n",
            "696000 1580093\n",
            "697000 1580093\n",
            "698000 1580093\n",
            "699000 1580093\n",
            "700000 1580093\n",
            "701000 1580093\n",
            "702000 1580093\n",
            "703000 1580093\n",
            "704000 1580093\n",
            "705000 1580093\n",
            "706000 1580093\n",
            "707000 1580093\n",
            "708000 1580093\n",
            "709000 1580093\n",
            "710000 1580093\n",
            "711000 1580093\n",
            "712000 1580093\n",
            "713000 1580093\n",
            "714000 1580093\n",
            "715000 1580093\n",
            "716000 1580093\n",
            "717000 1580093\n",
            "718000 1580093\n",
            "719000 1580093\n",
            "720000 1580093\n",
            "721000 1580093\n",
            "722000 1580093\n",
            "723000 1580093\n",
            "724000 1580093\n",
            "725000 1580093\n",
            "726000 1580093\n",
            "727000 1580093\n",
            "728000 1580093\n",
            "729000 1580093\n",
            "730000 1580093\n",
            "731000 1580093\n",
            "732000 1580093\n",
            "733000 1580093\n",
            "734000 1580093\n",
            "735000 1580093\n",
            "736000 1580093\n",
            "737000 1580093\n",
            "738000 1580093\n",
            "739000 1580093\n",
            "740000 1580093\n",
            "741000 1580093\n",
            "742000 1580093\n",
            "743000 1580093\n",
            "744000 1580093\n",
            "745000 1580093\n",
            "746000 1580093\n",
            "747000 1580093\n",
            "748000 1580093\n",
            "749000 1580093\n",
            "750000 1580093\n",
            "751000 1580093\n",
            "752000 1580093\n",
            "753000 1580093\n",
            "754000 1580093\n",
            "755000 1580093\n",
            "756000 1580093\n",
            "757000 1580093\n",
            "758000 1580093\n",
            "759000 1580093\n",
            "760000 1580093\n",
            "761000 1580093\n",
            "762000 1580093\n",
            "763000 1580093\n",
            "764000 1580093\n",
            "765000 1580093\n",
            "766000 1580093\n",
            "767000 1580093\n",
            "768000 1580093\n",
            "769000 1580093\n",
            "770000 1580093\n",
            "771000 1580093\n",
            "772000 1580093\n",
            "773000 1580093\n",
            "774000 1580093\n",
            "775000 1580093\n",
            "776000 1580093\n",
            "777000 1580093\n",
            "778000 1580093\n",
            "779000 1580093\n",
            "780000 1580093\n",
            "781000 1580093\n",
            "782000 1580093\n",
            "783000 1580093\n",
            "784000 1580093\n",
            "785000 1580093\n",
            "786000 1580093\n",
            "787000 1580093\n",
            "788000 1580093\n",
            "789000 1580093\n",
            "790000 1580093\n",
            "791000 1580093\n",
            "792000 1580093\n",
            "793000 1580093\n",
            "794000 1580093\n",
            "795000 1580093\n",
            "796000 1580093\n",
            "797000 1580093\n",
            "798000 1580093\n",
            "799000 1580093\n",
            "800000 1580093\n",
            "801000 1580093\n",
            "802000 1580093\n",
            "803000 1580093\n",
            "804000 1580093\n",
            "805000 1580093\n",
            "806000 1580093\n",
            "807000 1580093\n",
            "808000 1580093\n",
            "809000 1580093\n",
            "810000 1580093\n",
            "811000 1580093\n",
            "812000 1580093\n",
            "813000 1580093\n",
            "814000 1580093\n",
            "815000 1580093\n",
            "816000 1580093\n",
            "817000 1580093\n",
            "818000 1580093\n",
            "819000 1580093\n",
            "820000 1580093\n",
            "821000 1580093\n",
            "822000 1580093\n",
            "823000 1580093\n",
            "824000 1580093\n",
            "825000 1580093\n",
            "826000 1580093\n",
            "827000 1580093\n",
            "828000 1580093\n",
            "829000 1580093\n",
            "830000 1580093\n",
            "831000 1580093\n",
            "832000 1580093\n",
            "833000 1580093\n",
            "834000 1580093\n",
            "835000 1580093\n",
            "836000 1580093\n",
            "837000 1580093\n",
            "838000 1580093\n",
            "839000 1580093\n",
            "840000 1580093\n",
            "841000 1580093\n",
            "842000 1580093\n",
            "843000 1580093\n",
            "844000 1580093\n",
            "845000 1580093\n",
            "846000 1580093\n",
            "847000 1580093\n",
            "848000 1580093\n",
            "849000 1580093\n",
            "850000 1580093\n",
            "851000 1580093\n",
            "852000 1580093\n",
            "853000 1580093\n",
            "854000 1580093\n",
            "855000 1580093\n",
            "856000 1580093\n",
            "857000 1580093\n",
            "858000 1580093\n",
            "859000 1580093\n",
            "860000 1580093\n",
            "861000 1580093\n",
            "862000 1580093\n",
            "863000 1580093\n",
            "864000 1580093\n",
            "865000 1580093\n",
            "866000 1580093\n",
            "867000 1580093\n",
            "868000 1580093\n",
            "869000 1580093\n",
            "870000 1580093\n",
            "871000 1580093\n",
            "872000 1580093\n",
            "873000 1580093\n",
            "874000 1580093\n",
            "875000 1580093\n",
            "876000 1580093\n",
            "877000 1580093\n",
            "878000 1580093\n",
            "879000 1580093\n",
            "880000 1580093\n",
            "881000 1580093\n",
            "882000 1580093\n",
            "883000 1580093\n",
            "884000 1580093\n",
            "885000 1580093\n",
            "886000 1580093\n",
            "887000 1580093\n",
            "888000 1580093\n",
            "889000 1580093\n",
            "890000 1580093\n",
            "891000 1580093\n",
            "892000 1580093\n",
            "893000 1580093\n",
            "894000 1580093\n",
            "895000 1580093\n",
            "896000 1580093\n",
            "897000 1580093\n",
            "898000 1580093\n",
            "899000 1580093\n",
            "900000 1580093\n",
            "901000 1580093\n",
            "902000 1580093\n",
            "903000 1580093\n",
            "904000 1580093\n",
            "905000 1580093\n",
            "906000 1580093\n",
            "907000 1580093\n",
            "908000 1580093\n",
            "909000 1580093\n",
            "910000 1580093\n",
            "911000 1580093\n",
            "912000 1580093\n",
            "913000 1580093\n",
            "914000 1580093\n",
            "915000 1580093\n",
            "916000 1580093\n",
            "917000 1580093\n",
            "918000 1580093\n",
            "919000 1580093\n",
            "920000 1580093\n",
            "921000 1580093\n",
            "922000 1580093\n",
            "923000 1580093\n",
            "924000 1580093\n",
            "925000 1580093\n",
            "926000 1580093\n",
            "927000 1580093\n",
            "928000 1580093\n",
            "929000 1580093\n",
            "930000 1580093\n",
            "931000 1580093\n",
            "932000 1580093\n",
            "933000 1580093\n",
            "934000 1580093\n",
            "935000 1580093\n",
            "936000 1580093\n",
            "937000 1580093\n",
            "938000 1580093\n",
            "939000 1580093\n",
            "940000 1580093\n",
            "941000 1580093\n",
            "942000 1580093\n",
            "943000 1580093\n",
            "944000 1580093\n",
            "945000 1580093\n",
            "946000 1580093\n",
            "947000 1580093\n",
            "948000 1580093\n",
            "949000 1580093\n",
            "950000 1580093\n",
            "951000 1580093\n",
            "952000 1580093\n",
            "953000 1580093\n",
            "954000 1580093\n",
            "955000 1580093\n",
            "956000 1580093\n",
            "957000 1580093\n",
            "958000 1580093\n",
            "959000 1580093\n",
            "960000 1580093\n",
            "961000 1580093\n",
            "962000 1580093\n",
            "963000 1580093\n",
            "964000 1580093\n",
            "965000 1580093\n",
            "966000 1580093\n",
            "967000 1580093\n",
            "968000 1580093\n",
            "969000 1580093\n",
            "970000 1580093\n",
            "971000 1580093\n",
            "972000 1580093\n",
            "973000 1580093\n",
            "974000 1580093\n",
            "975000 1580093\n",
            "976000 1580093\n",
            "977000 1580093\n",
            "978000 1580093\n",
            "979000 1580093\n",
            "980000 1580093\n",
            "981000 1580093\n",
            "982000 1580093\n",
            "983000 1580093\n",
            "984000 1580093\n",
            "985000 1580093\n",
            "986000 1580093\n",
            "987000 1580093\n",
            "988000 1580093\n",
            "989000 1580093\n",
            "990000 1580093\n",
            "991000 1580093\n",
            "992000 1580093\n",
            "993000 1580093\n",
            "994000 1580093\n",
            "995000 1580093\n",
            "996000 1580093\n",
            "997000 1580093\n",
            "998000 1580093\n",
            "999000 1580093\n",
            "1000000 1580093\n",
            "1001000 1580093\n",
            "1002000 1580093\n",
            "1003000 1580093\n",
            "1004000 1580093\n",
            "1005000 1580093\n",
            "1006000 1580093\n",
            "1007000 1580093\n",
            "1008000 1580093\n",
            "1009000 1580093\n",
            "1010000 1580093\n",
            "1011000 1580093\n",
            "1012000 1580093\n",
            "1013000 1580093\n",
            "1014000 1580093\n",
            "1015000 1580093\n",
            "1016000 1580093\n",
            "1017000 1580093\n",
            "1018000 1580093\n",
            "1019000 1580093\n",
            "1020000 1580093\n",
            "1021000 1580093\n",
            "1022000 1580093\n",
            "1023000 1580093\n",
            "1024000 1580093\n",
            "1025000 1580093\n",
            "1026000 1580093\n",
            "1027000 1580093\n",
            "1028000 1580093\n",
            "1029000 1580093\n",
            "1030000 1580093\n",
            "1031000 1580093\n",
            "1032000 1580093\n",
            "1033000 1580093\n",
            "1034000 1580093\n",
            "1035000 1580093\n",
            "1036000 1580093\n",
            "1037000 1580093\n",
            "1038000 1580093\n",
            "1039000 1580093\n",
            "1040000 1580093\n",
            "1041000 1580093\n",
            "1042000 1580093\n",
            "1043000 1580093\n",
            "1044000 1580093\n",
            "1045000 1580093\n",
            "1046000 1580093\n",
            "1047000 1580093\n",
            "1048000 1580093\n",
            "1049000 1580093\n",
            "1050000 1580093\n",
            "1051000 1580093\n",
            "1052000 1580093\n",
            "1053000 1580093\n",
            "1054000 1580093\n",
            "1055000 1580093\n",
            "1056000 1580093\n",
            "1057000 1580093\n",
            "1058000 1580093\n",
            "1059000 1580093\n",
            "1060000 1580093\n",
            "1061000 1580093\n",
            "1062000 1580093\n",
            "1063000 1580093\n",
            "1064000 1580093\n",
            "1065000 1580093\n",
            "1066000 1580093\n",
            "1067000 1580093\n",
            "1068000 1580093\n",
            "1069000 1580093\n",
            "1070000 1580093\n",
            "1071000 1580093\n",
            "1072000 1580093\n",
            "1073000 1580093\n",
            "1074000 1580093\n",
            "1075000 1580093\n",
            "1076000 1580093\n",
            "1077000 1580093\n",
            "1078000 1580093\n",
            "1079000 1580093\n",
            "1080000 1580093\n",
            "1081000 1580093\n",
            "1082000 1580093\n",
            "1083000 1580093\n",
            "1084000 1580093\n",
            "1085000 1580093\n",
            "1086000 1580093\n",
            "1087000 1580093\n",
            "1088000 1580093\n",
            "1089000 1580093\n",
            "1090000 1580093\n",
            "1091000 1580093\n",
            "1092000 1580093\n",
            "1093000 1580093\n",
            "1094000 1580093\n",
            "1095000 1580093\n",
            "1096000 1580093\n",
            "1097000 1580093\n",
            "1098000 1580093\n",
            "1099000 1580093\n",
            "1100000 1580093\n",
            "1101000 1580093\n",
            "1102000 1580093\n",
            "1103000 1580093\n",
            "1104000 1580093\n",
            "1105000 1580093\n",
            "1106000 1580093\n",
            "1107000 1580093\n",
            "1108000 1580093\n",
            "1109000 1580093\n",
            "1110000 1580093\n",
            "1111000 1580093\n",
            "1112000 1580093\n",
            "1113000 1580093\n",
            "1114000 1580093\n",
            "1115000 1580093\n",
            "1116000 1580093\n",
            "1117000 1580093\n",
            "1118000 1580093\n",
            "1119000 1580093\n",
            "1120000 1580093\n",
            "1121000 1580093\n",
            "1122000 1580093\n",
            "1123000 1580093\n",
            "1124000 1580093\n",
            "1125000 1580093\n",
            "1126000 1580093\n",
            "1127000 1580093\n",
            "1128000 1580093\n",
            "1129000 1580093\n",
            "1130000 1580093\n",
            "1131000 1580093\n",
            "1132000 1580093\n",
            "1133000 1580093\n",
            "1134000 1580093\n",
            "1135000 1580093\n",
            "1136000 1580093\n",
            "1137000 1580093\n",
            "1138000 1580093\n",
            "1139000 1580093\n",
            "1140000 1580093\n",
            "1141000 1580093\n",
            "1142000 1580093\n",
            "1143000 1580093\n",
            "1144000 1580093\n",
            "1145000 1580093\n",
            "1146000 1580093\n",
            "1147000 1580093\n",
            "1148000 1580093\n",
            "1149000 1580093\n",
            "1150000 1580093\n",
            "1151000 1580093\n",
            "1152000 1580093\n",
            "1153000 1580093\n",
            "1154000 1580093\n",
            "1155000 1580093\n",
            "1156000 1580093\n",
            "1157000 1580093\n",
            "1158000 1580093\n",
            "1159000 1580093\n",
            "1160000 1580093\n",
            "1161000 1580093\n",
            "1162000 1580093\n",
            "1163000 1580093\n",
            "1164000 1580093\n",
            "1165000 1580093\n",
            "1166000 1580093\n",
            "1167000 1580093\n",
            "1168000 1580093\n",
            "1169000 1580093\n",
            "1170000 1580093\n",
            "1171000 1580093\n",
            "1172000 1580093\n",
            "1173000 1580093\n",
            "1174000 1580093\n",
            "1175000 1580093\n",
            "1176000 1580093\n",
            "1177000 1580093\n",
            "1178000 1580093\n",
            "1179000 1580093\n",
            "1180000 1580093\n",
            "1181000 1580093\n",
            "1182000 1580093\n",
            "1183000 1580093\n",
            "1184000 1580093\n",
            "1185000 1580093\n",
            "1186000 1580093\n",
            "1187000 1580093\n",
            "1188000 1580093\n",
            "1189000 1580093\n",
            "1190000 1580093\n",
            "1191000 1580093\n",
            "1192000 1580093\n",
            "1193000 1580093\n",
            "1194000 1580093\n",
            "1195000 1580093\n",
            "1196000 1580093\n",
            "1197000 1580093\n",
            "1198000 1580093\n",
            "1199000 1580093\n",
            "1200000 1580093\n",
            "1201000 1580093\n",
            "1202000 1580093\n",
            "1203000 1580093\n",
            "1204000 1580093\n",
            "1205000 1580093\n",
            "1206000 1580093\n",
            "1207000 1580093\n",
            "1208000 1580093\n",
            "1209000 1580093\n",
            "1210000 1580093\n",
            "1211000 1580093\n",
            "1212000 1580093\n",
            "1213000 1580093\n",
            "1214000 1580093\n",
            "1215000 1580093\n",
            "1216000 1580093\n",
            "1217000 1580093\n",
            "1218000 1580093\n",
            "1219000 1580093\n",
            "1220000 1580093\n",
            "1221000 1580093\n",
            "1222000 1580093\n",
            "1223000 1580093\n",
            "1224000 1580093\n",
            "1225000 1580093\n",
            "1226000 1580093\n",
            "1227000 1580093\n",
            "1228000 1580093\n",
            "1229000 1580093\n",
            "1230000 1580093\n",
            "1231000 1580093\n",
            "1232000 1580093\n",
            "1233000 1580093\n",
            "1234000 1580093\n",
            "1235000 1580093\n",
            "1236000 1580093\n",
            "1237000 1580093\n",
            "1238000 1580093\n",
            "1239000 1580093\n",
            "1240000 1580093\n",
            "1241000 1580093\n",
            "1242000 1580093\n",
            "1243000 1580093\n",
            "1244000 1580093\n",
            "1245000 1580093\n",
            "1246000 1580093\n",
            "1247000 1580093\n",
            "1248000 1580093\n",
            "1249000 1580093\n",
            "1250000 1580093\n",
            "1251000 1580093\n",
            "1252000 1580093\n",
            "1253000 1580093\n",
            "1254000 1580093\n",
            "1255000 1580093\n",
            "1256000 1580093\n",
            "1257000 1580093\n",
            "1258000 1580093\n",
            "1259000 1580093\n",
            "1260000 1580093\n",
            "1261000 1580093\n",
            "1262000 1580093\n",
            "1263000 1580093\n",
            "1264000 1580093\n",
            "1265000 1580093\n",
            "1266000 1580093\n",
            "1267000 1580093\n",
            "1268000 1580093\n",
            "1269000 1580093\n",
            "1270000 1580093\n",
            "1271000 1580093\n",
            "1272000 1580093\n",
            "1273000 1580093\n",
            "1274000 1580093\n",
            "1275000 1580093\n",
            "1276000 1580093\n",
            "1277000 1580093\n",
            "1278000 1580093\n",
            "1279000 1580093\n",
            "1280000 1580093\n",
            "1281000 1580093\n",
            "1282000 1580093\n",
            "1283000 1580093\n",
            "1284000 1580093\n",
            "1285000 1580093\n",
            "1286000 1580093\n",
            "1287000 1580093\n",
            "1288000 1580093\n",
            "1289000 1580093\n",
            "1290000 1580093\n",
            "1291000 1580093\n",
            "1292000 1580093\n",
            "1293000 1580093\n",
            "1294000 1580093\n",
            "1295000 1580093\n",
            "1296000 1580093\n",
            "1297000 1580093\n",
            "1298000 1580093\n",
            "1299000 1580093\n",
            "1300000 1580093\n",
            "1301000 1580093\n",
            "1302000 1580093\n",
            "1303000 1580093\n",
            "1304000 1580093\n",
            "1305000 1580093\n",
            "1306000 1580093\n",
            "1307000 1580093\n",
            "1308000 1580093\n",
            "1309000 1580093\n",
            "1310000 1580093\n",
            "1311000 1580093\n",
            "1312000 1580093\n",
            "1313000 1580093\n",
            "1314000 1580093\n",
            "1315000 1580093\n",
            "1316000 1580093\n",
            "1317000 1580093\n",
            "1318000 1580093\n",
            "1319000 1580093\n",
            "1320000 1580093\n",
            "1321000 1580093\n",
            "1322000 1580093\n",
            "1323000 1580093\n",
            "1324000 1580093\n",
            "1325000 1580093\n",
            "1326000 1580093\n",
            "1327000 1580093\n",
            "1328000 1580093\n",
            "1329000 1580093\n",
            "1330000 1580093\n",
            "1331000 1580093\n",
            "1332000 1580093\n",
            "1333000 1580093\n",
            "1334000 1580093\n",
            "1335000 1580093\n",
            "1336000 1580093\n",
            "1337000 1580093\n",
            "1338000 1580093\n",
            "1339000 1580093\n",
            "1340000 1580093\n",
            "1341000 1580093\n",
            "1342000 1580093\n",
            "1343000 1580093\n",
            "1344000 1580093\n",
            "1345000 1580093\n",
            "1346000 1580093\n",
            "1347000 1580093\n",
            "1348000 1580093\n",
            "1349000 1580093\n",
            "1350000 1580093\n",
            "1351000 1580093\n",
            "1352000 1580093\n",
            "1353000 1580093\n",
            "1354000 1580093\n",
            "1355000 1580093\n",
            "1356000 1580093\n",
            "1357000 1580093\n",
            "1358000 1580093\n",
            "1359000 1580093\n",
            "1360000 1580093\n",
            "1361000 1580093\n",
            "1362000 1580093\n",
            "1363000 1580093\n",
            "1364000 1580093\n",
            "1365000 1580093\n",
            "1366000 1580093\n",
            "1367000 1580093\n",
            "1368000 1580093\n",
            "1369000 1580093\n",
            "1370000 1580093\n",
            "1371000 1580093\n",
            "1372000 1580093\n",
            "1373000 1580093\n",
            "1374000 1580093\n",
            "1375000 1580093\n",
            "1376000 1580093\n",
            "1377000 1580093\n",
            "1378000 1580093\n",
            "1379000 1580093\n",
            "1380000 1580093\n",
            "1381000 1580093\n",
            "1382000 1580093\n",
            "1383000 1580093\n",
            "1384000 1580093\n",
            "1385000 1580093\n",
            "1386000 1580093\n",
            "1387000 1580093\n",
            "1388000 1580093\n",
            "1389000 1580093\n",
            "1390000 1580093\n",
            "1391000 1580093\n",
            "1392000 1580093\n",
            "1393000 1580093\n",
            "1394000 1580093\n",
            "1395000 1580093\n",
            "1396000 1580093\n",
            "1397000 1580093\n",
            "1398000 1580093\n",
            "1399000 1580093\n",
            "1400000 1580093\n",
            "1401000 1580093\n",
            "1402000 1580093\n",
            "1403000 1580093\n",
            "1404000 1580093\n",
            "1405000 1580093\n",
            "1406000 1580093\n",
            "1407000 1580093\n",
            "1408000 1580093\n",
            "1409000 1580093\n",
            "1410000 1580093\n",
            "1411000 1580093\n",
            "1412000 1580093\n",
            "1413000 1580093\n",
            "1414000 1580093\n",
            "1415000 1580093\n",
            "1416000 1580093\n",
            "1417000 1580093\n",
            "1418000 1580093\n",
            "1419000 1580093\n",
            "1420000 1580093\n",
            "1421000 1580093\n",
            "1422000 1580093\n",
            "1423000 1580093\n",
            "1424000 1580093\n",
            "1425000 1580093\n",
            "1426000 1580093\n",
            "1427000 1580093\n",
            "1428000 1580093\n",
            "1429000 1580093\n",
            "1430000 1580093\n",
            "1431000 1580093\n",
            "1432000 1580093\n",
            "1433000 1580093\n",
            "1434000 1580093\n",
            "1435000 1580093\n",
            "1436000 1580093\n",
            "1437000 1580093\n",
            "1438000 1580093\n",
            "1439000 1580093\n",
            "1440000 1580093\n",
            "1441000 1580093\n",
            "1442000 1580093\n",
            "1443000 1580093\n",
            "1444000 1580093\n",
            "1445000 1580093\n",
            "1446000 1580093\n",
            "1447000 1580093\n",
            "1448000 1580093\n",
            "1449000 1580093\n",
            "1450000 1580093\n",
            "1451000 1580093\n",
            "1452000 1580093\n",
            "1453000 1580093\n",
            "1454000 1580093\n",
            "1455000 1580093\n",
            "1456000 1580093\n",
            "1457000 1580093\n",
            "1458000 1580093\n",
            "1459000 1580093\n",
            "1460000 1580093\n",
            "1461000 1580093\n",
            "1462000 1580093\n",
            "1463000 1580093\n",
            "1464000 1580093\n",
            "1465000 1580093\n",
            "1466000 1580093\n",
            "1467000 1580093\n",
            "1468000 1580093\n",
            "1469000 1580093\n",
            "1470000 1580093\n",
            "1471000 1580093\n",
            "1472000 1580093\n",
            "1473000 1580093\n",
            "1474000 1580093\n",
            "1475000 1580093\n",
            "1476000 1580093\n",
            "1477000 1580093\n",
            "1478000 1580093\n",
            "1479000 1580093\n",
            "1480000 1580093\n",
            "1481000 1580093\n",
            "1482000 1580093\n",
            "1483000 1580093\n",
            "1484000 1580093\n",
            "1485000 1580093\n",
            "1486000 1580093\n",
            "1487000 1580093\n",
            "1488000 1580093\n",
            "1489000 1580093\n",
            "1490000 1580093\n",
            "1491000 1580093\n",
            "1492000 1580093\n",
            "1493000 1580093\n",
            "1494000 1580093\n",
            "1495000 1580093\n",
            "1496000 1580093\n",
            "1497000 1580093\n",
            "1498000 1580093\n",
            "1499000 1580093\n",
            "1500000 1580093\n",
            "1501000 1580093\n",
            "1502000 1580093\n",
            "1503000 1580093\n",
            "1504000 1580093\n",
            "1505000 1580093\n",
            "1506000 1580093\n",
            "1507000 1580093\n",
            "1508000 1580093\n",
            "1509000 1580093\n",
            "1510000 1580093\n",
            "1511000 1580093\n",
            "1512000 1580093\n",
            "1513000 1580093\n",
            "1514000 1580093\n",
            "1515000 1580093\n",
            "1516000 1580093\n",
            "1517000 1580093\n",
            "1518000 1580093\n",
            "1519000 1580093\n",
            "1520000 1580093\n",
            "1521000 1580093\n",
            "1522000 1580093\n",
            "1523000 1580093\n",
            "1524000 1580093\n",
            "1525000 1580093\n",
            "1526000 1580093\n",
            "1527000 1580093\n",
            "1528000 1580093\n",
            "1529000 1580093\n",
            "1530000 1580093\n",
            "1531000 1580093\n",
            "1532000 1580093\n",
            "1533000 1580093\n",
            "1534000 1580093\n",
            "1535000 1580093\n",
            "1536000 1580093\n",
            "1537000 1580093\n",
            "1538000 1580093\n",
            "1539000 1580093\n",
            "1540000 1580093\n",
            "1541000 1580093\n",
            "1542000 1580093\n",
            "1543000 1580093\n",
            "1544000 1580093\n",
            "1545000 1580093\n",
            "1546000 1580093\n",
            "1547000 1580093\n",
            "1548000 1580093\n",
            "1549000 1580093\n",
            "1550000 1580093\n",
            "1551000 1580093\n",
            "1552000 1580093\n",
            "1553000 1580093\n",
            "1554000 1580093\n",
            "1555000 1580093\n",
            "1556000 1580093\n",
            "1557000 1580093\n",
            "1558000 1580093\n",
            "1559000 1580093\n",
            "1560000 1580093\n",
            "1561000 1580093\n",
            "1562000 1580093\n",
            "1563000 1580093\n",
            "1564000 1580093\n",
            "1565000 1580093\n",
            "1566000 1580093\n",
            "1567000 1580093\n",
            "1568000 1580093\n",
            "1569000 1580093\n",
            "1570000 1580093\n",
            "1571000 1580093\n",
            "1572000 1580093\n",
            "1573000 1580093\n",
            "1574000 1580093\n",
            "1575000 1580093\n",
            "1576000 1580093\n",
            "1577000 1580093\n",
            "1578000 1580093\n",
            "1579000 1580093\n",
            "1580000 1580093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset name:\n",
        "\n",
        "```\n",
        "maximal-centaur-120203.stack_overflow_ir\n",
        "```"
      ],
      "metadata": {
        "id": "oUcSBRtUYNc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "currated_list = ['matplotlib', 'pandas', 'numpy', 'pytorch', \n",
        "                 'seaborn', 'jupyter-notebook', 'ipython', 'python-3.x', 'nlp', 'machine-learning']\n",
        "\n",
        "currated_ids = [7979, 67719, 4190, 124253, 99284, 116342, 14670, 60010, 2370, 5990]\n",
        "\n",
        "currated_irrelevant_list =['django', 'flask', 'javascript', \n",
        "                           'django-rest-framework', 'pyqt5', 'jinja2']\n",
        "\n",
        "# currated_irrelevant_ids = [get_tag_id(tag) for tag in currated_irrelevant_list]\n",
        "currated_irrelevant_ids = [243, 54712, 3, 81949, 94814, 20674]"
      ],
      "metadata": {
        "id": "ivoZW_rWX-IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_table_relevant_questions(currated_ids, currated_irrelevant_ids)"
      ],
      "metadata": {
        "id": "Ss8Xv6Q1jHOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_ids = load_answer_ids('/content/drive/My Drive/CS 685/Final Project/Data/questions_small.csv')\n",
        "download_answers(answer_ids)"
      ],
      "metadata": {
        "id": "0QWFcJpQsBP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_table_relevant_answers()"
      ],
      "metadata": {
        "id": "XuQyuTUaboLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_tag_id(\"machine-learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOj3JhjtWAJk",
        "outputId": "23e582c9-d509-4a7a-80fd-825075152091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The query data:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5990"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_post_by_id(4462952)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjrbHebeYlV5",
        "outputId": "cab3bd69-06d7-4e10-b89f-f2cec6deb6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('<python><debugging><winpdb>',), {'Tags': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(currated_irrelevant_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_LEExQpkFJF",
        "outputId": "a5c083d3-bd11-433b-c8e0-53e1400d9658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[243, 54712, 3, 81949, 94814, 20674]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selects posts based on whether they have a certain tag or not\n",
        "query = \"\"\"\n",
        "      WITH proper_ids AS (\n",
        "        WITH ids AS (\n",
        "          SELECT PostId, ARRAY_AGG(TagId) AS arr \n",
        "          FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "          GROUP BY PostId\n",
        "        )  \n",
        "        SELECT PostId \n",
        "        FROM ids \n",
        "        WHERE 16 IN UNNEST(ids.arr) \n",
        "        AND 243 NOT IN UNNEST(ids.arr) \n",
        "        AND 3 NOT IN UNNEST(ids.arr) \n",
        "      )\n",
        "\n",
        "      SELECT Title, Tags, Body FROM `sotorrent-org.2020_12_31.Posts`\n",
        "      JOIN proper_ids\n",
        "        ON proper_ids.PostId = `sotorrent-org.2020_12_31.Posts`.Id\n",
        "      WHERE `sotorrent-org.2020_12_31.Posts`.PostTypeId = 1\n",
        "      LIMIT 200;\n",
        "\"\"\"\n",
        "query_job = client.query(query)\n",
        "data = []\n",
        "for row in query_job:\n",
        "  print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IcmyGuqY0e_",
        "outputId": "a61dfa2b-5d8c-4fe5-cd33-eed78e3a6bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((\"How to use external python modules such as the module 'requests' when running executable python scripts such as .command files?\", '<python><python-3.x><python-requests><command><executable>', \"<p>I made a python script into an executable file by turning it into a .command file and adding the #!/usr/bin/env python3 on the first line of the file. </p>\\n\\n<p>When I double click to run the file, the file does run on the terminal, however the installed modules do not seem to be linked to the file. </p>\\n\\n<p>import requests\\nModuleNotFoundError: No module named 'requests'</p>\\n\\n<p>Is there a way to use external module such as the 'requests' module when running an executable form of a python script?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('pandas How to drop the whole row if any specific columns contains a specific values?', '<python><pandas>', '<p>I have a dataFrame like this:\\n<a href=\"https://i.stack.imgur.com/uPiBk.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\\n<p>I wonder how to drop the whole row if any specific columns contain a specific value?</p>\\n<p>For example, If columns Q1, Q2 or Q3 contain zero, delete the whole row. But if columns Q4 or Q5 contain zero, do not delete the row.</p>\\n<p><a href=\"https://i.stack.imgur.com/uPiBk.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"How can I capture realtime request url's to a local file with selenium using python\", '<python><python-3.x><selenium><selenium-webdriver><request>', '<p>I have a selenium script set up to open a particular website, the site requests multiple URL\\'s every 30 seconds and I need to somehow capture those requested URL and copy them to a file locally on my pc.</p>\\n<p>I\\'ve done lots of googling and found people recommending browsermob-proxy but it didn\\'t seem to fit my needs as I need to write the URL to a file in realtime. I\\'ll give an example photo in chrome\\'s network developer tool of what I am talking about that I need to have copied to a file.</p>\\n<p><a href=\"https://i.stack.imgur.com/gzsBw.jpg\" rel=\"nofollow noreferrer\">Example of the links I need to copy in realtime that happen every 30 seconds</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How can I disable a button in Python tkinter based on if there is text in the box or not?', '<python><python-3.x><user-interface><tkinter>', \"<p>I would like to ask, how can I change the state of a Button in Python Tkinter from DISABLED to NORMAL, based on if there is text in the entry box or not?</p>\\n<p>I have copied this code and I am trying to modify it for practice. Please feel free to run to make it simpler to understand my problem.</p>\\n<pre><code>import tkinter as tk\\nfrom tkinter import *\\n\\nbase = Tk()\\nbase.title(&quot;Lenny&quot;)\\nbase.geometry(&quot;600x700&quot;)\\nbase.resizable(width=FALSE, height=FALSE)\\n\\n#Create Chat window\\nChatLog = Text(base, bd=0, bg=&quot;white&quot;, height=&quot;8&quot;, width=&quot;50&quot;, font=&quot;Arial&quot;,)\\n\\nChatLog.config(state=DISABLED)\\n\\n#Bind scrollbar to Chat window\\nscrollbar = Scrollbar(base, command=ChatLog.yview, cursor=&quot;heart&quot;)\\nChatLog['yscrollcommand'] = scrollbar.set\\n\\n#Create Button to send message\\nSendButton = Button(base, font=(&quot;Segoe&quot;,12,'bold'), text=&quot;Send&quot;, width=&quot;12&quot;, height=5,\\n                    bd=0, bg=&quot;#C0C0C0&quot;, activebackground=&quot;#DCDCDC&quot;,fg='#000000',\\n                    command= send, state = NORMAL)\\n\\n#Create the box to enter message\\nEntryBox = Text(base, bd=0, bg=&quot;white&quot;,width=&quot;29&quot;, height=&quot;5&quot;, font=&quot;Arial&quot;)\\n\\n\\n#Place all components on the screen\\nscrollbar.place(x=580,y=6, height=600)\\nChatLog.place(x=6,y=6, height=600, width=578)\\nEntryBox.place(x=6, y=610, height=85, width=445)\\nSendButton.place(x=455, y=610, height=85)\\n\\nif (EntryBox.get(&quot;1.0&quot;,'end-1c').strip() == ''):\\n    SendButton['state'] = tk.DISABLED\\nelif EntryBox.get(&quot;1.0&quot;,'end-1c').strip() != '':\\n    SendButton['state'] = tk.NORMAL\\n\\ndef temp(event):\\n    print(EntryBox.get(&quot;1.0&quot;,'end-1c').strip() == '')\\n\\nbase.bind('&lt;Return&gt;', temp)\\n\\nbase.mainloop()\\n</code></pre>\\n<p>I have tried to achieve what I needed by using the if statement:</p>\\n<pre><code>if (EntryBox.get(&quot;1.0&quot;,'end-1c').strip() == ''):\\n    SendButton['state'] = tk.DISABLED\\nelif EntryBox.get(&quot;1.0&quot;,'end-1c').strip() != '':\\n    SendButton['state'] = tk.NORMAL\\n</code></pre>\\n<p>When the entry box is empty I want the send button to be disabled, and when I write text I want it to be enabled. Please ignore the 'def temp' function, I just wrote it to debug some stuff I had in mind.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Can you define aliases for imported modules in Python?', '<python><module><alias><python-import>', \"<p>In Python, is it possible to define an alias for an imported module?</p>\\n\\n<p>For instance:</p>\\n\\n<pre><code>import a_ridiculously_long_module_name\\n</code></pre>\\n\\n<p>...so that is has an alias of 'short_name'.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('What are the advantages of NumPy over regular Python lists?', '<python><arrays><list><numpy><numpy-ndarray>', '<p>What are the advantages of <a href=\"http://en.wikipedia.org/wiki/NumPy\" rel=\"noreferrer\">NumPy</a> over regular Python lists?</p>\\n\\n<p>I have approximately 100 financial markets series, and I am going to create a cube array of 100x100x100 = 1 million cells. I will be regressing (3-variable) each x with each y and z, to fill the array with standard errors.</p>\\n\\n<p>I have heard that for \"large matrices\" I should use NumPy as opposed to Python lists, for performance and scalability reasons. Thing is, I know Python lists and they seem to work for me. </p>\\n\\n<p>What will the benefits be if I move to NumPy?</p>\\n\\n<p>What if I had 1000 series (that is, 1 billion floating point cells in the cube)? </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Why a Python function copied from class access the class data from outside?', '<python>', '<p>How come function x can access the \"self\" of some object it\\'s not part of???\\nSee the following code:</p>\\n\\n<pre><code>#!/usr/bin/env python\\n\\nclass A(object):\\n  def __init__(self):\\n    self.a = 1\\n\\n  def doit(self):\\n    print self.a\\n\\na = A()\\nx = a.doit\\nx()\\n</code></pre>\\n\\n<p>See:</p>\\n\\n<pre><code>$ ./classes.py \\n1\\n$ \\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Showing 2 different graphs,', '<python><matplotlib><graph>', '<p>I try to create 2 graphs with the matplotlib, I have 2 functions called createAirGraph and createTempGraph. When I run the createAirGraph after the createTempGraph this is the result:</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/uUEj6.png\" alt=\"Picture\"></p>\\n\\n<p>I just want 2 seperate for windows, for each graph one window. </p>\\n\\n<p>I don\\'t understand why it is not creating a new object of \"GraphDisplay\" when I call createTempGraph after createAirGraph, wish there was something like a keyword \"new\" so it would be forced to do this.</p>\\n\\n<p>Python doesn\\'t seem to work/format well on stackoverflow; here is a pastebin of my complete code:\\n<a href=\"https://bpaste.net/show/MY7YU\" rel=\"nofollow noreferrer\">https://bpaste.net/show/MY7YU</a></p>\\n\\n<pre><code>class GraphDisplay:\\n\\n    def __init__(self, dates, data, ylbl, xlbl, titel, ):\\n            self.createGraph(dates,data,ylbl,xlbl,titel)\\n\\n    def createGraph(self,dates,data,ylbl,xlbl,titel):\\n        plt.plot_date(dates,data)\\n        plt.ylabel(ylbl)\\n        plt.xlabel(xlbl)\\n        plt.title(titel)\\n        plt.draw()\\n        plt.show()\\n\\n\\ndef main():\\n\\n    def createTempGraph(screen):\\n        stationname = screen.comboWeerstations.get()\\n        CSV_Reader = WeatherDataFiles()\\n        data = CSV_Reader.read_CSV(stationname)\\n        data = list(data)\\n        data.pop(2)\\n        data[0].pop(0)\\n        data[1].pop(0)\\n        dates = data[0]\\n        temperature = data[1]\\n        graph = GraphDisplay(dates, temperature,\"Temperatuur\",\"Datum\",stationname)\\n        return graph\\n    def createAirpGraph(screen):\\n        stationname = screen.comboWeerstations.get()\\n        CSV_Reader = WeatherDataFiles()\\n        data2 = CSV_Reader.read_CSV(stationname)\\n        data2 = list(data2)\\n        data2.pop(1)\\n        data2[0].pop(0)\\n        data2[1].pop(0)\\n        dates = data2[0]\\n        airpressure = data2[1]\\n        graph2 = GraphDisplay(dates, airpressure,\"Temperatuur\",\"Datum\",stationname) \\n        return graph2\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('I am importing data from csv file and trying to show as an image in python, but the image is not displaying correctly', '<python><matplotlib>', '<p>I have a csv file with 480x640 intensity values represented as floats.  It\\'s just one long column.</p>\\n\\n<p>In python I wanted to import that data and try to display it as an image. Here\\'s the best version I\\'ve come up with so far:</p>\\n\\n<pre><code>import math\\nimport pandas as pd\\nimport numpy as np\\nfrom PIL import Image\\n##import matplotlib\\nfrom matplotlib.pyplot import imshow\\nimport matplotlib.pyplot as plt\\n#visual one\\n#df = pd.read_csv(\\'93834016616704_DATA.csv\\', header=None) # read the training data file from working directory\\n#meter one93840538154878_DATA\\ndf = pd.read_csv(\\'235317464765230_DATA.csv\\', header=None) # read the training data file from working directory\\n\\ni = 3 # set any valid index of an image\\n##label = df.values[i][0] # retrieve label from first colum in dataframe\\n#im_buf = df.values[i][1:] # create flat array of only the pixels of the given image\\n#axis_len = int(math.sqrt(im_buf.shape[0])) # calculate the dimensions of the square image\\n\\nprint(\"df size\" + str(df.size.item()));\\n\\nim_array = np.int8(np.reshape(df.values, (480, 640))) # create a 2D array from flat array\\nim_array = im_array.transpose()\\nimg = Image.fromarray(im_array, \\'L\\') # convert to a PIL.Image object (\\'L\\' is for grayscale)\\n\\n#print(f\\'Label: {label}\\')\\nimshow(np.asarray(img))\\nplt.show()\\n</code></pre>\\n\\n<p>The result is the image is rotated by 90 degrees and also chopped and copied 4 times.  I\\'m not sure what I\\'m doing wrong.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('SQLAlchemy filter by upcoming birthday / annual anniversary', '<python><sqlalchemy><flask-sqlalchemy>', \"<p>Env: python 3.8, flask-sqlalchemy, postgres</p>\\n<pre><code>class User(db.Model):\\n    name = db.Column(db.Text)\\n    birthday = db.Column(db.DateTime)\\n\\n    @classmethod\\n    def upcoming_birthdays(cls):\\n        return (cls.query\\n                .filter(&quot;??&quot;)\\n                .all()\\n                )\\n</code></pre>\\n<p>I'd like to create a sqlalchemy query that filters users with an upcoming birthday within X number of days. I thought about using the <code>extract</code> function, to extract the month and day from the birthday, but that doesn't work for days at the end of the month or year. I also thought about trying to convert the birthday to a julian date for comparison, but I don't know how to go about that.</p>\\n<p>For example if today was August 30, 2020 it would return users with birthdays</p>\\n<ul>\\n<li>September 1 1995</li>\\n<li>August 31 2010 .... etc</li>\\n</ul>\\n<p>Thanks for your help</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How are nested dictionaries handled by DictWriter?', '<python><csv>', '<p>Using the CSV module in python, I was experimenting with the DictWriter class to convert dictionaries to rows in a csv. Is there any way to handle nested dictionaries?  Specifically, I\\'m exporting Disqus comments that have a structure like this:</p>\\n\\n<pre><code>{\\nu\\'status\\': u\\'approved\\', \\nu\\'forum\\': {u\\'id\\': u\\'\\', u\\'\\': u\\'\\', u\\'shortname\\': u\\'\\', u\\'name\\': u\\'\\', u\\'description\\': u\\'\\'}, \\nu\\'thread\\': {u\\'allow_comments\\': True, u\\'forum\\': u\\'\\', u\\'title\\': u\\'\\', u\\'url\\': u\\'\\', u\\'created_at\\': u\\'\\', u\\'id\\': u\\'\\', u\\'hidden\\': False, u\\'identifier\\': [], u\\'slug\\': u\\'\\'}, \\nu\\'is_anonymous\\': False, \\nu\\'author\\': {u\\'username\\': u\\'\\', u\\'email_hash\\': u\\'\\', u\\'display_name\\': u\\'\\', u\\'has_avatar\\': True, u\\'url\\': u\\'\\', u\\'id\\': 1, u\\'avatar\\': {u\\'small\\': u\\'\\', u\\'large\\': u\\'\\', u\\'medium\\': u\\'\\'}, u\\'email\\': u\\'\\'}, \\nu\\'created_at\\': u\\'2009-08-12T10:14\\', \\nu\\'points\\': 0, \\nu\\'message\\': u\"\", \\nu\\'has_been_moderated\\': False, \\nu\\'ip_address\\': u\\'\\', \\nu\\'id\\': u\\'\\', \\nu\\'parent_post\\': None\\n}\\n</code></pre>\\n\\n<p>I wanted to specify fields from the author and thread properties and haven\\'t found a way so far.  Here\\'s the code:</p>\\n\\n<pre><code>f = open(\\'export.csv\\', \\'wb\\')\\nfieldnames = (\\'id\\',\\'status\\',\\'is_anonymous\\',\\'created_at\\',\\'ip_address\\',\\'points\\',\\'has_been_moderated\\',\\'parent_post\\',\\'thread\\')\\ntry:\\n    exportWriter = csv.DictWriter(f,\\n        fieldnames,\\n        restval=None,\\n        extrasaction=\\'ignore\\',\\n        quoting=csv.QUOTE_NONNUMERIC\\n        )\\n\\n    for c in comments:\\n        exportWriter.writerow(c)\\n\\nfinally:\\n    f.close()\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('i18n translation with a different domain in .py files', '<python><internationalization><translation><plone>', \"<p>I'm a little confused on i18n translations in py files. I have a string where what needs to be translated is already in the plone domain in plone.pot so I want to specify the domain to be plone for that translation only. When I do the following, I get an error. And, this does get rendered in a page template so there's no need to call the translate function, is this correct?</p>\\n\\n<pre><code>    raise ValueError(_(u'Some string', domain='plone'))\\n\\n    TypeError: __call__() got an unexpected keyword argument 'domain'\\n</code></pre>\\n\\n<p>How should this be done? Thanks a lot!</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('obtain the decimal value from a hexadecimal string', '<python>', \"<p>I'm having some troubles converting a hexadecimal value to decimal. Theoretically is easy with <code>Python</code>:</p>\\n\\n<pre><code>value = '000100000001f8c65400fefe3195000001230000000000000000000000000000000000000000642b00090700000000001e'\\nprint(int(value,16))\\n</code></pre>\\n\\n<p>And this is the result:</p>\\n\\n<p><code>153914086775326342143664486282692693880080977757509806775956245674142536051238079779640236240803190331364310253598</code></p>\\n\\n<p>Since here all is ok.</p>\\n\\n<p>This string represents a payload of different bytes and I know two things:</p>\\n\\n<ul>\\n<li>1 byte = 8 bits.</li>\\n<li>Hexadecimal values are usually represented with two hexadecimal values, like <code>FF 2E 32 etc</code>.</li>\\n</ul>\\n\\n<p>The problem comes when I want to work with some concrete byte, because theoretically I know that in the byte 18, 19, 20 and 21 I have some decimal number that starts in 39 (I don't know the other numbers that follow). But when I want to decode it I can't find it.</p>\\n\\n<pre><code># First try\\na = value[36:43] # 18*2 to 21*2\\nprint(a)\\nprint(int(a,16))\\n\\n# Second try\\na = value[18:22] # 18 to 21\\nprint(a)\\nprint(int(a,16))\\n</code></pre>\\n\\n<p>With a naked eye, I can see that the third and fourth value in the first result is this <code>39</code>,</p>\\n\\n<p><code>153914086775326342143664486282692693880080977757509806775956245674142536051238079779640236240803190331364310253598</code></p>\\n\\n<p>But another time, if I do</p>\\n\\n<pre><code># third try\\na = value[2:4]\\nprint(a)\\nprint(int(a,16))\\n</code></pre>\\n\\n<p>I can't find this 39, and the values change from the first result.</p>\\n\\n<p>How I have to do it? I'm sure is easy but I don't know how to do it. I want to learn to access to the different bytes but I can't understand the logic.</p>\\n\\n<p><strong>EDIT trying to explain it better</strong></p>\\n\\n<p>I have this hexadecimal payload:</p>\\n\\n<p><code>153914086775326342143664486282692693880080977757509806775956245674142536051238079779640236240803190331364310253598</code></p>\\n\\n<p>And this represents the set of different values collected in bytes.</p>\\n\\n<p>Therefore, what I try is to be able to access a byte (or a set) to know what its value would be in decimal. For example, I know that byte 18 to 21 is the latitude and byte 39 the battery. How can I decode it with <code>python</code>?</p>\\n\\n<p>(In my city the latitude always starts in 39, that's what I said before this)</p>\\n\\n<p>Thank you very much</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('JupyterHub NonImplemented Error when everything appears correct', '<python><jupyter><jupyterhub>', '<p>So I am getting a NonImplemented error and I don\\'t know why. When I try to Google for it, all that comes up are errors for Jupyter, the downloaded version.</p>\\n\\n<pre><code>q1a_answer = .4818\\n\\n# YOUR CODE HERE\\nraise NotImplementedError()\\n</code></pre>\\n\\n<p>is my code and the error is</p>\\n\\n<pre><code>NotImplementedError                       Traceback (most recent call last)\\n&lt;ipython-input-2-6804eb83b16e&gt; in &lt;module&gt;\\n      2 \\n      3 # YOUR CODE HERE\\n----&gt; 4 raise NotImplementedError()\\n</code></pre>\\n\\n<p><a href=\"https://i.stack.imgur.com/ZKK7Y.png\" rel=\"nofollow noreferrer\">1</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('pyInstaller create execuable standalone linux', '<python><flask><bootstrap-4><pyinstaller>', '<p>I wrote a project using bootstrap, flask and python and used pyInstaller to generate the executable file following this link:\\n<a href=\"https://pyinstaller.readthedocs.io/en/stable/usage.html#using-pyinstaller\" rel=\"nofollow noreferrer\">https://pyinstaller.readthedocs.io/en/stable/usage.html#using-pyinstaller</a></p>\\n\\n<p>I then launched the following command:</p>\\n\\n<pre><code>pyinstaller -w -F --add-data \"templates:templates\" --add-data \"static:static\" app.py\\n</code></pre>\\n\\n<p>that created me a \"build\" directory at the end of the process, with the executable file inside. </p>\\n\\n<p>However, I noticed that in order to make it work properly, I still have to copy and paste all the project files into the \"build\" directory before launching the file.</p>\\n\\n<p>Is it possible to create a standalone file so that I don\\'t have to copy the whole source into the \"build\" directory?\\nthank you</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('I get an unexpected EOF error when trying to use Pyinstaller with Pandas. I do not know what is causing this', '<python><pandas><pyinstaller>', \"<p>When trying to compile a bigger program that uses multiple libraries, I ran into an EOF error. After some testing, I found that there was a issus between Pandas and Pyinstaller.</p>\\n<p>I boiled the code down to this:</p>\\n<pre><code>import pandas as pd\\ndata = pd.read_csv('matplotTEST.csv')\\nprint(data)\\n</code></pre>\\n<p>I ran the command:</p>\\n<pre><code>pyinstaller --onefile --clean testingPyinstaller.py\\n</code></pre>\\n<p>and got the following EOF error:</p>\\n<pre><code>D:\\\\Export\\\\BinGen&gt;pyinstaller --onefile --clean BinGenTopLevel.py\\n68 INFO: PyInstaller: 3.6\\n68 INFO: Python: 3.8.3\\n68 INFO: Platform: Windows-10-10.0.18362-SP0\\n69 INFO: wrote D:\\\\Export\\\\BinGen\\\\BinGenTopLevel.spec\\n71 INFO: UPX is not available.\\n71 INFO: Removing temporary files and cleaning cache in C:\\\\Users\\\\matth\\\\AppData\\\\Roaming\\\\pyinstaller\\n77 INFO: Extending PYTHONPATH with paths\\n['D:\\\\\\\\Export\\\\\\\\BinGen', 'D:\\\\\\\\Export\\\\\\\\BinGen']\\n77 INFO: checking Analysis\\n77 INFO: Building Analysis because Analysis-00.toc is non existent\\n77 INFO: Initializing module dependency graph...\\n80 INFO: Caching module graph hooks...\\n87 INFO: Analyzing base_library.zip ...\\n3135 INFO: Processing pre-find module path hook   distutils\\n3137 INFO: distutils: retargeting to non-venv dir 'c:\\\\\\\\users\\\\\\\\matth\\\\\\\\appdata\\\\\\\\local\\\\\\\\programs\\\\\\\\python\\\\\\\\python38-32\\\\\\\\lib'\\n6764 INFO: Caching module dependency graph...\\n6880 INFO: running Analysis Analysis-00.toc\\n6884 INFO: Adding Microsoft.Windows.Common-Controls to dependent assemblies of final executable\\n  required by c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\python.exe\\n7000 INFO: Analyzing D:\\\\Export\\\\BinGen\\\\BinGenTopLevel.py\\n8117 INFO: Processing pre-find module path hook   site\\n8118 INFO: site: retargeting to fake-dir 'c:\\\\\\\\users\\\\\\\\matth\\\\\\\\appdata\\\\\\\\local\\\\\\\\programs\\\\\\\\python\\\\\\\\python38-32\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\PyInstaller\\\\\\\\fake-modules'\\n9477 INFO: Processing pre-safe import module hook   setuptools.extern.six.moves\\n14584 INFO: Processing pre-safe import module hook   six.moves\\n23058 INFO: Processing module hooks...\\n23058 INFO: Loading module hook &quot;hook-distutils.py&quot;...\\n23061 INFO: Loading module hook &quot;hook-encodings.py&quot;...\\n23145 INFO: Loading module hook &quot;hook-lib2to3.py&quot;...\\n23153 INFO: Loading module hook &quot;hook-lxml.etree.py&quot;...\\n23155 INFO: Loading module hook &quot;hook-matplotlib.backends.py&quot;...\\n23743 INFO:   Matplotlib backend &quot;GTK3Agg&quot;: ignored\\n    backend Gtk3Agg requires cairo\\n24071 INFO:   Matplotlib backend &quot;GTK3Cairo&quot;: ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n24387 INFO:   Matplotlib backend &quot;MacOSX&quot;: ignored\\n    cannot import name '_macosx' from 'matplotlib.backends' (c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\__init__.py)\\n24703 INFO:   Matplotlib backend &quot;nbAgg&quot;: ignored\\n    No module named 'IPython'\\n25053 INFO:   Matplotlib backend &quot;Qt4Agg&quot;: ignored\\n    Failed to import any qt binding\\n25371 INFO:   Matplotlib backend &quot;Qt4Cairo&quot;: ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n25708 INFO:   Matplotlib backend &quot;Qt5Agg&quot;: ignored\\n    Failed to import any qt binding\\n26030 INFO:   Matplotlib backend &quot;Qt5Cairo&quot;: ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n26480 INFO:   Matplotlib backend &quot;TkAgg&quot;: added\\n26925 INFO:   Matplotlib backend &quot;TkCairo&quot;: ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n27244 INFO:   Matplotlib backend &quot;WebAgg&quot;: ignored\\n    Traceback (most recent call last):\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\backend_webagg.py&quot;, line 27, in &lt;module&gt;\\n    import tornado\\nModuleNotFoundError: No module named 'tornado'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File &quot;&lt;string&gt;&quot;, line 12, in &lt;module&gt;\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\backend_webagg.py&quot;, line 29, in &lt;module&gt;\\n    raise RuntimeError(&quot;The WebAgg backend requires Tornado.&quot;)\\nRuntimeError: The WebAgg backend requires Tornado.\\n27670 INFO:   Matplotlib backend &quot;WX&quot;: ignored\\n    No module named 'wx'\\n27990 INFO:   Matplotlib backend &quot;WXAgg&quot;: ignored\\n    No module named 'wx'\\n28306 INFO:   Matplotlib backend &quot;WXCairo&quot;: ignored\\n    No module named 'wx'\\n28626 INFO:   Matplotlib backend &quot;agg&quot;: added\\n28942 INFO:   Matplotlib backend &quot;cairo&quot;: ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n29399 INFO:   Matplotlib backend &quot;pdf&quot;: added\\n29828 INFO:   Matplotlib backend &quot;pgf&quot;: added\\n30160 INFO:   Matplotlib backend &quot;ps&quot;: added\\n30483 INFO:   Matplotlib backend &quot;svg&quot;: added\\n30909 INFO:   Matplotlib backend &quot;template&quot;: added\\n31167 INFO: Loading module hook &quot;hook-matplotlib.py&quot;...\\n31463 INFO: Loading module hook &quot;hook-numpy.core.py&quot;...\\n31565 INFO: Loading module hook &quot;hook-numpy.py&quot;...\\n31566 INFO: Loading module hook &quot;hook-pandas.py&quot;...\\n32299 INFO: Loading module hook &quot;hook-PIL.Image.py&quot;...\\n32774 INFO: Loading module hook &quot;hook-PIL.py&quot;...\\n32776 INFO: Excluding import 'PyQt4'\\n32779 INFO: Excluding import 'tkinter'\\n32781 INFO:   Removing import of tkinter from module PIL.ImageTk\\n32781 INFO: Import to be excluded not found: 'PySide'\\n32782 INFO: Import to be excluded not found: 'FixTk'\\n32782 INFO: Excluding import 'PyQt5'\\n32784 INFO:   Removing import of PyQt5 from module PIL.ImageQt\\n32784 INFO: Loading module hook &quot;hook-PIL.SpiderImagePlugin.py&quot;...\\n32786 INFO: Excluding import 'tkinter'\\n32787 INFO: Import to be excluded not found: 'FixTk'\\n32788 INFO: Loading module hook &quot;hook-pkg_resources.py&quot;...\\n33118 INFO: Processing pre-safe import module hook   win32com\\nTraceback (most recent call last):\\n  File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;\\nModuleNotFoundError: No module named 'win32com'\\n33175 INFO: Processing pre-safe import module hook   win32com\\nTraceback (most recent call last):\\n  File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;\\nModuleNotFoundError: No module named 'win32com'\\n33409 INFO: Excluding import '__main__'\\n33410 INFO:   Removing import of __main__ from module pkg_resources\\n33411 INFO: Loading module hook &quot;hook-pydoc.py&quot;...\\n33412 INFO: Loading module hook &quot;hook-pytz.py&quot;...\\n33474 INFO: Loading module hook &quot;hook-setuptools.py&quot;...\\n34016 INFO: Loading module hook &quot;hook-sqlalchemy.py&quot;...\\nTraceback (most recent call last):\\n  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\sqlalchemy\\\\__init__.py&quot;, line 12, in &lt;module&gt;\\n    from sqlalchemy.sql import (\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\sqlalchemy\\\\sql\\\\__init__.py&quot;, line 7, in &lt;module&gt;\\n    from sqlalchemy.sql.expression import (\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\sqlalchemy\\\\sql\\\\expression.py&quot;, line 32, in &lt;module&gt;\\n    from sqlalchemy import util, exc\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\sqlalchemy\\\\util\\\\__init__.py&quot;, line 7, in &lt;module&gt;\\n    from .compat import callable, cmp, reduce, defaultdict, py25_dict, \\\\\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\sqlalchemy\\\\util\\\\compat.py&quot;, line 202, in &lt;module&gt;\\n    time_func = time.clock\\nAttributeError: module 'time' has no attribute 'clock'\\nTraceback (most recent call last):\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\runpy.py&quot;, line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\runpy.py&quot;, line 87, in _run_code\\n    exec(code, run_globals)\\n  File &quot;C:\\\\Users\\\\matth\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38-32\\\\Scripts\\\\pyinstaller.exe\\\\__main__.py&quot;, line 7, in &lt;module&gt;\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\__main__.py&quot;, line 114, in run\\n    run_build(pyi_config, spec_file, **vars(args))\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\__main__.py&quot;, line 65, in run_build\\n    PyInstaller.building.build_main.main(pyi_config, spec_file, **kwargs)\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\building\\\\build_main.py&quot;, line 734, in main\\n    build(specfile, kw.get('distpath'), kw.get('workpath'), kw.get('clean_build'))\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\building\\\\build_main.py&quot;, line 681, in build\\n    exec(code, spec_namespace)\\n  File &quot;D:\\\\Export\\\\BinGen\\\\BinGenTopLevel.spec&quot;, line 6, in &lt;module&gt;\\n    a = Analysis(['BinGenTopLevel.py'],\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\building\\\\build_main.py&quot;, line 244, in __init__\\n    self.__postinit__()\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\building\\\\datastruct.py&quot;, line 160, in __postinit__\\n    self.assemble()\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\building\\\\build_main.py&quot;, line 422, in assemble\\n    self.graph.process_post_graph_hooks()\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\depend\\\\analysis.py&quot;, line 311, in process_post_graph_hooks\\n    module_hook.post_graph()\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\depend\\\\imphook.py&quot;, line 417, in post_graph\\n    self._load_hook_module()\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\depend\\\\imphook.py&quot;, line 383, in _load_hook_module\\n    self._hook_module = importlib_load_source(\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\compat.py&quot;, line 797, in importlib_load_source\\n    return mod_loader.load_module()\\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 462, in _check_name_wrapper\\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 962, in load_module\\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 787, in load_module\\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 265, in _load_module_shim\\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 702, in _load\\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 671, in _load_unlocked\\n  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 783, in exec_module\\n  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed\\n  File &quot;c:\\\\users\\\\matth\\\\appdata\\\\local\\\\programs\\\\python\\\\python38-32\\\\lib\\\\site-packages\\\\PyInstaller\\\\hooks\\\\hook-sqlalchemy.py&quot;, line 30, in &lt;module&gt;\\n    dialects = eval(dialects.strip())\\n  File &quot;&lt;string&gt;&quot;, line 0\\n\\n    ^\\nSyntaxError: unexpected EOF while parsing\\n</code></pre>\\n<p>Can anyone help me figure out what is causing this?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python - Google OAuth generate token from authorization code', '<python><oauth-2.0><google-cloud-functions><google-auth-library>', '<p>I have an python google cloud function which receives a OAuth authorization code as an argument. I want to exchange this code for a token which can be used to authenticate a service object.</p>\\n<p>The code is generated externally and passed to this function as a string arguement.</p>\\n<p>I\\'ve looked at the documentation for <a href=\"https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html\" rel=\"nofollow noreferrer\">google_auth_oauthlib.flow</a>. But it expects a flow object created to handle the auth. In my case I only have the code as the result.</p>\\n<p>How can I exchange a authorization code as string into a token?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Pandas Grouper - Why can't it handle numerical columns in order to bin data?\", '<python><pandas><pandas-groupby>', '<p>Why can pd.Grouper not handle binning?</p>\\n<p>Let me illustrate by example.\\nConsider</p>\\n<pre class=\"lang-py prettyprint-override\"><code>df = pd.DataFrame({\\'time\\': pd.date_range(pd.Timestamp(year=2020, month=10, day=20, hour=0), pd.Timestamp(year=2020, month=10, day=20, hour=23), freq=\\'1H\\'), \\'v0\\': np.arange(0,24), \\'v1\\': np.arange(100, 124)})\\n</code></pre>\\n<pre class=\"lang-py prettyprint-override\"><code>df\\n    time                v0  v1\\n0   2020-10-20 00:00:00 0   100\\n1   2020-10-20 01:00:00 1   101\\n2   2020-10-20 02:00:00 2   102\\n3   2020-10-20 03:00:00 3   103\\n4   2020-10-20 04:00:00 4   104\\n5   2020-10-20 05:00:00 5   105\\n6   2020-10-20 06:00:00 6   106\\n7   2020-10-20 07:00:00 7   107\\n8   2020-10-20 08:00:00 8   108\\n9   2020-10-20 09:00:00 9   109\\n10  2020-10-20 10:00:00 10  110\\n11  2020-10-20 11:00:00 11  111\\n12  2020-10-20 12:00:00 12  112\\n13  2020-10-20 13:00:00 13  113\\n14  2020-10-20 14:00:00 14  114\\n15  2020-10-20 15:00:00 15  115\\n16  2020-10-20 16:00:00 16  116\\n17  2020-10-20 17:00:00 17  117\\n18  2020-10-20 18:00:00 18  118\\n19  2020-10-20 19:00:00 19  119\\n20  2020-10-20 20:00:00 20  120\\n21  2020-10-20 21:00:00 21  121\\n22  2020-10-20 22:00:00 22  122\\n23  2020-10-20 23:00:00 23  123\\n</code></pre>\\n<p>The typical use case of pd.Grouper is to &quot;bin&quot; time:</p>\\n<pre class=\"lang-py prettyprint-override\"><code>df.groupby([pd.Grouper(key=&quot;time&quot;, freq=&quot;8H&quot;)]).agg({\\'v1\\': \\'sum\\'})\\n    \\n    time                v1\\n0   2020-10-20 00:00:00 828\\n1   2020-10-20 08:00:00 892\\n2   2020-10-20 16:00:00 956\\n</code></pre>\\n<p>I can achieve similar output by using np.digitize:</p>\\n<pre class=\"lang-py prettyprint-override\"><code>bins = np.arange(df.v0.min(), df.v0.max(), 8)\\ndf.groupby(np.digitize(df.v0, bins)).agg({\\'v1\\': \\'sum\\'})\\n\\n    v1\\n1   828\\n2   892\\n3   956\\n\\n</code></pre>\\n<p>My question is, why can\\'t i achieve the binning of column v0 with pd.Grouper? So,</p>\\n<pre class=\"lang-py prettyprint-override\"><code>df.groupby([pd.Grouper(key=&quot;v0&quot;, freq=8)]).agg({\\'v1\\': \\'sum\\'})\\n \\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How can I import a package using __import__() when the package name is only known at runtime?', '<python><python-import>', '<p>I have a messages folder(package) with <code>__init__.py</code> file and another module <code>messages_en.py</code> inside it. In <code>__init__.py</code> if I import <code>messages_en</code> it works, but <code>__import__</code> fails with \"ImportError: No module named messages_en\"</p>\\n\\n<pre><code>import messages_en # it works\\nmessages = __import__(\\'messages_en\\') # it doesn\\'t ?\\n</code></pre>\\n\\n<p>I used to think \\'import x\\' is just another way of saying <code>__import__(\\'x\\')</code></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Why am I getting this DCPError?', '<python><cvxpy><quadratic-programming>', '<p>I\\'m trying to optimize a binary portfolio vector to be greater than a benchmark using CVXPY.</p>\\n<pre class=\"lang-py prettyprint-override\"><code>import cvxpy as cp\\nimport numpy as np\\n\\n# Generate a random non-trivial quadratic program.\\n\\nn = 10 # number of options\\n\\nnp.random.seed(1)\\nmu = np.random.randn(n) # expected means\\nvar_covar = np.random.randn(n,n) # variance-covariance matrix\\nvar_covar = var_covar.T.dot(var_covar) # cont\\'d\\nbench_cov = np.random.randn(n) # n-length vector of cov(benchmark, returns)\\n\\nlamd = 0.01 # risk tolerance\\n\\n# Define and solve the CVXPY problem.\\n\\nx = cp.Variable(n, boolean=True)\\n\\nprob = cp.Problem(cp.Maximize(mu.T@x + lamd * (cp.quad_form(x, var_covar) - (2 * bench_cov.T@x))), [cp.sum(x) == 4])\\n\\nprob.solve()\\n</code></pre>\\n<p>I get this error using CVXPY version 1.1.0a0 (downloaded directly from github):</p>\\n<blockquote>\\n<p><strong>DCPError</strong>: Problem does not follow DCP rules. Specifically:</p>\\n<p>The objective is not DCP, even though each sub-expression is.</p>\\n<p>You are trying to maximize a function that is convex.</p>\\n</blockquote>\\n<p>From what I\\'ve read maximizing a convex function is very difficult, but I got this equation from a paper. I figure I must be doing something wrong as I\\'m new to quadratic programming and CVXPY.</p>\\n<p>Thank you!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('The HTML that python requests (and urllib) is not giving the same HTML as the original', '<python><html><python-requests><python-requests-html>', '<p>I am trying to create a \"Price Comparison\" python script. I am using \\'\\'\\'request\\'\\'\\' and \\'\\'\\'Beautiful Soup\\'\\'\\' to get the price.</p>\\n\\n<p>But it doesn\\'t give the same HTML as the original. I\\'ve tried to use headers, and I\\'ve tried to use urllib but still don\\'t work.</p>\\n\\n<p>Any help will be helpful. Thank you in advanced</p>\\n\\n<pre><code>import requests\\nfrom bs4 import BeautifulSoup\\n\\nheaders = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\"}\\n\\nresponse = requests.get(\"https://www.lazada.com.ph/products/rubiks-cube-i122835501-s127979620.html\", headers=headers, timeout=5, allow_redirects=True)\\n\\nsoup = BeautifulSoup(response.content, \"lxml\")\\n\\nprice = soup.find(\"span\", {\"class\": \"pdp-product-price\"})\\n\\nprint(price) #Output is None\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Train DL model using tf.data.Dataset', '<python><tensorflow><machine-learning><keras><deep-learning>', '<p>I\\'m trying to do a simple Deep Learning task to learn how to use Tensorflow (and especially its Dataset tool). The task is the following : training a model which can tell if the sum of a given sequence of floats (length is fixed) is positive (labelled as 1) or negative (labelled as 0). </p>\\n\\n<p>I did the following without using tf.data.Dataset and it works well.</p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>def get_rand_seq():\\n    return [rand.uniform(-1, 1) for _ in range(6)]\\n\\nn = 1000\\nX = np.array([get_rand_seq() for _ in range(n)])\\ny = np.array([0 if sum(seq) &lt; 0 else 1 for seq in X])\\n\\nmodel = tf.keras.models.Sequential()\\nmodel.add(tf.keras.layers.Dense(16, input_shape=(6, ), activation=\\'relu\\'))\\nmodel.add(tf.keras.layers.Dense(4, activation=\\'relu\\'))\\nmodel.add(tf.keras.layers.Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\', metrics=[\\'acc\\'])\\n\\nmodel.fit(X, y, epochs=10, batch_size=4)\\n</code></pre>\\n\\n<p>Still, when I\\'m trying to do the same using a tf.data.Dataset input, I\\'m getting an error at the training step <code>model.fit(...)</code>\\nHere is my code :</p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>ds_X = tf.data.Dataset.from_tensor_slices(X)\\nds_y = tf.data.Dataset.from_tensor_slices(y)\\nds = tf.data.Dataset.zip((ds_X, ds_y))\\n\\nmodel = tf.keras.models.Sequential()\\nmodel.add(tf.keras.layers.Dense(16, input_shape=(6, ), activation=\\'relu\\'))\\nmodel.add(tf.keras.layers.Dense(4, activation=\\'relu\\'))\\nmodel.add(tf.keras.layers.Dense(1, activation=\\'sigmoid\\'))\\nmodel.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\', metrics=[\\'acc\\'])\\n\\nmodel.fit(ds, epochs=10, batch_size=4)\\n</code></pre>\\n\\n<p>I get the following error :</p>\\n\\n<pre><code>ValueError: Input 0 of layer sequential_5 is incompatible with the layer: expected axis -1 of input shape to have value 6 but received input with shape [6, 1]\\n</code></pre>\\n\\n<p>Even changing the input_shape to (6, 1) doesn\\'t make it worked. </p>\\n\\n<p>Is there a kind soul to enlighten a lost sheep like me ?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How can I read english.pickle file from nltk module?', '<python><nlp><pickle>', \"<p>I am trying to figure out why I cant read the contents of the english.pickle file downloaded from nltk module.</p>\\n<p>I first downloaded the nltk file using this code:</p>\\n<pre><code>import nltk\\nnltk.download('punkt')\\n</code></pre>\\n<p>I then looked for inside the punkt file that I have on my home directory and found english.pickle file. I used the following code to read the file in python:</p>\\n<pre><code>import pickle\\nwith open('english.pickle', 'rb') as file:\\n    x = pickle.load(file)\\n</code></pre>\\n<p>It all seemed fine, however, when I am running the variable x (which should be storing the pickled data) i am unable to retrieve the data from as I would from any other pickled file.</p>\\n<p>Instead I am only getting the object name and the id:</p>\\n<pre><code>&lt;nltk.tokenize.punkt.PunktParameters at 0x7f86cf6c0cd0&gt;\\n</code></pre>\\n<p>The problem is I need to access the content of the file and I cant iterate through as it is not iterable.</p>\\n<p>Has anyone encountered the same problem?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How can I get more information on Python unexpected SIGABRT?', '<python><python-3.x><macos><sigabrt>', \"<p>I'm using:</p>\\n\\n<ol>\\n<li>MacOS Catalina, version 10.15 (19A603).</li>\\n<li>python 3.7.4</li>\\n<li>pip3</li>\\n</ol>\\n\\n<p>Running and Debugging the following Python code within venv:</p>\\n\\n<pre><code>import jose\\nprint(jose)\\nfrom jose import jwt\\ntoken = jwt.encode({'key': 'value'}, 'secret', algorithm='HS256')\\nprint(token)\\n</code></pre>\\n\\n<p>results with the following error:</p>\\n\\n<p><strong>Process finished with exit code 134 (interrupted by signal 6: SIGABRT)</strong></p>\\n\\n<p>the specific line is: from jose import jwt.</p>\\n\\n<p>How can I get more information towards solving that problem.</p>\\n\\n<p>My pip freeze of venv:</p>\\n\\n<pre><code>Active-Alchemy==1.0.0\\nalembic==1.2.1\\naniso8601==8.0.0\\nanyjson==0.3.3\\nappnope==0.1.0\\narrow==0.15.2\\nasn1crypto==0.24.0\\nattrdict==2.0.0\\nattrs==19.3.0\\nauth0-python==3.1.2\\nbackcall==0.1.0\\nbcrypt==3.1.7\\nbeautifulsoup4==4.8.1\\nbleach==3.1.0\\nboto3==1.10.2\\nbotocore==1.13.2\\ncachetools==3.1.1\\ncertifi==2019.9.11\\ncffi==1.11.5\\nchardet==3.0.4\\nClick==7.0\\nconfigparser==4.0.2\\ncrypto==1.4.1\\ncryptography==2.4.2\\ncssselect==1.1.0\\ncytoolz==0.9.0.1\\ndecorator==4.3.0\\ndefusedxml==0.6.0\\ndjango-dotenv==1.4.2\\ndnspython==1.16.0\\ndocutils==0.15.2\\nEasyProcess==0.2.7\\necdsa==0.13\\nemoji==0.4.5\\nentrypoints==0.3\\neth-abi==1.2.2\\neth-account==0.3.0\\neth-hash==0.2.0\\neth-keyfile==0.5.1\\neth-keys==0.2.0b3\\neth-rlp==0.1.2\\neth-typing==1.3.0\\neth-utils==1.2.2\\neventlet==0.25.1\\nfacebook-sdk==2.0.0\\nfeedparser==5.2.1\\nFlask==1.1.1\\nflask-restplus==0.13.0\\nFlask-SQLAlchemy==2.4.1\\nforex-python==1.5\\nfuture==0.16.0\\ngevent==1.4.0\\ngoogle-api-python-client==1.6.3\\ngoogle-auth==1.6.3\\ngoogle-auth-httplib2==0.0.3\\ngreenlet==0.4.15\\ngunicorn==19.9.0\\nhexbytes==0.1.0\\nhttplib2==0.10.3\\nidna==2.5\\nimportlib-metadata==0.23\\ninflection==0.3.1\\nipykernel==5.1.3\\nipython==7.8.0\\nipython-genutils==0.2.0\\nipywidgets==7.5.1\\niso3166==0.8\\niso8601==0.1.12\\nitsdangerous==1.1.0\\njedi==0.15.1\\nJinja2==2.10.3\\njmespath==0.9.4\\njoblib==0.14.0\\njsonpickle==0.9.5\\njsonrpclib==0.1.7\\njsonschema==3.1.1\\njupyter-client==5.3.4\\njupyter-core==4.6.1\\nlogstash-formatter==0.5.17\\nlru-dict==1.1.6\\nlxml==4.4.1\\nMako==1.0.7\\nMarkupSafe==1.0\\nmistune==0.8.4\\nmonotonic==1.5\\nmore-itertools==7.2.0\\nmysqlclient==1.4.4\\nNaked==0.1.31\\nnbconvert==5.6.1\\nnbformat==4.4.0\\nnltk==3.4.5\\nnotebook==6.0.1\\nnumpy==1.17.3\\noauth2client==4.1.2\\norderedset==2.0.1\\nPaginator==0.5.1\\npandas==0.25.2\\npandocfilters==1.4.2\\nparsimonious==0.8.1\\nparso==0.5.1\\npasslib==1.7.1\\npexpect==4.7.0\\npg8000==1.10.2\\npickleshare==0.7.5\\nprometheus-client==0.7.1\\nprompt-toolkit==2.0.10\\npsycopg2==2.7.3\\npsycopg2-binary==2.8.4\\nptyprocess==0.6.0\\npy==1.7.0\\npy4j==0.10.8.1\\npyasn1==0.3.3\\npyasn1-modules==0.1.1\\npycountry==19.8.18\\npycparser==2.19\\npycryptodome==3.7.0\\nPygments==2.4.2\\nPyJWT==1.6.1\\nPyMySQL==0.6.6\\nPyro4==4.77\\npyrsistent==0.15.4\\npyscreenshot==0.5.1\\npython-dateutil==2.6.1\\npython-editor==1.0.3\\npython-jose==3.0.1\\npython-logstash==0.4.6\\npytz==2017.2\\nPyVirtualDisplay==0.2.4\\nPyYAML==3.13\\npyzmq==18.1.0\\nqgrid==1.1.1\\nredis==3.3.11\\nrequests==2.22.0\\nrequests-file==1.4.2\\nretry==0.9.2\\nretrying==1.3.3\\nrlp==1.0.3\\nrq==1.1.0\\nrsa==4.0\\ns3transfer==0.2.1\\nscrypt==0.8.6\\nSend2Trash==1.5.0\\nsentry-sdk==0.13.0\\nserpent==1.28\\nshellescape==3.4.1\\nsimplejson==3.11.1\\nsix==1.12.0\\nsnowplow-analytics-sdk==0.2.3\\nsoupsieve==1.9.4\\nSQLAlchemy==1.2.14\\nSQLAlchemy-Utils==0.34.2\\nsqlitedict==1.6.0\\nstatsd==3.3.0\\nterminado==0.8.2\\ntestpath==0.4.2\\ntextblob==0.15.3\\ntldextract==2.1.0\\ntoolz==0.9.0\\ntornado==6.0.3\\ntqdm==4.36.1\\ntraitlets==4.3.3\\nuritemplate==3.0.0\\nurllib3==1.21.1\\nwcwidth==0.1.7\\nweb3==4.8.1\\nwebencodings==0.5.1\\nwebsockets==6.0\\nWerkzeug==0.16.0\\nwidgetsnbextension==3.5.1\\nzipp==0.6.0\\n</code></pre>\\n\\n<p>___________________How did I solve it evantually _____________________\\nWrote a script that installed the dependencies one by one and try to run the script after each dependency installment. </p>\\n\\n<p>Found out that it throws after asn1crpto installed.</p>\\n\\n<p>Tried to install asn1cyrpto and jose at first it worked.</p>\\n\\n<p>Then, re-run the script when jose and asn1crypto are already installed and found out that when cryptography installed it throws again.</p>\\n\\n<p>tried to search for cryptography + asn1crypto related problems, updated asn1crypto 0.24.0 -> 1.0.0 and it worked.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Error training RNN with pytorch : RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn', '<python><deep-learning><pytorch><recurrent-neural-network>', '<p>Helo everyone, I am trying to create a model using the PyTorch <code>RNN</code> class and to train this model using minibatches. My dataset is a simple timeserie (one input one output). Here is what my model looks like : </p>\\n\\n<pre><code>class RNN_pytorch(nn.Module):\\n    def __init__(self, input_size, hidden_size, output_size):\\n        super(RNN_pytorch, self).__init__()\\n\\n        self.hidden_size = hidden_size\\n        self.input_size = input_size\\n\\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1)\\n        self.linear =  nn.Linear(hidden_size, output_size)\\n\\n    def forward(self, x, hidden):\\n\\n        batch_size = x.size(1)\\n#         print(batch_size)\\n        hidden = self.init_hidden(batch_size)\\n\\n        out, hidden = self.rnn(x, hidden)\\n#         out = out.view(out.size(1), out.size(2))\\n        print(\"Input linear : \", out.size())\\n        out = self.linear(out)\\n\\n        return out, hidden\\n\\n    def init_hidden(self, batch_size):\\n\\n        hidden = torch.zeros(1, batch_size, self.hidden_size)\\n#         print(hidden.size())\\n\\n        return hidden\\n</code></pre>\\n\\n<p>Then I process my dataset and split it like so : </p>\\n\\n<pre><code>batch_numbers = 13\\nbatch_size = int(len(train_signal[:-1])/batch_numbers)\\nprint(\"Train sample total size =\", len(train_signal[:-1]))\\nprint(\"Number of batches = \", batch_numbers)\\nprint(\"Size of batches = {} (train_size / batch_numbers)\".format(batch_size))\\n\\ntrain_signal_batched = train_signal[:-1].reshape(batch_numbers, batch_size, 1)\\ntrain_label_batched = train_signal[1:].reshape(batch_numbers, batch_size, 1)\\n\\nprint(\"X_train shape =\", train_signal_batched.shape)\\nprint(\"Y_train shape =\", train_label_batched.shape)\\n</code></pre>\\n\\n<p>Returning :</p>\\n\\n<pre><code>Train sample total size = 829439\\nNumber of batches =  13\\nSize of batches = 63803 (train_size / batch_numbers)\\nX_train shape = (13, 63803, 1)\\nY_train shape = (13, 63803, 1)\\n</code></pre>\\n\\n<p>So far so good, but then I try to train my model : </p>\\n\\n<pre><code>rnn_mod = RNN_pytorch(1, 16, 1)\\n\\ncriterion = nn.MSELoss()\\noptimizer = torch.optim.RMSprop(rnn_mod.parameters(), lr=0.01)\\n\\nn_epochs = 3\\nhidden = rnn_mod.init_hidden(batch_size)\\nfor epoch in range(1, n_epochs):\\n    for i, batch in enumerate(train_signal_batched):\\n        optimizer.zero_grad()\\n        x = torch.Tensor([batch]).float()\\n        print(\"Input : \",x.size())\\n        out, hidden = rnn_mod.forward(x, hidden)\\n        print(\"Output : \",out.size())\\n        label = torch.Tensor([train_label_batched[i]]).float()\\n        print(\"Label : \", label.size())\\n        loss = criterion(output, label)\\n        print(\"Loss : \", loss)\\n        loss.backward(retain_graph=True)\\n        optimizer.step()\\n        print(\"*\", end=\"\")\\n\\n#     if epoch % 100 == 0:\\n    print(\"Step {} --- Loss {}\".format(epoch, loss))\\n</code></pre>\\n\\n<p>Which leads to the error : </p>\\n\\n<pre><code>Input :  torch.Size([1, 63803, 1])\\nInput linear :  torch.Size([1, 63803, 16])\\nOutput :  torch.Size([1, 63803, 1])\\nLabel :  torch.Size([1, 63803, 1])\\nLoss :  tensor(0.0051)\\n\\n/home/kostia/.virtualenvs/machine-learning/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 63803, 1])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\\n  return F.mse_loss(input, target, reduction=self.reduction)\\n\\n---------------------------------------------------------------------------\\nRuntimeError                              Traceback (most recent call last)\\n&lt;ipython-input-217-d019358438ff&gt; in &lt;module&gt;\\n     17         loss = criterion(output, label)\\n     18         print(\"Loss : \", loss)\\n---&gt; 19         loss.backward(retain_graph=True)\\n     20         optimizer.step()\\n     21         print(\"*\", end=\"\")\\n\\n~/.virtualenvs/machine-learning/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\\n    116                 products. Defaults to ``False``.\\n    117         \"\"\"\\n--&gt; 118         torch.autograd.backward(self, gradient, retain_graph, create_graph)\\n    119 \\n    120     def register_hook(self, hook):\\n\\n~/.virtualenvs/machine-learning/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\\n     91     Variable._execution_engine.run_backward(\\n     92         tensors, grad_tensors, retain_graph, create_graph,\\n---&gt; 93         allow_unreachable=True)  # allow_unreachable flag\\n     94 \\n     95 \\n\\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\\n</code></pre>\\n\\n<p>Can anyone tell me what is the problem here because I honestly doesn\\'t have a clue ?</p>\\n\\n<p>Thanks in advance</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Need to plot pytorch 2d tensor's [0, 0] object against loss value\", '<python><pytorch><linear-regression>', '<p>I need a plot like this:</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/5OIl5.png\" alt=\"/\\\\w/ with a tangent in the first upslope in the w\"></p>\\n\\n<p>Here is my Code</p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>new_weights_tensor = w.clone()\\n\\nweights_x = [new_weights_tensor[0, 0].item()]\\nloss_y = [float(loss.detach().numpy())]\\n\\nfor i in range(0, 10):\\n    new_weights_tensor = new_weights_tensor.clone()\\n    new_weights_tensor[0, 0] = (new_weights_tensor[0, 0] + 0.01)\\n    pred = model(inputs, new_weights_tensor)\\n    new_loss = mse(pred, targets)\\n\\n    weights_x.append(new_weights_tensor[0, 0].item())\\n    loss_y.append(new_loss.item())\\n\\n# print(weights_x)\\n# print(loss_y)\\n\\nplt.plot(weights_x, loss_y)\\nplt.show()\\n</code></pre>\\n\\n<p>But i m getting this instead:</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/BaS2s.png\" alt=\"Downward sloping line\"></p>\\n\\n<p>This is the link for tutorial which i am following\\n<a href=\"https://jovian.ml/aakashns/02-linear-regression\" rel=\"nofollow noreferrer\">https://jovian.ml/aakashns/02-linear-regression</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('DataClassJsonMixin.from_dict leaves nested dict as a dict', '<python><python-dataclasses>', '<p>In file <code>nested.py</code> I have</p>\\n<pre><code>import typing as t\\n\\nfrom dataclasses import dataclass\\nfrom dataclasses_json import DataClassJsonMixin\\n\\n\\n@dataclass\\nclass B(DataClassJsonMixin):\\n    b_val: int\\n\\n\\n@dataclass\\nclass A(DataClassJsonMixin):\\n    val: t.Union[str, B]\\n\\n</code></pre>\\n<p>Now if I run this script</p>\\n<pre><code>import nested\\n\\na = nested.A(nested.B(42))\\nprint(f&quot;a.val {a.val} has type {type(a.val)}&quot;)\\nd = a.to_dict()\\nprint(f&quot;d is {d}&quot;) \\nnew_a = nested.A.from_dict(d)\\nprint(f&quot;new_a.val {new_a.val} has type {type(new_a.val)}&quot;)\\n\\n</code></pre>\\n<p>I get</p>\\n<p><code>a.val B(b_val=42) has type &lt;class \\'nested.B\\'&gt; </code></p>\\n<p><code>d is {\\'val\\': {\\'b_val\\': 42}} </code></p>\\n<p><code>new_a.val {\\'b_val\\': 42} has type &lt;class \\'dict\\'&gt; </code></p>\\n<p>I took a look at <code>dataclasses-json</code> and seems to be giving up <a href=\"https://github.com/lidatong/dataclasses-json/blob/3dc59e01ccdfec619ee4e4c3502b9759b67c3fa8/dataclasses_json/core.py#L278\" rel=\"nofollow noreferrer\">here</a>.</p>\\n<p>Can we not have unions of non-primitive types in <code>DataClassJsonMixin</code>?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Adding Vertical Rectangles to Plotly Subplots Without Using Plotly Express', '<python><plotly><plotly-python>', '<p>I\\'m trying to create shaded areas that correspond to different date ranges in a plotly chart that has subplots.</p>\\n<p>Ideally I\\'d like for each shaded rectangle to be suitably fitted to each subplot, but I\\'m finding this difficult.  Here\\'s some sample code:</p>\\n<pre><code>import pandas as pd\\nimport numpy as np\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nfrom plotly.subplots import make_subplots\\n\\ndf = pd.DataFrame({\\'A\\': list(range(25)),\\n                   \\'B\\': list(range(25, 50)),\\n                   \\'C\\': list(range(50, 75))}, index=pd.date_range(\\'20200101\\', periods=25))\\n\\nfig = make_subplots(rows=3, cols=1)\\n\\nfor idx, col in enumerate(df.columns):\\n    fig.add_trace(go.Scatter(x=df.index, y=df[col]), row=idx + 1, col=1)\\n\\nshape_dict = {\\'type\\':\\'rect\\', \\'xref\\':\\'x\\', \\'yref\\':\\'paper\\', \\'x0\\':\\'2020-01-03\\', \\'x1\\':\\'2020-01-12\\', \\'y0\\':0, \\'y1\\':1, \\'fillcolor\\': \\'LightSalmon\\', \\'layer\\': \\'below\\', \\'opacity\\': 0.25, \\'line_width\\': 0}\\n</code></pre>\\n<p>If I do <code>fig.update_layout(shapes=[shape_dict])</code>, then I get this:</p>\\n<p><a href=\"https://i.stack.imgur.com/7P3tN.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/7P3tN.jpg\" alt=\"enter image description here\" /></a></p>\\n<p>Not too bad, but I\\'d prefer to have each of these shapes fitted separately into their own subplot.</p>\\n<p>When I try doing this with <code>add_shape</code>, the shaded area loses its scaling:</p>\\n<pre><code>for idx, col in enumerate(df.columns):\\n    fig.add_trace(go.Scatter(x=df.index, y=df[col]), row=idx + 1, col=1)\\n    fig.add_shape(shape_dict, row=idx + 1, col=1)\\n</code></pre>\\n<p>And that gives me this:</p>\\n<p><a href=\"https://i.stack.imgur.com/WPG2B.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/WPG2B.jpg\" alt=\"enter image description here\" /></a></p>\\n<p>I would prefer <strong>not</strong> to have to re-calculate axes individually.</p>\\n<p>I also can\\'t access <code>add_vrect</code> -- I\\'m not sure why, but it\\'s not available as a method, and I also can\\'t use <code>plotly.express</code>, and most of the plot.ly\\'s documentation uses the <code>px</code> charts and their methods to do what I\\'m describing.</p>\\n<p><strong>EDIT</strong></p>\\n<p>To respond to the answer below, <code>add_vrect</code> does not work on my version of plotly, which is 4.12.0.</p>\\n<p>For example the sample code in <code>r-beginners</code> returns me this:</p>\\n<pre><code>df = pd.DataFrame({\\'A\\': list(range(25)),\\n                   \\'B\\': list(range(25, 50)),\\n                   \\'C\\': list(range(50, 75))}, index=pd.date_range(\\'20200101\\', periods=25))\\n\\nfig = make_subplots(rows=3, cols=1)\\n\\nfor idx, col in enumerate(df.columns):\\n    fig.add_trace(go.Scatter(x=df.index, y=df[col]), row=idx + 1, col=1)\\n\\n# shape_dict = {\\'type\\':\\'rect\\', \\'xref\\':\\'x\\', \\'yref\\':\\'paper\\', \\'x0\\':\\'2020-01-03\\', \\'x1\\':\\'2020-01-12\\', \\'y0\\':0, \\'y1\\':1, \\'fillcolor\\': \\'LightSalmon\\', \\'layer\\': \\'below\\', \\'opacity\\': 0.25, \\'line_width\\': 0}\\n# fig.update_layout(shapes=[shape_dict])\\n\\nfig.add_vrect(\\n    x0=&quot;2020-01-03&quot;, x1=&quot;2020-01-12&quot;,\\n    y0=0, y1=1,\\n    fillcolor=&quot;LightSalmon&quot;, opacity=0.25,\\n    layer=&quot;below&quot;, line_width=0)\\n\\nfig.show()\\n</code></pre>\\n<p>Returns the error message:  <code>AttributeError: \\'Figure\\' object has no attribute \\'add_vrect\\'</code></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('error says \\\\\\\\\\\\\\\\Ref\\\\\\\\builds/out exists but it doesnt exist', '<python><shutil>', '<p>I am trying to copy a source code tree using the below code and running into an error,am not sure why I am getting this?error says \\\\\\\\Ref\\\\builds/out exists but it doesnt exist,\"out\" is the directory the source location that the script is trying to copy to destination,any other ways to do copy if shutil is not suited for this type of copy?</p>\\n\\n<pre><code>//local/mnt/workspace/04.01_HY11/out\\n\\\\\\\\Ref\\\\builds/out\\ncopying\\nTraceback (most recent call last):\\n  File \"test.py\", line 21, in &lt;module&gt;\\n    main()\\n  File \"test.py\", line 18, in main\\n    copytree(src,dst)\\n  File \"test.py\", line 11, in copytree\\n    shutil.copytree(s, d)\\n  File \"/pkg/qct/software/python/2.5.2/.amd64_linux26/lib/python2.5/shutil.py\", line 110, in copytree\\n    os.makedirs(dst)\\n  File \"/pkg/qct/software/python/2.5.2/.amd64_linux26/lib/python2.5/os.py\", line 171, in makedirs\\n    mkdir(name, mode)\\nOSError: [Errno 17] File exists: \\'\\\\\\\\\\\\\\\\Ref\\\\\\\\builds/out\\'\\n</code></pre>\\n\\n<p>Python code</p>\\n\\n<pre><code>import os,shutil\\n\\ndef copytree(src, dst, symlinks=False, ignore=None):\\n    for item in os.listdir(src):\\n        s = os.path.join(src, item)\\n        print s\\n        d = os.path.join(dst, item)\\n        print d\\n        if os.path.isdir(s):\\n            print \"copying\"\\n            shutil.copytree(s, d, symlinks, ignore)\\n        else:\\n            shutil.copy2(s, d)\\ndef main ():\\n    src=\"//local/mnt/workspace/04.01_HY11\"\\n    dst=\"\\\\\\\\\\\\\\\\Ref\\\\\\\\builds\"\\n    copytree(src,dst)\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Introspection of dir()', '<python>', \"<p>If I do a <code>dir</code> of the <code>object</code>, I get the following:</p>\\n\\n<pre><code>&gt;&gt;&gt; dir(object)\\n['__class__', '__delattr__', '__doc__', '__format__', '__getattribute__', \\n '__hash__', '__init__', '__new__', '__reduce__', '__reduce_ex__', \\n'__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\\n</code></pre>\\n\\n<p>But it also contains other methods that are not included, for example:</p>\\n\\n<pre><code>&gt;&gt;&gt; object.__name__\\n'object'\\n\\n&gt;&gt;&gt; object.__module__\\n'__builtin__'\\n</code></pre>\\n\\n<p>I know this above example is quite trivial, but my question is why doing <code>dir</code> doesn't show <strong>all</strong> available methods for that object? Where does it do a fallback to if it's not contained in the specific object itself?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('vtk error in pycharm: GLEW could not be initialized', '<python><opengl><pycharm><vtk><glew>', '<p>How can I run the simple python vtk example from\\n<a href=\"https://lorensen.github.io/VTKExamples/site/Python/GeometricObjects/CylinderExample/\" rel=\"nofollow noreferrer\">here</a> in pycharm?\\nI\\'ve installed vtk version 8.1.2 using pycharm and I\\'m using python version 3.7.4. Also, I have windows 10.</p>\\n\\n<p>When I run the example file I get this instead of a 3D cylinder.</p>\\n\\n<pre><code>ERROR: In C:\\\\VPP\\\\standalone-build\\\\VTK-source\\\\Rendering\\\\OpenGL2\\\\vtkWin32OpenGLRenderWindow.cxx, line 685\\nvtkWin32OpenGLRenderWindow (000001FACEF53880): failed to get wglChoosePixelFormatARB\\n\\nERROR: In C:\\\\VPP\\\\standalone-build\\\\VTK-source\\\\Rendering\\\\OpenGL2\\\\vtkWin32OpenGLRenderWindow.cxx, line 769\\nvtkWin32OpenGLRenderWindow (000001FACEF53880): failed to get valid pixel format.\\n\\nERROR: In C:\\\\VPP\\\\standalone-build\\\\VTK-source\\\\Rendering\\\\OpenGL2\\\\vtkOpenGLRenderWindow.cxx, line 785\\nvtkWin32OpenGLRenderWindow (000001FACEF53880): GLEW could not be initialized.\\n</code></pre>\\n\\n<p>To fix this error I\\'ve tried updating OpenGL by updating my graphics driver. Everything is up to date. The OpenGL Extensions Viewer 6.0 shows me this:</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/Rtyb9.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Rtyb9.jpg\" alt=\"driver info\"></a></p>\\n\\n<p>As requested, these are the packages I have installed along with the version number:</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/ENDHB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ENDHB.png\" alt=\"packages \"></a></p>\\n\\n<p>Also as requested, my system path looks like this: (I reformatted it to read easier)</p>\\n\\n<pre><code>C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;\\nC:\\\\WINDOWS\\\\system32;\\nC:\\\\WINDOWS;\\nC:\\\\WINDOWS\\\\System32\\\\Wbem;\\nC:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;\\nC:\\\\Program Files\\\\PuTTY\\\\;\\nC:\\\\Program Files\\\\Git\\\\cmd;\\nC:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;\\nC:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Python36_64\\\\Scripts;\\nC:\\\\Users\\\\levib\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Scripts\\\\;\\nC:\\\\Users\\\\levib\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\;\\nC:\\\\Users\\\\levib\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;;%CLion%\\n</code></pre>\\n\\n<p>I\\'ve tried following the instructions \\n<a href=\"https://vtk.org/Wiki/VTK/PythonDevelopment#Environment_variables_for_Windows\" rel=\"nofollow noreferrer\">here</a>\\nbut it seems that they are for only if you are using Eclipse with Pydev. (See the top of that page) I\\'m not sure why that would matter that much but regardless I was unable to find anything similar to the directory structure shown in those instructions around where pycharm installed vtk in my files.</p>\\n\\n<p>I found the GLEW source <a href=\"https://sourceforge.net/projects/glew/\" rel=\"nofollow noreferrer\">here</a> but I don\\'t know what I would even do with that.</p>\\n\\n<p><a href=\"https://stackoverflow.com/questions/52373482/paraview-glew-could-not-be-initialized\">This</a> is the closest thing to my question but it has no answer.</p>\\n\\n<p>Please help! I\\'m not very familiar in this!</p>\\n\\n<p><strong>Update:</strong></p>\\n\\n<p>Still, no luck getting it to run. Someone suggested adding VTK\\\\bin to my path variable and I feel like that could be part of the problem as well. But I can\\'t even find any vtk\\\\bin directory! I know I have vtk though because it imports.</p>\\n\\n<p>I\\'ve tried installing vtk in an anaconda environment (miniconda actually if that makes a difference) but that didn\\'t work either. I got this error instead though.</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/Ormwh.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Ormwh.jpg\" alt=\"vtk_error_conda\"></a></p>\\n\\n<p>I\\'m pretty sure my OpenGL version is sufficient but I\\'m thinking that vtk can\\'t \"find\" it or something...?</p>\\n\\n<p>HELP! I\\'m getting desperate!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Is there any way to replace built-in parametric variable name in sympy?', '<python><sympy>', '<pre><code>import sympy as sp\\n\\na = sp.Matrix([[1,1,1],[0,0,0],[0,0,0]])\\n\\nb = sp.Matrix([35,0,0])\\n\\nc = a.gauss_jordan_solve(b)\\n\\nprint(c[0][0])\\nprint(c[0][1])\\nprint(c[0][2])\\n</code></pre>\\n\\n<p><strong>Output:</strong></p>\\n\\n<pre><code>-tau0 - tau1 + 35\\n\\ntau0\\n\\ntau1\\n</code></pre>\\n\\n<p>I want to replace <code>tau0</code> and <code>tau1</code> with any letter, how can I accomplish this?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Starting from the nth term to the end of list python', '<python><list>', '<p>Hello I was wondering how you could do the following in python</p>\\n<p>Suppose we have these lists</p>\\n<pre><code>[&quot;Apples&quot;,&quot;Pears&quot;,&quot;Oranges&quot;,&quot;Grapes&quot;]\\n[&quot;Apples&quot;,&quot;Pears&quot;,&quot;Oranges&quot;,&quot;Grapes&quot;,&quot;Strawberries&quot;]\\n[&quot;Apples&quot;,&quot;Pears&quot;,&quot;Oranges&quot;,&quot;Pumpkins&quot;,&quot;Cherries&quot;,&quot;Lemons&quot;]\\n</code></pre>\\n<p>And I wanted to extract to extract the 4th element and beyond. So...</p>\\n<pre><code>[&quot;Grapes&quot;]\\n[&quot;Grapes&quot;,&quot;Strawberries&quot;]\\n[&quot;Pumpkins&quot;,&quot;Cherries&quot;,&quot;Lemons&quot;]\\n</code></pre>\\n<p>The lists will all have more than 3 elements.</p>\\n<p>How would I do this?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('What is wrong with my blackjack code? It keeps running forever', '<python><function><loops><recursion><blackjack>', \"<p>I am trying to make a very simple version of blackjack. I want to see if I can make it without following a tutorial. However, I got stuck because my code keeps running forever, and I can't figure out the reason.</p>\\n<p>Here is how it works, or at least how it should: the ace card is represented as 1(I have not added the possibility of the ace card having a value of 11 because of added complexity). Cards 1 through 9 having a value of 1 to 9. The 10, jack, queen, and king cards have a value of 10.</p>\\n<p>Both the player and the dealer start with an empty deck, represented by Player_cards and Dealer_cards, and both decks start with a sum value of 0, represented by a Dealer_sum and Player_sum.</p>\\n<p>First, one card is dealt to the dealer, and then two cards are dealt to the player.This is done by the random.choice function. I didn't want to deal with the complexity of having to deal a face down card to the dealer, so I just dealt one card; the face down card is replaced with a dealt card.I defined a list_sum function to sum the values of the player's and dealer's cards.</p>\\n<p>The vital part, which also happens to be the broken part, is the standorhit function, which should gives the choice to either hit if the player typed hit or Hit, or stand if the player typed stand or Stand. If the player decided to hit, the hit function starts, and draws a card to the player, sums up his cards, and decideds on what to do based on the value of his cards. If his cards value was over 21, the player loses, and the cards value was equal to 21, the player wins( for simplicity, I have skipped over the chance that the dealer's cards could be equal to 21), and if the player's cards were less than 21 in value, then it should return to the standorhit function, allowing the player to choose either to hit or stand.</p>\\n<p>If the player chose to stand , the dealer will deal cards to them-self until they are over 16, and if they overshoot 21, they lose, and they are in the range of 17 to 21, it will be compared to the player's card sum and declare the winner.</p>\\n<pre><code>def blackjack():\\n    import random\\n    cards =[1,2,3,4,5,6,7,8,9,10,10,10,10]\\n    Player_cards = []\\n    Dealer_cards = []\\n    Player_sum = 0\\n    Dealer_sum = 0\\n    Dealer_cards.append(random.choice(cards))\\n    Player_cards.append(random.choice(cards))\\n    Player_cards.append(random.choice(cards))\\n    print(&quot; The dealer cards are&quot;, str(Dealer_cards))\\n    print(&quot; The player cards are&quot;, str(Player_cards))\\n    def list_sum(a):\\n        total = 0\\n        for i in a:\\n            total += i\\n        return total\\n\\n    def standorhit():\\n\\n        def hit():\\n            Player_cards.append(random.choice(cards))\\n            Player_sum = list_sum(Player_cards)\\n            print(&quot; The dealer cards are&quot;, str(Dealer_cards))\\n            print(&quot; The player cards are&quot;, str(Player_cards))\\n            if Player_sum &gt; 21:\\n                print(&quot;Your cards value went over 21. YOu lose!!!&quot;)\\n            elif Player_sum == 21:\\n                print(&quot;21! You have won!!!&quot;)\\n\\n            elif Player_sum &lt; 21:\\n                standorhit()\\n        def stand():\\n            Dealer_sum = list_sum(Dealer_cards)\\n            if Dealer_sum &lt;17:\\n                Dealer_cards.append(random.choice(cards))\\n                print(&quot;The dealer has just dealed a card to hiself&quot;)\\n                Dealer_sum = list_sum(Dealer_cards)\\n                print(&quot; The dealer cards are&quot;, str(Dealer_cards))\\n                print(&quot; The player cards are&quot;, str(Player_cards))\\n                print(&quot; The dealer's sum is&quot;, str(Dealer_sum))\\n                stand()     \\n\\n            elif Dealer_sum&gt;16 and Dealer_sum&lt;21:\\n                if Dealer_sum &gt; Player_sum:\\n                    print(&quot;The dealer wins because their cards have a higher value!!!&quot;)\\n                elif Dealer_sum == Player_sum:\\n                    print(&quot;Push! No body wins!!!&quot;)\\n\\n                elif Player_sum &gt; Dealer_sum:\\n                    print(&quot;The Player wins beacause your cards have a hugher value than the dealer!!!&quot;)\\n\\n            else:\\n                print (&quot;The player wins because their cards value exceeded 21!!&quot;)\\n        A = input(&quot;Do you want to Stand or Hit?&quot;)\\n        if A == &quot;Stand&quot; or &quot;stand&quot;:\\n            stand()\\n\\n        elif A ==&quot;Hit&quot; or &quot;hit&quot;:\\n            hit()\\n\\n    standorhit()\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Assign class methods from YAML file', '<python><class-design><yaml>', \"<p>In short,I've written an application that parses text files in specified formats from different email feeds.  Currently, there are two formats allowed by users in order to correctly upload information.  I've also included a simple YAML file that allows people with non-programming backgrounds (ie sysadmins) to define the basics parsing parameters such as delimiters for each different email feed.</p>\\n\\n<p>As it turns out, users are going to require a lot more formats than the ones I've defined.  As in entirely-different-parsing-algorithm format.</p>\\n\\n<p>Since it would be difficult for someone not familiar with the source to constantly add/update parsing methods, my idea is to allow the admin to define custom methods in the YAML file like so:</p>\\n\\n<pre><code>parser: !!python/name:modules.custom.parser\\n</code></pre>\\n\\n<p>That way the admin can define their own parsing method called, for example, modules.custom.parser without having to dig through source code.</p>\\n\\n<p>Am I playing with fire allowing the admin to dynamically upload their own custom methods?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python, creating a new variable from a dictionary? not as straightforward as it seems?', '<python><dictionary>', \"<p>I'm trying to create a new variable that will consist of an existing dictionary so that I can change things in this new dictionary without it affecting the old one. When I try this below, which I think would be the obvious way to do this, it still seems to edit my original dictionary when I make edits to the new one.. I have been searching for info on this but can't seem to find anything, any info is appreciated</p>\\n\\n<pre><code>newdictionary = olddictionary\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Can't understand: ValueError: Graph disconnected: cannot obtain value for tensor Tensor\", '<python><tensorflow><keras><keras-layer><tf.keras>', '<p>I wrote a architecture similar to this code:\\n<a href=\"https://keras.io/guides/functional_api/#manipulate-complex-graph-topologie\" rel=\"nofollow noreferrer\">https://keras.io/guides/functional_api/#manipulate-complex-graph-topologie</a>:</p>\\n<pre><code>  visual_features_input = keras.Input(\\n    shape=(1000,), name=&quot;Visual-Input-FM&quot;, dtype=\\'float\\') \\n  et_features_input = keras.Input(\\n      shape=(12,), name=&quot;ET-input&quot;, dtype=\\'float\\') \\n  sentence_encoding_input = keras.Input(\\n    shape=(784,), name=&quot;Sentence-Input-Encoding&quot;, dtype=\\'float\\') \\n    \\n  et_features = layers.Dense(units = 12, name = \\'et_features\\')(et_features_input)\\n  visual_features = layers.Dense(units = 100, name = \\'visual_features\\')(visual_features_input)\\n  sentence_features = layers.Dense(units = 60, name = \\'sentence_features\\')(sentence_encoding_input)\\n\\n  x = layers.concatenate([sentence_features, visual_features, et_features], name = \\'hybrid-concatenation\\')\\n\\n  score_pred = layers.Dense(units = 1, name = &quot;score&quot;)(x)\\n  group_pred = layers.Dense(units = 5, name=&quot;group&quot;)(x)\\n  \\n  # Instantiate an end-to-end model predicting both score and group\\n  hybrid_model = keras.Model(\\n      inputs=[sentence_features, visual_features, et_features],\\n      outputs=[group_pred]\\n      # outputs=[group_pred, score_pred],\\n  )\\n</code></pre>\\n<p>But I get the error:</p>\\n<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor Tensor(&quot;Sentence-Input-Encoding_2:0&quot;, shape=(None, 784), dtype=float32) at layer &quot;sentence_features&quot;. The following previous layers were accessed without issue: []\\n</code></pre>\\n<p>Any idea why?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('I cannot SELECT a recent INSERT to my database unless I stop and restart my program', '<python><python-3.x><sqlite>', \"<p>When I run my code, I am trying to INSERT some info into my database and then recall that info with SELECT.  I can see the new entry when I manually check the database. The entry is being inserted but my python code can't see it until I exit and re-run it.</p>\\n<p>These are being called through an async bot (not shown below).  But the same thing happens in the self contained code below.  You'll notice some over-use of commits because I'd read a few places people had success committing before a select, but its not working.</p>\\n<p>I've found a couple questions on here pertaining to this issue but none of their solutions seem to be working for me.</p>\\n<p>EDIT: If it's not clear from the code itself, these are adding dice rolls to a database and then returning them base on either epoch dates and number of entries.</p>\\n<pre><code>import sqlite3, time\\nfrom datetime import datetime\\n\\ndef add_roll(user=None, nick=None, argument=None, equation=None, result=None, stat=None, success=None, comment=None):\\n    conn = sqlite3.connect('dicebot.db')\\n    c = conn.cursor()\\n\\n    sql = &quot;INSERT INTO rolls (messagetime, user, nick, argument, equation, result, stat, success, comment) VALUES (?,?,?,?,?,?,?,?,?)&quot;\\n    values = (time.time(), user, nick, argument, equation, result, stat, success, comment)\\n    c.execute(sql,values)\\n    conn.commit()    \\n    conn.close()\\n\\ndef get_entry(date_in_epoch=0, date_out_epoch=time.time(), number_of_entries=1):\\n    conn = sqlite3.connect('dicebot.db')\\n    c = conn.cursor()\\n    conn.commit()\\n\\n    select_stmt = '''SELECT * FROM rolls ORDER BY messagetime DESC LIMIT (%s)''' % (number_of_entries,)\\n\\n    if number_of_entries == -1:\\n        select_stmt = '''SELECT * from rolls WHERE messagetime BETWEEN (%s) and (%s) ORDER BY messagetime''' % (date_in_epoch, date_out_epoch)\\n    elif number_of_entries &gt;= 0:\\n        select_stmt = '''SELECT * from rolls WHERE messagetime BETWEEN (%s) and (%s) ORDER BY messagetime DESC LIMIT (%s)''' % (date_in_epoch, date_out_epoch, number_of_entries)\\n\\n    x = c.execute(select_stmt)\\n    records = x.fetchall()\\n\\n    output = []\\n    for record in records:\\n        nick = record[3]\\n        equation = record[5]\\n        result = record[6]\\n        stat = record[7]\\n        success = record[8]\\n        comment = &quot;&quot; if record[9] is None else record[9]\\n\\n        if success is not None:\\n            output.append(&quot;**{}:** {} {} {} (Stat={})&quot;.format(nick, result, success, comment, stat))\\n        else:\\n            output.append(&quot;**{}:** {} {}&quot;.format(nick, result, comment))\\n\\n    conn.close()\\n    return output\\n\\n\\nif __name__ == '__main__':\\n    add_roll(&quot;MyName&quot;, &quot;MyHandle&quot;, &quot;1d6+2&quot;, &quot;(3)+2&quot;, 5, 45, None)\\n    for record in get_entry(number_of_entries=10):\\n        print (record)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Find Largest File and Deleting Folders', '<python>', '<p>I\\'m working on a cleanup script for tv shows that I download.  I want it to get the largest file in each folder, move/rename it and then delete that folder.  The issue I\\'m having is that sometimes when there is another nested folder, it crashes and skips it.  I\\'m not sure how to convert this into a recursive function that does the same functionality.  It would also be nice to just look for the largest file instead of use the hard coded 30MB.</p>\\n\\n<p>Also, sometimes a file I download has an incorrect date so it would be great if it could make each new file the current date and time when the script ran.</p>\\n\\n<pre><code>import os\\nimport shutil\\n\\n\\ndir = \"C:\\\\Users\\\\Bobe\\\\Downloads\\\\TV\\\\\\\\\"\\n\\nfor folder in os.listdir(dir):\\n    if os.path.isdir(os.path.join(dir,folder)):\\n        for file in os.listdir(dir + folder):\\n            filelocation = dir+folder+\"\\\\\\\\\"+file\\n            if os.path.getsize(filelocation) &gt; 30000000: # This is in bytes (30 MB)\\n                extension = os.path.splitext(file)[1]\\n                shutil.move(filelocation, dir + folder + extension)\\n            else:               \\n                os.remove(filelocation)\\n\\n        shutil.rmtree(dir + folder)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How do you create a browser in PyQt5?', '<python><pyqt5><qtwebengine>', '<p>I have a very simple application that is intended to run a web browser in PyQt window.</p>\\n\\n<p>The code runs without errors the window opens and then \\'blinks\\' briefly and then is blank.</p>\\n\\n<p>I am running MacOS(10.13.6)  Python 3.8  and PyQt5 5.14 and PyQtWebEngine 5.14.</p>\\n\\n<pre><code>from PyQt5.QtCore import *\\nfrom PyQt5.QtWidgets import *\\nfrom PyQt5.QtGui import *\\nfrom PyQt5.QtWebEngineWidgets import *\\n\\nimport sys\\n\\nclass MainWindow(QMainWindow):\\n\\n    def __init__(self, *args, **kwargs):\\n        super(MainWindow,self).__init__(*args, **kwargs)\\n\\n        self.browser = QWebEngineView()\\n        self.browser.setUrl(QUrl(\"http://google.com\"))\\n\\n        self.setCentralWidget(self.browser)\\n\\n        self.show()\\n\\napp = QApplication(sys.argv)\\nwindow = MainWindow()\\n\\napp.exec_()\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Reducing .exe file using virtual environment', '<python><virtualenv><pyinstaller>', '<p>I am quite new to Python (and programming in general to be frank), and am using pyinstaller to create a .exe file from a .py file. After a few trials I figured that pyinstaller is including many unnecessary libraries such as scipy which is making my file extremely big.\\nTo get around that I made a virtual environment and installed the modules I needed. However, when I tried making the .exe while still in the venv using pyinstaller -w -F -i \"iconpath\" filename.py its not working (it just stops after the last line in the code below):</p>\\n\\n<pre><code>126 INFO: PyInstaller: 3.6\\n126 INFO: Python: 3.8.1\\n127 INFO: Platform: Windows-10-10.0.16299-SP0\\n128 INFO: wrote C:\\\\Users\\\\26039190\\\\RefCal_v4\\\\RefCal_v4.spec\\n131 INFO: UPX is not available.\\n139 INFO: Extending PYTHONPATH with paths\\n[\\'C:\\\\\\\\Users\\\\\\\\26039190\\\\\\\\RefCal_v4\\', \\'C:\\\\\\\\Users\\\\\\\\26039190\\\\\\\\RefCal_v4\\']\\n139 INFO: checking Analysis\\n139 INFO: Building Analysis because Analysis-00.toc is non existent\\n139 INFO: Initializing module dependency graph...\\n143 INFO: Caching module graph hooks...\\n153 INFO: Analyzing base_library.zip ...\\n5696 INFO: Processing pre-find module path hook   distutils\\n5697 INFO: distutils: retargeting to non-venv dir \\'C:\\\\\\\\Users\\\\\\\\26039190\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Python\\\\\\\\Python38-32\\\\\\\\lib\\'\\n9412 INFO: Caching module dependency graph...\\n9565 INFO: running Analysis Analysis-00.toc\\n9570 INFO: Adding Microsoft.Windows.Common-Controls to dependent assemblies of final executable\\n  required by c:\\\\users\\\\26039190\\\\env\\\\scripts\\\\python.exe\\n9601 INFO: Analyzing C:\\\\Users\\\\26039190\\\\RefCal_v4\\\\RefCal_v4.py\\n13180 INFO: Processing pre-find module path hook   site\\n13181 INFO: site: retargeting to fake-dir \\'c:\\\\\\\\users\\\\\\\\26039190\\\\\\\\env\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\PyInstaller\\\\\\\\fake-modules\\'\\n14909 INFO: Processing pre-safe import module hook   setuptools.extern.six.moves\\n21403 INFO: Processing pre-safe import module hook   six.moves\\n122612 INFO: Processing module hooks...\\n122615 INFO: Loading module hook \"hook-distutils.py\"...\\n122622 INFO: Loading module hook \"hook-encodings.py\"...\\n122840 INFO: Loading module hook \"hook-lib2to3.py\"...\\n122846 INFO: Loading module hook \"hook-matplotlib.backends.py\"...\\n124362 INFO:   Matplotlib backend \"GTK3Agg\": ignored\\n    backend Gtk3Agg requires cairo\\n124925 INFO:   Matplotlib backend \"GTK3Cairo\": ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n125538 INFO:   Matplotlib backend \"MacOSX\": ignored\\n    cannot import name \\'_macosx\\' from \\'matplotlib.backends\\' (c:\\\\users\\\\26039190\\\\env\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\__init__.py)\\n126226 INFO:   Matplotlib backend \"nbAgg\": ignored\\n    No module named \\'IPython\\'\\n127194 INFO:   Matplotlib backend \"Qt4Agg\": added\\n128011 INFO:   Matplotlib backend \"Qt4Cairo\": ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n128802 INFO:   Matplotlib backend \"Qt5Agg\": added\\n129303 INFO:   Matplotlib backend \"Qt5Cairo\": ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n130180 INFO:   Matplotlib backend \"TkAgg\": added\\n131163 INFO:   Matplotlib backend \"TkCairo\": ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n131845 INFO:   Matplotlib backend \"WebAgg\": ignored\\n    Traceback (most recent call last):\\n  File \"c:\\\\users\\\\26039190\\\\env\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\backend_webagg.py\", line 27, in &lt;module&gt;\\n    import tornado\\nModuleNotFoundError: No module named \\'tornado\\'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"&lt;string&gt;\", line 12, in &lt;module&gt;\\n  File \"c:\\\\users\\\\26039190\\\\env\\\\lib\\\\site-packages\\\\matplotlib\\\\backends\\\\backend_webagg.py\", line 29, in &lt;module&gt;\\n    raise RuntimeError(\"The WebAgg backend requires Tornado.\")\\nRuntimeError: The WebAgg backend requires Tornado.\\n132610 INFO:   Matplotlib backend \"WX\": ignored\\n    No module named \\'wx\\'\\n133240 INFO:   Matplotlib backend \"WXAgg\": ignored\\n    No module named \\'wx\\'\\n133885 INFO:   Matplotlib backend \"WXCairo\": ignored\\n    No module named \\'wx\\'\\n134389 INFO:   Matplotlib backend \"agg\": added\\n135129 INFO:   Matplotlib backend \"cairo\": ignored\\n    cairo backend requires that pycairo&gt;=1.11.0 or cairocffiis installed\\n136202 INFO:   Matplotlib backend \"pdf\": added\\n136913 INFO:   Matplotlib backend \"pgf\": added\\n137455 INFO:   Matplotlib backend \"ps\": added\\n138036 INFO:   Matplotlib backend \"svg\": added\\n138739 INFO:   Matplotlib backend \"template\": added\\n139367 INFO: Loading module hook \"hook-matplotlib.py\"...\\n139836 INFO: Loading module hook \"hook-numpy.core.py\"...\\n140027 INFO: Loading module hook \"hook-numpy.py\"...\\n140031 INFO: Loading module hook \"hook-pkg_resources.py\"...\\n140710 INFO: Processing pre-safe import module hook   win32com\\nTraceback (most recent call last):\\n  File \"&lt;string&gt;\", line 2, in &lt;module&gt;\\nModuleNotFoundError: No module named \\'win32com\\'\\n140839 INFO: Processing pre-safe import module hook   win32com\\nTraceback (most recent call last):\\n  File \"&lt;string&gt;\", line 2, in &lt;module&gt;\\nModuleNotFoundError: No module named \\'win32com\\'\\n140954 INFO: Excluding import \\'__main__\\'\\n140957 INFO:   Removing import of __main__ from module pkg_resources\\n140966 INFO: Loading module hook \"hook-pydoc.py\"...\\n140976 INFO: Loading module hook \"hook-PyQt5.py\"...\\n</code></pre>\\n\\n<p>Can anyone please shed some light?\\nBy the way I am using anaconda, could that be the problem? Some people say I should uninstall anaconda, but I do not want to delete anaconda since I use Jupyter and Spyder quite a lot</p>\\n\\n<p>Thank you everyone</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Add Empty Subplot With No Axis Ticks/Labels for Text as Subplot in Matplotlib', '<python><matplotlib>', '<p>My goal is to create plot with four subplots, where the bottom two are really just empty boxes where I will display some text. Unfortunately, all of my efforts to remove the y and x axis tick marks and labels have failed. I\\'m still new to matplotlib so I\\'m sure there\\'s something simple that I\\'m missing. Here\\'s what I\\'m trying and what I get:</p>\\n<pre><code>import matplotlib.pyplot as plt\\nfig, axes = plt.subplots(2, 2, sharex=False, sharey=True, figsize=(6,6))\\nfig.add_subplot(111, frameon=False)\\nplt.tick_params(labelcolor=\\'none\\', top=False, bottom=False, left=False, right=False)\\nplt.title(\\'Neuron Length\\')\\nplt.xlabel(\\'Strain\\')\\nplt.ylabel(\\'Neuron Length (um)\\')\\n\\naIP = fig.add_subplot(223, frameon=False)\\naIP.annotate(\\'Big Axes \\\\nGridSpec[1:, -1]\\', (0.1, 0.5),\\n               xycoords=\\'axes fraction\\', va=\\'center\\')\\n# First approach\\naIP.axes.xaxis.set_ticks([])\\naIP.axes.yaxis.set_ticks([])\\n# Second approach\\nax = plt.gca()\\nax.axes.yaxis.set_visible(False)\\n\\nplt.show()\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/5JkqW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5JkqW.png\" alt=\"4x4 grid of empty subplots with x and y labels and tick marks present\" /></a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to simulate a button click in selenium?', '<python><selenium-webdriver>', '<p>I am currently learning selenium. I tried to simulate button click of a csv file from url &quot;https://worldpopulationreview.com/countries/countries-by-gdp/#worldCountries&quot;.</p>\\n<p>I did:</p>\\n<pre><code>Right click the csv icon\\nInspect and copy the full xpath\\n</code></pre>\\n<p>Then I used following code:</p>\\n<pre class=\"lang-py prettyprint-override\"><code>from selenium import webdriver\\nfrom selenium.webdriver.common.keys import Keys\\nimport os\\n\\ndriver = webdriver.Chrome()\\n\\nurl = \\'https://worldpopulationreview.com/countries/countries-by-gdp\\'\\ndriver.get(url)\\n\\nxpath = \\'/html/body/div[1]/div/div[1]/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/a[2]\\'\\n\\nbtn = driver.find_element_by_xpath(xpath)\\nbtn.click()\\n\\n# df = pd.read_csv(os.path.expanduser(\\'~/Downloads/data.csv\\'))\\n# print(df.head())\\n# driver.close()\\n</code></pre>\\n<h1>Errro</h1>\\n<pre><code>WebDriverException: Message: unknown error: Element &lt;a&gt;...&lt;/a&gt; is not clickable at point (1070, 879). Other element would receive the click: &lt;div id=&quot;google_ads_iframe_/15184186/worldpopulationreview_adhesion_0__container__&quot; style=&quot;border: 0pt none;&quot;&gt;...&lt;/div&gt;\\n  (Session info: chrome=85.0.4183.121)\\n  (Driver info: chromedriver=2.42.591059 (a3d9684d10d61aa0c45f6723b327283be1ebaad8),platform=Mac OS X 10.15.7 x86_64)\\n</code></pre>\\n<h1>Attempts</h1>\\n<p>I tried multiple attempts with different xpaths, but to no avail. How to simulate button click for this particular website?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('show top 5 rows for each group in dataframe with multiple numeric columns', '<python><pandas><sorting><multiple-columns><multi-index>', \"<p>I have the following dataframe which I obtained using: <code>df.groupby(['departamento','campo']).describe()</code></p>\\n<p>df_statistics:</p>\\n<pre><code>                            produccion                                         \\n                                mean           std          min           max\\ndepartamento campo                                                           \\nf7fd2c4f     8dd7c41b    4714.695603   1076.940951  3091.015553   6378.546534\\n             82edafb9    1851.291482    841.512944   675.814722   3006.476183\\n             58a0d8ca    1768.151315    347.896113  1033.459536   2242.544338\\n             8ba362f3     257.917212    231.490925     0.000000    497.916659\\n             4f4a249f     192.811711     80.299111   129.190598    356.437730\\n             741abe20     431.717352     71.053604   291.831556    529.518332\\n             51cbb05d     489.804186     65.542073   353.186216    582.869264\\n             4d0fb45e     358.597250     30.166391   314.168045    407.842103\\n             c98bd9dd     437.244383     27.135823   402.546159    481.245852\\n             7eb34927     106.426374     22.579237    81.994706    142.283652\\nec12ad00     44502c89      15.015145     11.467353     0.000000     29.241879\\n             5558f26e       1.107400      0.959445     0.000000      2.762156\\n             85c1a0e5       0.122720      0.425113     0.000000      1.472635\\ncf33cb8a     2f614c0b   12458.858168  12042.715975   150.635367  25999.977584\\n             5559f8d7    4272.447078   1326.999765  2458.231739   6059.658900\\n             fd6f6562    3378.712031   1194.101786   869.763739   4814.220212\\n             febb6cf6    4149.936221    833.663173  2471.139924   5827.822674\\n             d56beadb     474.831361    810.840341     0.000000   2283.465569\\n             124207de    3863.484888    796.945367  2713.111304   5150.735620\\n             1f d2689f   6099.963902    768.102604  4766.241346   7897.993261\\n             c728bf96    3361.623457    704.293795  2203.721911   4949.989960\\n</code></pre>\\n<p>I have sorted the dataframe based on the standard deviation ('std') column, but I want to show only the top 5 values for each group in the column 'departamento'.</p>\\n<p>I tried the following code: <code>df_statistics.nlargest(5, columns =('produccion','std'))</code></p>\\n<p>but I get the top 5 overall the groups in the column 'departamento':</p>\\n<pre><code>                            produccion                                         \\n                               mean           std          min           max\\ndepartamento campo                                                          \\ncf33cb8a     2f614c0b  12458.858168  12042.715975   150.635367  25999.977584\\n             5559f8d7   4272.447078   1326.999765  2458.231739   6059.658900\\n             fd6f6562   3378.712031   1194.101786   869.763739   4814.220212\\nf7fd2c4f     8dd7c41b   4714.695603   1076.940951  3091.015553   6378.546534\\n             82edafb9   1851.291482    841.512944   675.814722   3006.476183\\n</code></pre>\\n<p>How can I show the top 5 values for each group based on the column 'std'</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('passing an itterator to a parrent class init in python', '<python><python-3.x><oop>', \"<p>What I want to do is to wrap around the <code>Doc2Vec</code> class in <code>gensim</code> and give it a training method. Normaly if i wanted to train a new model I would do the following:</p>\\n<pre><code>import glob\\nfrom gensim.models import doc2vec, Doc2Vec\\n\\n\\nclass tagged_documents(object):\\n    def __init__(self, path):\\n        self.file_l = [name for name in glob.iglob(path, recursive=True)]\\n    \\n    def __iter__(self):\\n        for f_id, f_path in enumerate(self.file_l):\\n            with open(f_path, 'r') as f:\\n                docu = f.read()\\n                yield doc2vec.TaggedDocument(words=docu, tags=(f'DOC_{f_id}',))\\n\\n\\n\\nDocs = tagged_documents('/path/to/docs/*')\\n    \\nDoc2Vec(Docs, min_count = 100, \\n                 vector_size=300, \\n                 epochs = 20, \\n                 negative = 5, \\n                 workers=20, \\n                 sample = 1e-5,\\n                 alpha=0.01,\\n                 min_alpha=0.0001)\\n</code></pre>\\n<p>and this works fine</p>\\n<p>now what I want to do is this wrapper</p>\\n<pre><code>class doc2vec_model(Doc2Vec):\\n\\n    def train(self,docs):\\n        super(Doc2Vec, self).__init__(docs, min_count = 100, \\n                                     vector_size=300, \\n                                     epochs = 20, \\n                                     negative = 5, \\n                                     workers=20, \\n                                     sample = 1e-5,\\n                                     alpha=0.01,\\n                                     min_alpha=0.0001)\\n\\n        \\nDocs = tagged_documents('/path/to/docs/*')\\nmodel = doc2vec_model()\\nmodel.train(Docs)\\n</code></pre>\\n<p>where I get the exception that <code>TypeError: 'NoneType' object is not iterable</code> when i try to call the <code>model.train()</code> function</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Processing output from cmdline via a Python script', '<python><scripting><process>', \"<p>I'm trying to use the subprocess module with Python 2.6 in order to run a command and get its output. The command is typically ran like this:</p>\\n\\n<pre><code>/usr/local/sbin/kamctl fifo profile_get_size myprofile | awk -F ':: ' '{print $2}'\\n</code></pre>\\n\\n<p>What's the best way to use the subprocess module in my script to execute that command with those arguments and get the return value from the command? I'm using Python 2.6.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Python watchdog script doesn't function properly\", '<python>', '<p>I am trying to use Python Watchdog to monitor a directory for changes. However, when I try to run the Quickstart example:</p>\\n\\n<pre><code>import time\\nfrom watchdog.observers import Observer\\nfrom watchdog.events import LoggingEventHandler\\n\\nif __name__ == \"__main__\":\\n    event_handler = LoggingEventHandler()\\n    observer = Observer()\\n    observer.schedule(event_handler, path=\\'.\\', recursive=True)\\n    observer.start()\\n    try:\\n        while True:\\n            time.sleep(1)\\n    except KeyboardInterrupt:\\n        observer.stop()\\n    observer.join()\\n</code></pre>\\n\\n<p>by putting in it the file <strong>test.py</strong>, nothing displays in the Terminal window where I ran it. What is causing this to happen, and how can I fix it?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python Folium pie chart MarkerCluster', '<python><leaflet><pie-chart><folium><leaflet.markercluster>', '<p>I am using Folium to plot the locations of stores from several different companies. Currently, with the MarkerCluster function and using the Subgroup plugin, the map shows the total number of stores on each region of the map. I am amble to select, using Layer Control, the companies that will have their markers displayed.</p>\\n\\n<p>The problem is that the map clusters the markers of all companies into one cluster group, displaying the total sum of stores, while I need to know the separate value for each one of them (the idea is to do a comparative analysis). I first tried to insert one separate cluster group for each company, but the map was unreadable. </p>\\n\\n<p>I am now trying to substitute the default style of the Marker for a pie chart (probably using the icon_create_function parameter), that would consider the value for each company in a certain region of the map.</p>\\n\\n<p>I also considered using the Minichart plugin, but it seems there\\'s no way to integrate it with MarkerCluster..</p>\\n\\n<p>There are solutions using Javascript here:</p>\\n\\n<p><a href=\"http://bl.ocks.org/gisminister/10001728\" rel=\"nofollow noreferrer\">http://bl.ocks.org/gisminister/10001728</a></p>\\n\\n<p>And also here:  <a href=\"https://github.com/SINTEF-9012/PruneCluster\" rel=\"nofollow noreferrer\">https://github.com/SINTEF-9012/PruneCluster</a>.</p>\\n\\n<p>Was anyone able to do it using Python (Folium)? </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('error when running python script: \"AttributeError: \\'EventObject\\' object has no attribute \\'sentence\\'\"', '<python><attributeerror>', \"<p>when I run my code, I receive the following error message. I think the fault must lie in a short script that is called upon when I run the main script, because that is the only one in which there is an &quot;EventObject&quot;. This is the error:</p>\\n<pre><code>AttributeError: 'EventObject' object has no attribute 'sentence'\\n</code></pre>\\n<p>This is the code from the short script:</p>\\n<pre><code>class AnnotationsObject:\\n\\ndef __init__(self):\\n    self.eventlist = []\\n    self.entitylist = []\\n    self.polaritytriggerslist = []\\n\\n\\nclass EventObject:\\n    def __init__(self):\\n        self.eventtext = []\\n        self.polarity = None\\n        self.sameclause = False\\n\\nclass EntityObject:\\n    def __init__(self):\\n        self.entitytype = None\\n        self.entitytext = []\\n        self.polarity = []\\n        self.metonymy = False\\n\\nclass PolarityTriggersObject:\\n    def __init__(self):\\n        self.text = []\\n        self.polarity = []\\n        self.target = []\\n        self.id = None\\n        self.irony = []\\n        self.eventrelationpolarity = []\\n        self.span = []\\n</code></pre>\\n<p>Any ideas on what the problem might be?</p>\\n<p>Edit: This is the piece of code which calls on &quot;EventObject&quot; and the &quot;sentence&quot;-attribute</p>\\n<pre><code>def write_annotations_eventpolarity(allAnnotationsDict, annotatornames, outfilefolder):\\nalleventsdict = get_all_events(allAnnotationsDict)\\n'''\\nGets, for every unique event (alleventslist), its polarity given by each annotator\\n'''\\nwith open(os.path.join(outfilefolder,'annotations_eventpolarity.csv'), 'w') as csvfile:\\n    outfilewriter = csv.writer(csvfile, delimiter='\\\\t',quotechar='|', quoting=csv.QUOTE_MINIMAL)\\n    outfilewriter.writerow(['Document', 'Event'] + [a for a in annotatornames] + ['Sentence', 'Sentence without event'])\\n    for documentname, annotatordict in allAnnotationsDict.items():\\n        #Get a list of all events per document, consider the first annotator in the dict, as the events are the same for each annotator.\\n        allevents = alleventsdict[documentname][annotatornames[0]]\\n        alleventstrings = ['+'.join(x.eventtext) for x in allevents] #Events can be stored as lists of two non-consecutive spans\\n        alleventsentences = [x.sentence for x in allevents]\\n        alleventsentenceswithoutevent = [x.sentencewithoutevent for x in allevents]\\n        seen = []\\n        for eventText, eventSent, eventSentWith in zip(alleventstrings, alleventsentences, alleventsentenceswithoutevent):\\n            rowelements = [] #Rowelements will be written to output file\\n            rowelements.append(documentname)\\n            rowelements.append(eventText)\\n            for a in annotatornames:\\n                pol = []\\n                eventobjectslist = alleventsdict[documentname][a]\\n                for eveobj in eventobjectslist:\\n                    found = False\\n                    if '+'.join(eveobj.eventtext) == eventText and eveobj.sentence == eventSent:\\n                        if eveobj.polarity == None:\\n                            pol.append('None')\\n                        else:\\n                            pol.append(eveobj.polarity)\\n                        found = True\\n                    else:\\n                        continue\\n                    if not found:\\n                        print('Warning: event\\\\t{0}\\\\t{1}\\\\tfrom annotator {2} not found in alleventslist.'.format(eveobj.eventtext, documentname, a))\\n                        warnings.append('Write annotations for event polarities: event\\\\t{0}\\\\t{1}\\\\tfrom annotator {2} not found in alleventslist.'.format(eveobj.eventtext, documentname, a))\\n                if len(pol) &gt; 1 and 'None' in pol: #Event polarity can be 'None' if the event is part of a linked event span and its polarity was added to the other part\\n                    indx_none = pol.index('None') #Remove 'None' polarities\\n                    pol.pop(indx_none)\\n                rowelements.append(','.join(list(set(pol))))\\n            rowelements.append(eventSent)\\n            rowelements.append(eventSentWith)\\n            if not (eventText,eventSent) in seen: #Discard 100% duplicates (i.e. events that are annotated twice in the sentence)\\n                outfilewriter.writerow(rowelements)\\n            seen.append((eventText,eventSent))\\n</code></pre>\\n<p>The error seems to occur at <code>alleventsentences = [x.sentence for x in allevents]</code></p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to pause matplotlib animation for some seconds(without using any mouse clicks)?', '<python><matplotlib><animation><pause>', '<p>I have created a script that animates two scatter points and a line in between them. Here is the gif:</p>\\n<p><a href=\"https://i.stack.imgur.com/yFmIc.gif\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yFmIc.gif\" alt=\"\" /></a></p>\\n<p>And here is the script used for animation:</p>\\n<pre class=\"lang-py prettyprint-override\"><code>from a import get_points\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport matplotlib.animation as animation\\nimport time\\n\\nfig, ax = plt.subplots(figsize=(12,8))\\nax.set(xlim=(0,104), ylim=(0,68))\\n\\nx_start, y_start = (50, 35)\\nx_end, y_end = (90, 45)\\n\\nx_1, y_1 = get_points(x_start, y_start, x_end, y_end, 0.55)\\nx_2, y_2 = get_points(x_end, y_end, x_start, y_start, 0.55)\\n\\nx = np.linspace(x_1, x_2, 20)\\ny = np.linspace(y_1, y_2, 20)\\n\\nsc_1 = ax.scatter([], [], color=&quot;green&quot;, zorder=4)\\nline, = ax.plot([], [], color=&quot;crimson&quot;, zorder=4)\\nsc_2 = ax.scatter([], [], color=&quot;gold&quot;, zorder=4)\\ntitle = ax.text(50, 65, &quot;&quot;, bbox={\\'facecolor\\':\\'w\\', \\'alpha\\':0.5, \\'pad\\':5}, ha=&quot;center&quot;)\\n\\ndef animate(i):\\n    ## plot scatter point\\n    sc_1.set_offsets([x_start, y_start])\\n\\n    ## plot line\\n    line.set_data(x[:i], y[:i])\\n\\n    ## plot scatter point\\n    if i == len(x):\\n        sc_2.set_offsets([x_end, y_end])\\n\\n    return sc_1, line, sc_2, title,\\n\\nani = animation.FuncAnimation(  \\n    fig=fig, func=animate, interval=50, blit=True)  \\n\\nplt.show()\\n</code></pre>\\n<p>What I want is: to pause the animation for 2 seconds when the first scatter point shows up then animate the line and when the line animation is complete pause animation for 2 more seconds and after that display the scatter point.</p>\\n<p>What should I change in my code to get the required animation?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How can I lock the button for 3 seconds in kivy python?', '<python><kivy>', '<p>I designed a gui. That gui includes button when button pressed it countsdown from 3 to 0 and captures a frame. While in this 3 secs when I press button more then once it captures more then one frame how can i solve this problem waiting your recommendations?? </p>\\n\\n<pre><code>   def capturecountdown(self, *args):\\n  if self.countdown == 3:\\n     self.mainscr.add_widget(self.counter3_button)\\n     print(\"3\")\\n  elif self.countdown == 2:\\n     self.mainscr.remove_widget(self.counter3_button)\\n     self.mainscr.add_widget(self.counter2_button)\\n     print(\"2\")\\n  elif self.countdown == 1:\\n     self.mainscr.remove_widget(self.counter2_button)\\n     self.mainscr.add_widget(self.counter1_button)\\n     print(\"1\")\\n  elif self.countdown == 0:\\n     self.mainscr.remove_widget(self.counter1_button)\\n     self.countdown = 3\\n     self.capturepressed = True\\n     return self.capture()\\n  self.countdown -= 1\\n  Clock.schedule_once(self.capturecountdown, 1)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Iterating through files in sub directories and loading them', '<python><loops>', \"<p>I've got the following situation to solve: my parent directory has ~25 subfolders. Each of the subfolders contains a file that ends with 'RRS.csv'. Additonally, some of the subfolders contain a file ending with 'ROH.csv'. From each of the subfolders, i need to import the 'ROH.csv' file if it exists, and if not, the 'RRS.csv' file. I tried this through iterating through all subfolders and all files in the subfolders using the os.path.exists operator to check if the 'ROH.csv' file exists. Another idea was to first list all files in each subfolder, then identifying if one element contains the 'ROH.csv' ending and then loading it.</p>\\n<pre><code>for filename in sorted(os.listdir(parent_dir)):\\n    for subdir, dirs, files in os.walk(parent_dir):\\n        if not os.path.exists(filename.endswith('ROH.csv')):\\n            data = np.genfromtxt(filename.endswith('RRS.csv'), delimiter=',', skip_header=1)\\n            # some calculations\\n        else:\\n            data = np.genfromtxt(filename.endswith('ROH.csv'), delimiter=',', skip_header=1)\\n            # more funny calculations\\n</code></pre>\\n<p>This code has multiple problems: (i) it has to check if one file in the subfolder ends with 'ROH.csv', and not if each file ends with it; (ii) i havent figured out a way yet to specify which file to load; endswith does not work (bool); (iii) it contains double for-loops.</p>\\n<p>Hope anyone has an idea to solve this.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Sympy: Multiplications of exponential rather than exponential of sum', '<python><sum><multiplication><sympy><exponential>', \"<p>I'm searching how to tell SymPy to use a multiplication of exponentials rather than an exponential of a sum. That is, it currently gives me exp(a + b) and I would want to get exp(a)*exp(b). There must be a fairly easy way but I can't seem to find it.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Is there any way i can pass in only the values of a list to a dictionary and not the reference of the list?', '<python><list><dictionary><reference>', '<p>Is there any way i can pass in only the values of a list to a dictionary and not the reference of the list?</p>\\n\\n<pre><code>*my_list = [1, 2, 3]\\nmy_dict = {\"list\": my_list}\\nprint(my_dict[\"list\"])\\nmy_list.pop()\\nprint(my_dict[\"list\"])*\\n</code></pre>\\n\\n<p>currently the output is:\\n[1, 2, 3]\\n[1, 2]</p>\\n\\n<p>i want it to be:\\n[1, 2, 3]\\n[1, 2, 3]</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Using an error as a condition in an if/then statement', '<python><if-statement>', '<p>I\\'m working on a knn function.  Within it, I already have a function that will return the indices of the k-nearest neighbors for a given data point, when that point is compared to the data set.  </p>\\n\\n<p>Now, I\\'m trying to get the actual classifier function to work but I\\'m having trouble with an if/then statement.  There\\'s no weighting to the nearest neighbors so it\\'s a majority vote and as such, calculating the mode should do it.  </p>\\n\\n<p>However, since \"k\" can be an even number, there\\'s a possibility of a tie, in which case, the nearest neighbor \"wins\" the vote.  </p>\\n\\n<p>So I\\'m basically trying to code the following:</p>\\n\\n<p>if the mode exists/\\'statistics.mode()\\' does not produce an error, then the doc will be classified by the mode</p>\\n\\n<p>else, the doc will be classified by the nearest neighbor.</p>\\n\\n<p>TIA for any help!\\nHere\\'s the code I have</p>\\n\\n<pre><code> def getPrediction(indices_of_nearest_neighbors, training_labels):\\n\\n    # get vector of \"votes\"\\n    nearest_Y = training_labels.iloc[indices_of_nearest_neighbors, 1].values     \\n\\n    if statistics.mode(nearest_Y) ##does not throw an error:\\n        doc_classification=statistics.mode(nearest_Y)\\n\\n    else doc_classification= training_labels.iloc[closest_neighbor,1]\\n\\n    return doc_classification\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Testing for even letters, why does indexing differ inside and outside my function?', '<python><function><indexing>', \"<p>The function: </p>\\n\\n<pre><code>def func(word):\\n    out=[]\\n    for i in word:\\n        if i in word[0::2]:\\n            out.append(i.upper())\\n    return out\\n</code></pre>\\n\\n<p>If I run </p>\\n\\n<pre><code>func('This is a string')\\n</code></pre>\\n\\n<p>This returns:</p>\\n\\n<pre><code>['T','I','S', ' ', 'I','S', ' ','A', ' ','S','R','I','N']\\n</code></pre>\\n\\n<p>which is what I expected when testing for every second letter from position 0.</p>\\n\\n<p>Whereas </p>\\n\\n<pre><code>mystring = 'This is a string'\\nmystring[0::2]\\n</code></pre>\\n\\n<p>Will return </p>\\n\\n<pre><code>'Ti sasrn'\\n</code></pre>\\n\\n<p>Please note the function is not my production code but a point of interest that I found and simplified. </p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Is there a way to find and set the DataType from CSV file, without specifying it prior?', '<python><csv><parsing><types>', '<p>I noticed an example by user647772 from <a href=\"https://stackoverflow.com/questions/11665628/read-data-from-csv-file-and-transform-from-string-to-correct-data-type-includin\">Reading Data from CSV file...</a></p>\\n<pre><code>data = &quot;&quot;&quot;True,foo,1,2.3,baz\\nFalse,bar,7,9.8,qux&quot;&quot;&quot;\\nreader = csv.reader(StringIO.StringIO(data), delimiter=&quot;,&quot;)\\nparsed = (({\\'True\\':True}.get(row[0], False),\\n       row[1],\\n       int(row[2]),\\n       float(row[3]),\\n       row[4])\\n      for row in reader)\\n getBackData = list(parsed)\\n</code></pre>\\n<p>I couldn\\'t find much for CSV Reader library related to code written for &quot;parsed&quot; variable. I\\'d really appreciate if somebody could point me to the correct documentation in python website.</p>\\n<p>Also, I am interested to know if there is a way I can determine the Data Type and set the value of variable parsed (above), at runtime. So, is the following implementation &quot;valid&quot; if I modify the code above like:</p>\\n<pre><code>parsed = &quot;((row[0], int(row[1]), int(row[2]), int(row[3]), row[4], row[5]) for row in rawReader)&quot;\\n</code></pre>\\n<p>and</p>\\n<pre><code>getBackData = list(eval((parsed)))\\n</code></pre>\\n<p>Or there is any better way?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Kivy Buildozer Returns errored out with exit status 1 in setup.py', '<python><kivy><buildozer>', \"<p>I am making an android application using kivy and kivymd. So i followed all the instructions on the documentation page of buildozer and I am facing an error. The modules that I have used are <code>kivy,kivymd,datetime,sqlite3</code>(All of which are written in pure python or contain a recipe).</p>\\n<p>I have typed all of this inside the buildozer.spec file.</p>\\n<p>I am running buildozer inside a virtual environment that has python 3.7 on the lastest release of Ubuntu(20)</p>\\n<p>This is what appear before the error:</p>\\n<pre><code>[INFO]:    -&gt; running python3 -m venv venv\\n[INFO]:    Upgrade pip to latest version\\n[INFO]:    -&gt; running bash -c source venv/bin/activate &amp;&amp; pip install -U pip\\n[INFO]:    Install Cython in case one of the modules needs it to build                                 \\n[INFO]:    -&gt; running bash -c venv/bin/pip install Cython\\n[INFO]:    Creating a requirements.txt file for the Python modules                                     \\n[INFO]:    Installing Python modules with pip\\n[INFO]:    IF THIS FAILS, THE MODULES MAY NEED A RECIPE. A reason for this is often modules       compiling native code that is unaware of Android cross-compilation and does not work without additional changes / workarounds.\\n[INFO]:    -&gt; running bash -c venv/bin/pip install -v --target '/home/guhan/...(and 146 more)\\nworking: Removed build tracker: '/tmp/pip-req-tracker-e95kbahw'\\n</code></pre>\\n<p><strong>And this is the errors after that</strong></p>\\n<pre><code>Exception information:\\nTraceback (most recent call last):\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/cli/base_command.py&quot;, line 216, in _main\\n   status = self.run(options, args)\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/cli/req_command.py&quot;, line 182, in wrapper\\n   return func(self, options, args)\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/commands/install.py&quot;, line 324, in run\\n   requirement_set = resolver.resolve(\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py&quot;, line 183, in resolve\\n   discovered_reqs.extend(self._resolve_one(requirement_set, req))\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py&quot;, line 388, in _resolve_one\\n   abstract_dist = self._get_abstract_dist_for(req_to_install)\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py&quot;, line 340, in _get_abstract_dist_for\\n   abstract_dist = self.preparer.prepare_linked_requirement(req)\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py&quot;, line 482, in prepare_linked_requirement\\n   abstract_dist = _get_prepared_distribution(\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/operations/prepare.py&quot;, line 91, in _get_prepared_distribution\\n   abstract_dist.prepare_distribution_metadata(finder, build_isolation)\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/distributions/sdist.py&quot;, line 40, in prepare_distribution_metadata\\n   self.req.prepare_metadata()\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/req/req_install.py&quot;, line 554, in prepare_metadata\\n   self.metadata_directory = self._generate_metadata()\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/req/req_install.py&quot;, line 529, in _generate_metadata\\n   return generate_metadata_legacy(\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/operations/build/metadata_legacy.py&quot;, line 70, in generate_metadata\\n   call_subprocess(\\n File &quot;/home/guhan/Documents/Program-files/Remainder_App/.buildozer/android/platform/build-armeabi-v7a/build/venv/lib/python3.8/site-packages/pip/_internal/utils/subprocess.py&quot;, line 242, in call_subprocess\\n   raise InstallationError(exc_msg)\\npip._internal.exceptions.InstallationError: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\\nRemoved ast from https://files.pythonhosted.org/packages/4b/fb/2b954d2a38c9a0ef1da6a46737a75b4dbf6f60e5dad0f267a4ec5ece20de/AST-0.0.2.tar.gz#sha256=dc5b79c6ba11aea72c59c791a0bc5ae483b4c18fec6f643002d6fae24361eba0 (from -r requirements.txt (line 1)) from build tracker '/tmp/pip-req-tracker-e95kbahw'\\nRemoved build tracker: '/tmp/pip-req-tracker-e95kbahw'\\n</code></pre>\\n<p>The same error apears twice in the log</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('PANDAS reading dataframe from file properly', '<python><pandas>', \"<p>my file(text file) looks like:</p>\\n<pre><code> -1         1 2.99988E-02-4.93580E-17 4.28928E-17-2.01725E-16 4.57184E-18 1.54030E-16\\n -1         2 2.99988E-02-4.93581E-17-3.85396E-17-2.02655E-16-4.41397E-17-2.23963E-16\\n -1         3 2.99988E-02 2.47173E-17 4.28930E-17 1.60350E-16 5.28503E-17 1.53007E-16\\n...\\n\\n</code></pre>\\n<p>i want to create a dataframe with header and index, so that it looks like:</p>\\n<pre><code>  0 1          2            3          4            5           6   \\n0 1 2.99988E-02-4.62001E-17 3.51002E-17-1.90612E-16 1.52704E-17 1.41065E-16\\n1 2 2.99988E-02-4.62001E-17-2.81042E-17-1.88765E-16-3.45762E-17-2.06278E-16\\n...\\n\\n</code></pre>\\n<p>i tried this but it didnt work out:</p>\\n<pre><code>df = pd.read_table(file_dir, delim_whitespace=True, header=None)\\n\\nand\\n\\ndf = pd.read_table(file_dir, sep='s+', header=None)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python shapely polygon line intersection', '<python><intersection><shapely>', \"<p>I'm currently working on a small script that calculates the reflection of a ray at a wall of a building in 2D. Therefor I'm using the shapely.geometry.intersection methods which is doing it's job really well. To calculate the reflection ray i need the exact LineString of the certain wall to calculate the normal of it.</p>\\n<p>Currently I'm splitting the polygon into each of its exterior LineStrings and looking for a intersection.</p>\\n<p>Is there any other way to get the intersected boundary without splitting the polygon?</p>\\n<p>Thanks for your help :)</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Visiting nodes in a syntax tree with Python ast module', '<python><parsing><abstract-syntax-tree>', '<p>I\\'m playing with python ast (abstract syntax tree). </p>\\n\\n<p>I wrote the following and it visited all nodes of the AST.</p>\\n\\n<pre><code>import ast\\n\\nclass Py2Neko(ast.NodeVisitor):\\n    def generic_visit(self, node):\\n              print type(node).__name__\\n              ast.NodeVisitor.generic_visit(self, node)\\n\\n       def visit_Name(self, node):\\n              print \\'Name :\\', node.id\\n\\n       def visit_Num(self, node):\\n              print \\'Num :\\', node.__dict__[\\'n\\']\\n\\n       def visit_Str(self, node):\\n              print \"Str :\", node.s\\n\\nif __name__ == \\'__main__\\':\\n\\n    node = ast.parse(\"a = 1 + 2\")\\n\\n    print ast.dump(node)\\n\\n    v = Py2Neko()\\n    v.visit(node)\\n</code></pre>\\n\\n<p>Then added some methods to Py2Neko class</p>\\n\\n<pre><code>def visit_Print(self, node):\\n    print \"Print :\"\\n\\ndef visit_Assign(self, node):\\n    print \"Assign :\"\\n\\ndef visit_Expr(self, node):\\n    print \"Expr :\"\\n</code></pre>\\n\\n<p>But then when it encounters a \"print\" statement or an assignement or an expression it seems that it stops and isn\\'t going further.</p>\\n\\n<p>It outputs:</p>\\n\\n<pre><code>Module(body=[Assign(targets=[Name(id=\\'a\\', ctx=Store())], value=BinOp(left=Num(n=1), op=Add(),       right=Num(n=2)))])\\nModule\\nAssign :\\n</code></pre>\\n\\n<p>Can someone tell me what I did wrong.</p>\\n\\n<p>I\\'m using Python 2.6.6</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Can SQLAlchemy be configured to be non-blocking?', '<python><database><asynchronous><sqlalchemy><nonblocking>', \"<p>I'm under the impression that database calls through SQLAlchemy will block and aren't suitable for use in anything other than synchronous code. Am I correct (I hope I'm not!) or is there a way to configure it to be non-blocking?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('append a list into end of list in list', '<python><list><2d>', \"<p>Is there a good way to 'merge' 2 lists together so an item in one list can be appended to the end of a list in a list? For example...</p>\\n\\n<pre><code>a2dList=[['a','1','2','3','4'],['b','5','6','7','8'],[........]]\\notherList = [9,8,7,6,5]\\n\\ntheFinalList=[['a','1','2','3','4',9],['b','5','6','7','8',8],[....]]\\n</code></pre>\\n\\n<p>I'm not sure if it matter that a2dList is made of strings and otherList are numbers...\\nI've tried <code>append</code> but I end up with </p>\\n\\n<pre><code>theFinalList=[['a','1','2','3','4'],['b','5','6','7','8'],[.......],[9,8,7,6,5]\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('os.walk folder exclusion based on .txt file', '<python>', '<p>I would like to have a <code>Folders_To_Skip.txt</code> file with a list of directories separated by new lines</p>\\n\\n<p>ex:</p>\\n\\n<pre><code>A:\\\\\\\\stuff\\\\a\\\\b\\\\\\nA:\\\\\\\\junk\\\\a\\\\b\\\\\\n</code></pre>\\n\\n<p>I have files which are breaking my .csv record compiling that this is used for and I want to exclude directories which I have no use for reading anyway. </p>\\n\\n<p>In the <code>locate</code> function I have what I tried to implement from <a href=\"https://stackoverflow.com/questions/19859840/excluding-directories-in-os-walk\">Excluding directories in os.walk</a> but I can\\'t seem to get it to work with directories in a <code>list</code> let alone while reading from a text file list as when I <code>print</code> files accessed it still includes files in the directories I attempted to exclude. </p>\\n\\n<p>Could you also explain whether the solution would be specific excluded directories (not the end of the world) or if it can be operated to exclude subdirectories (would be more convenient). </p>\\n\\n<p>Right now the code preceding <code>locate</code> allows for easy lookup of controlling text files and then loading those items in as lists for the rest of the script to run, with the assumption that all control files are in the same location but  that location can change based on who is running the script and from where.</p>\\n\\n<p>Also for testing purposes <code>Drive_Locations.txt</code> is setup as:</p>\\n\\n<pre><code>A\\nB\\n</code></pre>\\n\\n<p>Here is the current script:</p>\\n\\n<pre><code>import os\\nfrom tkinter import filedialog\\nimport fnmatch\\n\\ninput(\\'Press Enter to select any file in writing directory or associated control files...\\')\\nfname = filedialog.askopenfilename()\\nfpath = os.path.split(fname)\\n\\n# Set location for Drive Locations to scan\\nDisk_Locations = os.path.join(fpath[0], r\\'Drive_Locations.txt\\')\\n# Set location for Folders to ignore such as program files\\nIgnore = os.path.join(fpath[0], r\\'Folders_To_Skip.txt\\')\\n\\n# Opens list of Drive Locations to be sampled\\nwith open(Disk_Locations, \\'r\\') as Drives:\\n    Drive = Drives.readlines()\\n    Drive = [x.replace(\\'\\\\n\\', \\'\\') for x in Drive]\\n# Iterable list for directories to be excluded\\nwith open(Ignore, \\'r\\') as SkipF1:\\n    Skip_Fld = SkipF1.readlines()\\n    Skip_Fld = [x.replace(\\'\\\\n\\', \\'\\') for x in Skip_Fld]\\n\\n# Locates file in entire file tree from previously established parent directory.\\ndef locate(pattern, root=os.curdir):\\n    for path, dirs, files in os.walk(os.path.abspath(root), topdown=True):\\n        dirs[:] = [d for d in dirs if d not in Skip_Fld]\\n        for filename in fnmatch.filter(files, pattern):\\n            yield os.path.join(path, filename)\\n\\nfor disk in Drive:\\n    # Formats Drive Location for acceptance\\n    disk = str.upper(disk)\\n    if str.find(disk, \\':\\') &lt; 0:\\n        disk = disk + \\':\\'\\n    # Changes the current disk drive\\n    if os.path.exists(disk):\\n        os.chdir(disk)\\n    # If disk incorrect skip to next disk\\n    else:\\n        continue\\n    for exist_csv in locate(\\'*.csv\\'):\\n        # Skip compiled record output files in search\\n            print(exist_csv)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('The most efficient way to store a very large 2D array in Python/MicroPython', '<python><arrays><embedded><micropython>', '<p>I have a project in an embedded system (NodeMCU running MicroPython), where I need to store a very large array of variables, which have values of either 0 or 1. I need to be able to read/write them individually or via loops in a convenient way. For this example, I am filling the array with random integers between 0 and 1:</p>\\n\\n<pre><code>N = 50\\ntable = [[randInt(0,1) for i in range(N)] for j in range(N)]\\n</code></pre>\\n\\n<p>On my NodeMCU, even such a small array (2500 items) is enough to exceed the NodeMCU memory limits, crashing my script. I suppose this is because that in Python, int is an object with a lot of overhead. Since in my case I do not need the capacity of int variable - actually, 0 or 1 could be stored as a bit - how can I create and fill an array with the least-memory-consuming variables? Say, like in this example, randomizing between 0 and 1. I reviewed the <a href=\"https://www.sutron.com/micropython/html/library/uctypes.html\" rel=\"nofollow noreferrer\">uctypes</a>, but as I\\'m new to Python, I couldn\\'t get these to work. Or is there another way? How can create such an array with the least memory usage possible?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Error: TypeError: can't multiply sequence by non-int of type 'numpy.float64' <Figure size 432x288 with 0 Axes> (don't know what to do)\", '<python><numpy><scipy>', \"<p>I'm trying to plot an equation that contains and definite integral. It is a photoionisation cross section associated with the intersubband transitions in a two-dimensional quantum ring. I made the angular part analytically, and I'm trying to calculate numerically the radial part. </p>\\n\\n<p>Here's my attempt to implement this in a Python code:</p>\\n\\n<pre><code>from scipy.integrate import quad\\nimport numpy as np\\nfrom scipy.special import gamma\\nfrom scipy.constants import alpha\\nimport matplotlib.pyplot as plt\\n\\n#Constants\\nepsilon = 13.1 #dielectric constant of the material\\ngamma_C = 0.5 # donor impurity linewidth \\nnr = 3.2 #refractive index of semiconductor\\nflux = 0  # Phi in eqn 8 magnetic flux\\nR = 5  #radius of the qunatum ring in nm\\nr = np.linspace(0, 6 * R)\\nrho = r / R\\nm_0 = 0.0067*0.511 # electron effective mass\\nh = 4.13e-15 # Planck constant in eV\\nhbar =  6.58e-16 # reduced Planck constant in eV\\n#Photon energy\\nhnu = np.linspace(0, 100) #in eV\\n\\n\\n#Function that calculates the integrand\\ndef func(rho):\\n    betai = np.sqrt( gama**4/4)\\n    betaf = np.sqrt(1+gama**4/2)\\n    return ((gama * rho)**(betai + betaf) *\\n            np.exp(-1/2*(gama * rho)**2) \\n         * (gama * rho)**2/2   ) \\n\\ndef cross_section(hnu, gama):\\n    #function that calculates the photoionisation cross section\\n    betai = np.sqrt( gama**4/4)\\n    betaf = np.sqrt(1+gama**4/2)\\n    Ei = gama**2*(1+betai)-gama**4/2\\n    Ef = gama**2*(3+betaf)-gama**4/2\\n    return (nr/epsilon * 4*np.pi/3 * alpha * hnu *\\n            (abs(R * np.sqrt(1/2**betai*gamma(betai + 1))*\\n            np.sqrt(1/2**betaf*gamma(betaf + 1)) *\\n            quad(func, 0, np.infty))**2 * \\n             hbar * gamma_C/(Ef - Ei - hnu)**2 + ( hbar * gamma_C)**2))\\n\\n#Plot\\n\\nplt.figure();plt.clf()\\n\\nfor gama in [1.0, 1.5, 2.0]:\\n    plt.plot(hnu, cross_section(hnu, gama))\\n</code></pre>\\n\\n<p>But I keep receiving this error</p>\\n\\n<pre><code>TypeError: can't multiply sequence by non-int of type 'numpy.float64'\\n</code></pre>\\n\\n<p></p>\\n\\n<p>Anyone knows the cause and how can avoid this?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Filtering in pandas dataframe is not working', '<python><pandas><csv>', '<p>I\\'m trying to combine 3 CSV into one by using panda data frame. Consider below example</p>\\n<p><a href=\"https://i.stack.imgur.com/oG28i.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/oG28i.png\" alt=\"data1.csv\" /></a>\\n<a href=\"https://i.stack.imgur.com/Im0re.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Im0re.png\" alt=\"data2.csv\" /></a>\\n<a href=\"https://i.stack.imgur.com/CFUKO.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CFUKO.png\" alt=\"data3.csv\" /></a></p>\\n<p>So I need to combine above the csv into one. This is implemented using below code</p>\\n<pre><code>if os.path.isfile(data1.csv) and os.path.isfile(data2.csv) and os.path.isfile(data3.csv):\\n    df1 = pd.read_csv(data1.csv)\\n    df2 = pd.read_csv(data2.csv)\\n    df3 = pd.read_csv(data3.csv)\\n    self.combined_data_frame = pd.concat([df1, df2, df3], ignore_index=True)\\n    self.combined_data_frame = pd.DataFrame(self.combined_data_frame, columns=[\\'col1\\', \\'col2\\', \\'col3\\'])\\n    result = self.combined_data_frame.loc[(self.combined_data_frame[\\'col3\\'] == \\'FALSE\\')]\\n    result.to_csv(data4.csv)\\n</code></pre>\\n<p>Even though am able to combine the CSV into one, could not filter the rows based on the condition. When I tried above code snippet I got below warning and data4.csv does not contain anything except the headers</p>\\n<pre><code>(venv) C:\\\\Users\\\\edward_arrow\\\\path_to_location&gt;python runscript.py\\nC:\\\\Users\\\\edward_arrow\\\\path_to_location\\\\venv\\\\lib\\\\site-packages\\\\pa\\nndas\\\\core\\\\computation\\\\expressions.py:68: FutureWarning: elementwise comparison f\\nailed; returning scalar instead, but in the future will perform elementwise comp\\narison\\n  return op(a, b)\\n</code></pre>\\n<p>May I know how can I resolve this issue in order to achieve my requirement or else is there any other method to implement using python.</p>\\n<p>Your  hints &amp; solution are appreciated\\n#UPDATE\\nThis is the excepted output\\n<a href=\"https://i.stack.imgur.com/kBH5e.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/kBH5e.png\" alt=\"final output\" /></a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Your most unpythonic code snippet', '<python>', \"<p>I am an experienced developer new to python, and still catching myself writing correct but unpythonic code. I thought it might be enlightening and entertaining to see small examples of python code people have written that in some way clashes with the generally preffered way of doing things. </p>\\n\\n<p>I'm interested in code you actually wrote rather than invented examples. Here is one of mine: In code that was expecting a sequence that could be empty or None I had</p>\\n\\n<pre><code>if data is not None and len(data) &gt; 0:\\n</code></pre>\\n\\n<p>I later reduced that to</p>\\n\\n<pre><code>if data:\\n</code></pre>\\n\\n<p>The simpler version allows additional true values like True or 10, but that's ok because the caller made a mistake and will get an exception from the statements within the if.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python Equivalent to phpinfo()', '<python><phpinfo>', '<p>Quite simply, is there a <a href=\"http://www.python.org/\" rel=\"nofollow noreferrer\">python</a> equivalent to php\\'s <a href=\"http://php.net/manual/en/function.phpinfo.php\" rel=\"nofollow noreferrer\"><code>phpinfo();</code></a>? If so, what is it and how do I use it (a link to a reference page would work great). </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Extract Words from a file', '<python>', '<p>I open a file using python to find whether a predefined set of words are present in the opened file or not. I took the predefined set of words in a list and opened the file that has to be tested. Now is there any method to extract words in python rather than lines. Thats makes my work lot easier.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Difference in peak dB value between sound forge spectrum analysis and Welch Sectrogram using python', '<python><signal-processing><fft><psd><spectrum>', \"<p>Using welch Average spectrum for the audio signal using <code>scipy.signal.welch()</code> function python. I am verifying the same using the Sound forge spectrum analysis. Peak values between the python code and sound forge is not matching. I am getting the difference of 10 db. that is with python code i am getting 10 db lee when compare to sound forge tool. </p>\\n\\n<p>Please let me know how to solve this issue. </p>\\n\\n<p>Function used to compute the spectrum analysis in python. </p>\\n\\n<pre><code>scipy.signal.welch(x, fs=1.0, window='hanning', nperseg=256, noverlap=None, nfft=None, detrend='constant', return_onesided=True, scaling='density', axis=-1)\\n</code></pre>\\n\\n<p>when I compute the peak value of spectrum obtained from above function I am getting 10db less than soundforge value.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('creating mysql tables id best pratice', '<python><mysql><sql>', '<p>I am coding a new python (version 3.8.2) project with a mysql(8.0.19) db.<br>\\nThis is the table creation code:  </p>\\n\\n<pre><code>    import mysql.connector\\n\\nmydb = mysql.connector.connect(\\n    host = \"localhost\",\\n    user = \"root\",\\n    password = \"mypassword\",\\n    database = \"acme_db\"\\n)\\n\\nmycursor = mydb.cursor()\\n\\nsql_formula = (\"CREATE TABLE employee (employee_id INT AUTO_INCREMENT PRIMARY KEY,\"\\n                                        \"first_name VARCHAR(255),\"\\n                                        \"last_name VARCHAR(255),\"\\n                                        \"email VARCHAR(255),\"\\n                                        \"phone_nr VARCHAR(255),\"\\n                                        \"hire_date DATE,\"\\n                                        \"job_id INTEGER,\"\\n                                        \"salary NUMERIC(8,2),\"\\n                                        \"commission_pct NUMERIC(8,2),\"\\n                                        \"manager_id INTEGER,\"\\n                                        \"department_id INTEGER)\")\\nmycursor.execute(sql_formula)\\n\\nmycursor.execute(\"CREATE TABLE jobs (job_id INT, job VARCHAR(255))\")\\n\\nmycursor.execute(\"CREATE TABLE managers (manager_id INT, employee_id INTEGER)\")\\n\\nmycursor.execute(\"CREATE TABLE departments (department_id INT, department_name VARCHAR(255))\")\\n</code></pre>\\n\\n<p>The question is, what is the best practice about id?<br>\\nWhat I mean is this, employee_id is unique auto increment pk, that I understand, what about the other id\\'s? for tables jobs, managers and departments.<br>\\nShouldn\\'t they be also the same as employee_id definition or just INT and I need to take care of the number, that it doesn\\'t repeat itself, and so on?<br>\\nI did make all id\\'s the same definition but I coudn\\'t insert data to the tables:  </p>\\n\\n<pre><code>dptFormula = \"INSERT INTO depatments (department_name) VALUES (%s)\"\\nacme_departments = [(\"Accounting\"),(\"R&amp;D\"),(\"Support\")]\\nmycursor.executemany(dptFormula, acme_departments)\\n</code></pre>\\n\\n<p>I got:  </p>\\n\\n<pre><code>Traceback (most recent call last):\\n  File \"c:/Users/Daniel/EmployeeProject/employee_mgt/insert_into.py\", line 20, in &lt;module&gt;\\n    mycursor.executemany(dptFormula, acme_departments)\\n  File \"C:\\\\Program Files\\\\Python38\\\\lib\\\\site-packages\\\\mysql\\\\connector\\\\cursor.py\", line 668, in executemany\\n    stmt = self._batch_insert(operation, seq_params)\\n  File \"C:\\\\Program Files\\\\Python38\\\\lib\\\\site-packages\\\\mysql\\\\connector\\\\cursor.py\", line 613, in _batch_insert\\n    raise errors.ProgrammingError(\\nmysql.connector.errors.ProgrammingError: Not all parameters were used in the SQL statement\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('python: generating a histogram', '<python>', \"<p>this:</p>\\n\\n<pre><code> numpy.histogram([1,3,2,3,1,1,1,1,2,3,2,5,6,6],bins=numpy.arange(0,7,1))\\n</code></pre>\\n\\n<p>yields:</p>\\n\\n<pre><code>(array([0, 5, 3, 3, 0, 3]), array([0, 1, 2, 3, 4, 5, 6]))\\n</code></pre>\\n\\n<p>why does it count three 6's? there are only 2!</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to create a list or tuple of empty lists in Python?', '<memory-management><python>', '<p>I need to incrementally fill a list or a tuple of lists. Something that looks like this:</p>\\n\\n<pre><code>result = []\\nfirstTime = True\\nfor i in range(x):\\n    for j in someListOfElements:\\n        if firstTime:\\n            result.append([f(j)])\\n        else:\\n            result[i].append(j)\\n</code></pre>\\n\\n<p>In order to make it less verbose an more elegant, I thought I will preallocate a list of empty lists</p>\\n\\n<pre><code>result = createListOfEmptyLists(x)\\nfor i in range(x):\\n    for j in someListOfElements:\\n        result[i].append(j)\\n</code></pre>\\n\\n<p>The preallocation part isn\\'t obvious to me. When I do <code>result = [[]] * x</code>, I receive a list of <code>x</code> references to the same list, so that the output of the following</p>\\n\\n<pre><code>result[0].append(10)\\nprint result\\n</code></pre>\\n\\n<p>is:</p>\\n\\n<pre><code>[[10], [10], [10], [10], [10], [10], [10], [10], [10], [10]]\\n</code></pre>\\n\\n<p>I can use a loop (<code>result = [[] for i in range(x)]</code>), but I wonder whether a \"loopless\" solution exists.</p>\\n\\n<p>Is the only way to get what I\\'m looking for </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Pyinstaller-created app crashes on a different computer', '<python><macos><pyinstaller>', '<p>I\\'m making a wxpython-based App for MacOS, and packaging it with pyinstaller. \\nIt seems to work on my machine, and on another machine, but crashes when I send it to my user.</p>\\n\\n<p>I initially posted here: <a href=\"https://stackoverflow.com/questions/24129747/macos-app-bundle-built-with-pyinstaller-crashes-on-another-mac\">https://stackoverflow.com/questions/24129747/macos-app-bundle-built-with-pyinstaller-crashes-on-another-mac</a>, but then just tried to package a simple app and see if it would work, but the results are the same. I have Mac OS X 10.9.2, python 2.7.5, wxpython 2.9.5 and the latest development pyinstaller. The app did work on another machine, Mac OS X 10.9.3. However, when I sent it to my user who has Mac OS 10.8.5, the app crashes with Segmentation fault 11:</p>\\n\\n<pre><code>idm2277:~ mdutra$ /Users/mdutra/Desktop/Test.app/Contents/MacOS/test ; exit;\\nSegmentation fault: 11\\nlogout\\n\\n[Process completed]\\n</code></pre>\\n\\n<p>Here is a simple script test.py that creates a hello window:</p>\\n\\n<pre><code>import wx\\napp = wx.App(False)\\nframe = wx.Frame(None,wx.ID_ANY,\"Hello!\")\\nframe.Show(True)\\ncontrol = wx.StaticText(frame,label = \"Test successful!\")\\napp.MainLoop()\\n</code></pre>\\n\\n<p>And here is the specification my.spec, which I run as follows: </p>\\n\\n<p><code>python {path_to_pyinstaller_folder}/pyinstaller.py --windowed my.spec</code></p>\\n\\n<pre><code>import os\\nsrc =\\'/Users/ojy/test\\'\\ndist = \\'/Users/ojy/test/bin\\'\\nicn = \\'/Users/ojy/icon.icns\\'\\n\\na = Analysis([os.path.join(src,\\'test.py\\')],\\n         pathex=[dist],\\n         hiddenimports=[],\\n         hookspath=None,\\n         runtime_hooks=None)\\npyz = PYZ(a.pure)\\nexe = EXE(pyz,\\n      a.scripts,\\n      exclude_binaries=True,\\n      name=\\'test\\',\\n      debug=False,\\n      strip=None,\\n      upx=True,\\n      console=False )\\ncoll = COLLECT(exe,\\n           a.binaries,\\n           a.zipfiles,\\n           a.datas,\\n           strip=None,\\n           upx=True,\\n           name=\\'Test\\')\\napp = BUNDLE(coll,\\n         name=\\'Test.app\\',\\n         icon=icn)\\n</code></pre>\\n\\n<p>Any ideas why it happens and how to fix it?</p>\\n\\n<p>Crash log (the complete file didn\\'t meet the size limitation, so I replaced the middle chunk with ....), but I can add the whole thing if necessary.</p>\\n\\n<pre><code>Process:         test [9701]\\nPath:            /Users/USER/Desktop/Test.app/Contents/MacOS/test\\nIdentifier:      test\\nVersion:         0.0.0 (???)\\nCode Type:       X86-64 (Native)\\nParent Process:  bash [9698]\\nUser ID:         502\\n\\nDate/Time:       2014-06-09 17:13:40.558 -0700\\nOS Version:      Mac OS X 10.8.5 (12F45)\\nReport Version:  10\\n\\nCrashes Since Last Report:           1\\nPer-App Crashes Since Last Report:   1\\nAnonymous UUID:                      D034FFD8-9A64-DFC6-DC85-9FD7B4DD8F61\\n\\nCrashed Thread:  0  Dispatch queue: com.apple.main-thread\\n\\nException Type:  EXC_CRASH (SIGSEGV)\\nException Codes: 0x0000000000000000, 0x0000000000000000\\n\\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\\n0   libsystem_kernel.dylib          0x00007fff8a40cd46 __kill + 10\\n1   test                            0x000000010f924c18 0x10f922000 + 11288\\n2   test                            0x000000010f937bed 0x10f922000 + 89069\\n3   test                            0x000000010f923454 0x10f922000 + 5204\\n\\nThread 1:\\n0   libsystem_kernel.dylib          0x00007fff8a40d6d6 __workq_kernreturn + 10\\n1   libsystem_c.dylib               0x00007fff91036f1c _pthread_workq_return + 25\\n2   libsystem_c.dylib               0x00007fff91036ce3 _pthread_wqthread + 412\\n3   libsystem_c.dylib               0x00007fff91021191 start_wqthread + 13\\n\\nThread 2:: Dispatch queue: com.apple.libdispatch-manager\\n0   libsystem_kernel.dylib          0x00007fff8a40dd16 kevent + 10\\n1   libdispatch.dylib               0x00007fff92b67dea _dispatch_mgr_invoke + 883\\n2   libdispatch.dylib               0x00007fff92b679ee _dispatch_mgr_thread + 54\\n\\nThread 3:\\n0   libsystem_kernel.dylib          0x00007fff8a40d6d6 __workq_kernreturn + 10\\n1   libsystem_c.dylib               0x00007fff91036f1c _pthread_workq_return + 25\\n2   libsystem_c.dylib               0x00007fff91036ce3 _pthread_wqthread + 412\\n3   libsystem_c.dylib               0x00007fff91021191 start_wqthread + 13\\n\\nThread 0 crashed with X86 Thread State (64-bit):\\nrax: 0x0000000000000000  rbx: 0x0000000000000001  rcx: 0x00007fff502dcf28  rdx: 0x0000000000000000\\nrdi: 0x00000000000025e5  rsi: 0x000000000000000b  rbp: 0x00007fff502dcf80  rsp: 0x00007fff502dcf28\\nr8: 0x0000000000000003   r9: 0x0000000035447f8c  r10: 0x00000000000fc080  r11: 0x0000000000000206\\nr12: 0x00007fff502ddd00  r13: 0x00007fa5d2c0e920  r14: 0x0000000000000000  r15: 0x0000000000000001\\nrip: 0x00007fff8a40cd46  rfl: 0x0000000000000206  cr2: 0x00007fa5d2c0f9a0\\nLogical CPU: 0\\n\\nBinary Images:\\n   0x10f922000 -        0x10f93eff7 +test (0.0.0 - ???) &lt;C371E49E-CC99-3791-8965-4D3EE55AD3BF&gt; /Users/USER/Desktop/Test.app/Contents/MacOS/test\\n0x7fff6f522000 -     0x7fff6f55693f  dyld (210.2.3) &lt;6900F2BA-DB48-3B78-B668-58FC0CF6BCB8&gt; /usr/lib/dyld\\n0x7fff89c71000 -     0x7fff89dc3fff  com.apple.audio.toolbox.AudioToolbox (1.9.2 - 1.9.2) &lt;DC5F3D1B-036A-37DE-BC24-7636DC95EA1C&gt; /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox\\n0x7fff89dc4000 -     0x7fff89e89ff7  com.apple.coreui (2.0 - 181.1) &lt;83D2C92D-6842-3C9D-9289-39D5B4554C3A&gt; /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI\\n0x7fff89e8a000 -     0x7fff8a15bfff  com.apple.security (7.0 - 55179.16.1) &lt;49A6A8FD-124D-30E0-94C3-C73F8C9469E6&gt; /System/Library/Frameworks/Security.framework/Versions/A/Security\\n0x7fff8a335000 -     0x7fff8a35dfff  libJPEG.dylib (852) &lt;4E159C31-1B41-3EFF-89EC-3F7BC9053F2C&gt; /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib\\n0x7fff8a3be000 -     0x7fff8a3c4fff  libmacho.dylib (829) &lt;BF332AD9-E89F-387E-92A4-6E1AB74BD4D9&gt; /usr/lib/system/libmacho.dylib\\n0x7fff8a3c5000 -     0x7fff8a3e5fff  libPng.dylib (852) &lt;CCBFA9A9-33C0-3189-AFE0-A77E831EEBA8&gt; /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib\\n0x7fff8a3fb000 -     0x7fff8a416ff7  libsystem_kernel.dylib (2050.48.12) &lt;4B7993C3-F62D-3AC1-AF92-414A0D6EED5E&gt; /usr/lib/system/libsystem_kernel.dylib\\n0x7fff8a417000 -     0x7fff8a43efff  com.apple.framework.familycontrols (4.1 - 410) &lt;50F5A52C-8FB6-300A-977D-5CFDE4D5796B&gt; /System/Library/PrivateFrameworks/FamilyControls.framework/Versions/A/FamilyControls\\n0x7fff8a43f000 -     0x7fff8a519fff  com.apple.backup.framework (1.4.3 - 1.4.3) &lt;6B65C44C-7777-3331-AD9D-438D10AAC777&gt; /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup\\n0x7fff8a51a000 -     0x7fff8a633fff  com.apple.ImageIO.framework (3.2.2 - 852) &lt;1D023BCE-1FA2-3743-B449-7489BC0C5C43&gt; /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO\\n0x7fff8a634000 -     0x7fff8a655fff  com.apple.Ubiquity (1.2 - 243.15) &lt;C9A7EE77-B637-3676-B667-C0843BBB0409&gt; /System/Library/PrivateFrameworks/Ubiquity.framework/Versions/A/Ubiquity\\n0x7fff8a6e0000 -     0x7fff8a6e4ff7  com.apple.CommonPanels (1.2.5 - 94) &lt;AAC003DE-2D6E-38B7-B66B-1F3DA91E7245&gt; /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels\\n0x7fff8a6e5000 -     0x7fff8a73aff7  libTIFF.dylib (852) &lt;0CA1662F-EB05-34DE-B9BA-0A03EC59B846&gt; /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib\\n.....\\n.....\\n0x7fff93654000 -     0x7fff936d5fff  com.apple.Metadata (10.7.0 - 707.12) &lt;69E3EEF7-8B7B-3652-8320-B8E885370E56&gt; /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata\\n0x7fff936d6000 -     0x7fff93735fff  com.apple.AE (645.6 - 645.6) &lt;44F403C1-660A-3543-AB9C-3902E02F936F&gt; /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE\\n0x7fff93754000 -     0x7fff93759fff  libcompiler_rt.dylib (30) &lt;08F8731D-5961-39F1-AD00-4590321D24A9&gt; /usr/lib/system/libcompiler_rt.dylib\\n0x7fff937ef000 -     0x7fff93a24ff7  com.apple.CoreData (106.1 - 407.7) &lt;A676E1A4-2144-376B-92B8-B450DD1D78E5&gt; /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData\\n0x7fff93a60000 -     0x7fff93abcff7  com.apple.Symbolication (1.3 - 93) &lt;D5044687-E424-31CF-B120-667143E6B9C1&gt; /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication\\n0x7fff93af0000 -     0x7fff93af4fff  libCoreVMClient.dylib (32.5) &lt;DB009CD4-BB0E-3331-BBB4-A118781D193F&gt; /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib\\n0x7fff93af5000 -     0x7fff93af6fff  liblangid.dylib (116) &lt;864C409D-D56B-383E-9B44-A435A47F2346&gt; /usr/lib/liblangid.dylib\\n0x7fff93af7000 -     0x7fff93b95ff7  com.apple.ink.framework (10.8.2 - 150) &lt;3D8D16A2-7E01-3EA1-B637-83A36D353308&gt; /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink\\n0x7fff93fc9000 -     0x7fff94086ff7  com.apple.ColorSync (4.8.0 - 4.8.0) &lt;6CE333AE-EDDB-3768-9598-9DB38041DC55&gt; /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSync.framework/Versions/A/ColorSync\\n0x7fff94087000 -     0x7fff94087fff  com.apple.vecLib (3.8 - vecLib 3.8) &lt;6CBBFDC4-415C-3910-9558-B67176447789&gt; /System/Library/Frameworks/vecLib.framework/Versions/A/vecLib\\n0x7fff94088000 -     0x7fff940a7ff7  com.apple.ChunkingLibrary (2.0 - 133.3) &lt;8BEC9AFB-DCAA-37E8-A5AB-24422B234ECF&gt; /System/Library/PrivateFrameworks/ChunkingLibrary.framework/Versions/A/ChunkingLibrary\\n0x7fff940a8000 -     0x7fff944c5fff  FaceCoreLight (2.4.1) &lt;DDAFFD7A-D312-3407-A010-5AEF3E17831B&gt; /System/Library/PrivateFrameworks/FaceCoreLight.framework/Versions/A/FaceCoreLight\\n0x7fff9453b000 -     0x7fff94541fff  com.apple.DiskArbitration (2.5.2 - 2.5.2) &lt;C713A35A-360E-36CE-AC0A-25C86A3F50CA&gt; /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration\\n0x7fff9455e000 -     0x7fff94562fff  libpam.2.dylib (20) &lt;C8F45864-5B58-3237-87E1-2C258A1D73B8&gt; /usr/lib/libpam.2.dylib\\n0x7fff94563000 -     0x7fff94566fff  libRadiance.dylib (852) &lt;139962CD-21E2-3D31-9F47-D5F2D6C2C2BC&gt; /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib\\n0x7fff94567000 -     0x7fff94589ff7  libxpc.dylib (140.43) &lt;70BC645B-6952-3264-930C-C835010CCEF9&gt; /usr/lib/system/libxpc.dylib\\n0x7fff9465e000 -     0x7fff946a8ff7  libGLU.dylib (8.10.1) &lt;6699DEA6-9EEB-3B84-A57F-B25AE44EC584&gt; /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib\\n0x7fff94eff000 -     0x7fff94efffff  libkeymgr.dylib (25) &lt;CC9E3394-BE16-397F-926B-E579B60EE429&gt; /usr/lib/system/libkeymgr.dylib\\n0x7fff94f00000 -     0x7fff94f0fff7  libxar.1.dylib (105) &lt;370ED355-E516-311E-BAFD-D80633A84BE1&gt; /usr/lib/libxar.1.dylib\\n0x7fff94f4c000 -     0x7fff94f98ff7  libauto.dylib (185.4) &lt;AD5A4CE7-CB53-313C-9FAE-673303CC2D35&gt; /usr/lib/libauto.dylib\\n0x7fff94fc1000 -     0x7fff94fc4ff7  libdyld.dylib (210.2.3) &lt;F59367C9-C110-382B-A695-9035A6DD387E&gt; /usr/lib/system/libdyld.dylib\\n0x7fff96120000 -     0x7fff9623892f  libobjc.A.dylib (532.2) &lt;90D31928-F48D-3E37-874F-220A51FD9E37&gt; /usr/lib/libobjc.A.dylib\\n0x7fff96239000 -     0x7fff96240fff  libGFXShared.dylib (8.10.1) &lt;B4AB9480-2CDB-34F8-8D6F-F5A2CFC221B0&gt; /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib\\n0x7fff96241000 -     0x7fff96284ff7  com.apple.bom (12.0 - 192) &lt;0BF1F2D2-3648-36B7-BE4B-551A0173209B&gt; /System/Library/PrivateFrameworks/Bom.framework/Versions/A/Bom\\n0x7fff962e1000 -     0x7fff962e2ff7  libdnsinfo.dylib (453.19) &lt;14202FFB-C3CA-3FCC-94B0-14611BF8692D&gt; /usr/lib/system/libdnsinfo.dylib\\n0x7fff962e3000 -     0x7fff964cdff7  com.apple.CoreFoundation (6.8 - 744.19) &lt;0F7403CA-2CB8-3D0A-992B-679701DF27CA&gt; /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\\n0x7fff964ce000 -     0x7fff96580ff7  com.apple.LaunchServices (539.11 - 539.11) &lt;A86F44E5-F285-3029-A5D1-00CD3C231A08&gt; /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices\\n0x7fff96581000 -     0x7fff96978fff  libLAPACK.dylib (1073.4) &lt;D632EC8B-2BA0-3853-800A-20DA00A1091C&gt; /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib\\n0x7fff96979000 -     0x7fff9697bfff  com.apple.securityhi (4.0 - 55002) &lt;9B6CBA92-123F-3307-A2D7-D77A8D3BF87E&gt; /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI\\n\\nExternal Modification Summary:\\n    Calls made by other processes targeting this process:\\n        task_for_pid: 2\\n        thread_create: 0\\n        thread_set_state: 0\\n    Calls made by this process:\\n        task_for_pid: 0\\n        thread_create: 0\\n        thread_set_state: 0\\n    Calls made by all processes on this machine:\\n        task_for_pid: 4537\\n        thread_create: 1\\n        thread_set_state: 0\\n\\nVM Region Summary:\\nReadOnly portion of Libraries: Total=142.6M resident=62.2M(44%) swapped_out_or_unallocated=80.4M(56%)\\nWritable regions: Total=67.3M written=236K(0%) resident=920K(1%) swapped_out=2728K(4%) unallocated=66.4M(99%)\\n\\nREGION TYPE                      VIRTUAL\\n===========                      =======\\nCG shared images                    128K\\nCoreServices                       1360K\\nMALLOC                             41.5M\\nMALLOC guard page                    48K\\nMemory tag=242                       12K\\nSTACK GUARD                        56.0M\\nStack                              9752K\\nVM_ALLOCATE                        16.0M\\n__DATA                             10.2M\\n__IMAGE                             528K\\n__LINKEDIT                         52.1M\\n__TEXT                             90.5M\\n__UNICODE                           544K\\nmapped file                        19.0M\\nshared memory                       308K\\n===========                      =======\\nTOTAL                             297.6M\\n\\nSystem Profile:\\nModel: iMac13,3, BootROM IM131.010A.B07, 2 processors, Intel Core i3, 3.3 GHz, 4 GB, SMC 2.10f5\\nGraphics: Intel HD Graphics 4000, Intel HD Graphics 4000, Built-In, 512 MB\\nMemory Module: BANK 0/DIMM0, 2 GB, DDR3, 1600 MHz, 0x80AD, 0x484D54333235533643465238432D50422020\\nMemory Module: BANK 1/DIMM0, 2 GB, DDR3, 1600 MHz, 0x80AD, 0x484D54333235533643465238432D50422020\\nAirPort: spairport_wireless_card_type_airport_extreme (0x14E4, 0xF4), Broadcom BCM43xx 1.0 (5.106.98.100.17)\\nBluetooth: Version 4.1.7f4 12974, 3 service, 21 devices, 3 incoming serial ports\\nNetwork Service: Ethernet, Ethernet, en0\\nNetwork Service: Wi-Fi, AirPort, en1\\nSerial ATA Device: APPLE HDD ST500LM012, 500.11 GB\\nUSB Device: hub_device, 0x8087  (Intel Corporation), 0x0024, 0x1d100000 / 2\\nUSB Device: Keyboard Hub, apple_vendor_id, 0x1006, 0x1d130000 / 5\\nUSB Device: Apple Keyboard, apple_vendor_id, 0x024f, 0x1d132000 / 9\\nUSB Device: hub_device, 0x0424  (SMSC), 0x2412, 0x1d180000 / 3\\nUSB Device: BRCM20702 Hub, 0x0a5c  (Broadcom Corp.), 0x4500, 0x1d181000 / 4\\nUSB Device: Bluetooth USB Host Controller, apple_vendor_id, 0x828b, 0x1d181300 / 7\\nUSB Device: Apple Optical USB Mouse, apple_vendor_id, 0x0304, 0x14400000 / 1\\nUSB Device: hub_device, 0x8087  (Intel Corporation), 0x0024, 0x1a100000 / 2\\nUSB Device: FaceTime HD Camera (Built-in), apple_vendor_id, 0x8511, 0x1a110000 / 3\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('String replacement from another dataframe', '<python><python-3.x><pandas><dataframe>', '<p>I need to replace my column depending upon data from another dataframe.\\nHave to search for respective \"name\" from the other dataframe and include the \"change_name\" in the df1</p>\\n\\n<p>df1:</p>\\n\\n<pre><code>ID  name\\n1   cat\\n2   jack\\n3   snake\\n4   monkey\\n</code></pre>\\n\\n<p>df2:</p>\\n\\n<pre><code>name    change_name\\ncat     meow\\njack    oooo \\nsnake   ssss\\nmonkey \\n</code></pre>\\n\\n<p>output:</p>\\n\\n<pre><code>ID  name\\n1   cat      meow\\n2   jack     oooo\\n3   snake    ssss\\n4   monkey   nan\\n</code></pre>\\n\\n<p>Sorry, I had to edit my question.</p>\\n\\n<p>I had to do like below:</p>\\n\\n<pre><code>def map_name(name):\\n    elif name == \\'cat\\':\\n        return \\'meow\\'\\n    elif name == \\'jack\\':\\n        return \\'oooo\\'\\n    elif name == \\'snake\\':\\n        return \\'ssss\\'\\n    elif name == \\'monkey \\':\\n        return None\\n    else\\n        return name\\n</code></pre>\\n\\n<p><code>df1[\\'name\\'] = df1[\\'name\\'].apply(map_name)</code></p>\\n\\n<p>As the list is small, I have hardcoded here but the list might grow. Can someone tell how to do teh same functionality using dataframes?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Prophet model predicts negative values', '<python><facebook><time-series><predict><facebook-prophet>', '<p>I am new to prophet (and stackoverflow in general ;) ) and have some issues with creating a predictive model using python. I am trying to predict daily sales of a product, using around 5 years of data. The data looks as follows: <a href=\"https://i.stack.imgur.com/cax67.png\" rel=\"nofollow noreferrer\">General data plot</a>. </p>\\n\\n<p>The company is closed in the weekends en during holidays, so there will be no orders. I accounted for this by creating a dataframe with al the weekends/holidays and using this dataframe as an argument for the holidays parameter. Furthermore I didn\\'t change anything from the model, so it looks like: Prophet(holidays = my weekend/holiday dataframe). </p>\\n\\n<p>However, my model doens\\'t seem to work right and predicts negative values, see the following plot: <a href=\"https://i.stack.imgur.com/ov8Xy.png\" rel=\"nofollow noreferrer\">Predicition 1</a>. Hereby also the different component plots as extra information: <a href=\"https://i.stack.imgur.com/CaXSE.png\" rel=\"nofollow noreferrer\">trend</a>, <a href=\"https://i.stack.imgur.com/NBPU6.png\" rel=\"nofollow noreferrer\">holidays</a>, <a href=\"https://i.stack.imgur.com/owE7d.png\" rel=\"nofollow noreferrer\">weekly</a>, <a href=\"https://i.stack.imgur.com/iJJfD.png\" rel=\"nofollow noreferrer\">yearly</a>. I also tried to just replace the negative values in the prediction by 0, which gives some better result (see <a href=\"https://i.stack.imgur.com/eD0bV.png\" rel=\"nofollow noreferrer\">prediction 2</a>), but I don\\'t think this is the right way to tackle this problem. The last thing I tried was to remove all the weekends from the training and predicting data. The results weren\\'t good either: <a href=\"https://i.stack.imgur.com/J7ezM.png\" rel=\"nofollow noreferrer\">prediction 3</a>.</p>\\n\\n<p>I would love to hear some tips from you guys, for things I could try to do. If anything is unclear or you need more information, just let me know. Thank you in advance!!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Using Python Click, how do I add more than 5 options i.e. more than 5?', '<python><python-3.7>', '<p>Current code:</p>\\n\\n<pre><code>@click.command()\\n@click.option(\\'--logs\\', type=click.Choice([\\'all\\', \\'errors\\', \\'no-errors\\', \\'archive\\',\\n                                           \\'archive-with-errors\\']))\\n@click.option(\\'--process\\', type=click.Choice([\\'all\\', \\'fix\\', \\'spool\\', \\'status\\', \\'import\\']))\\n@click.option(\\'--quiet\\', is_flag=True)\\n@click.option(\\'--check\\', is_flag=True)\\n@click.option(\\'--scan\\', nargs=1)\\ndef main(logs, process, quiet, check, scan):\\n</code></pre>\\n\\n<p>If I add a 6th option to the main function, pylint complains about \"Too many arguments (6/5) (52:0) [too-many-arguments]\"</p>\\n\\n<p><strong>I do not what to add an exception to pylint config file.</strong>  </p>\\n\\n<p>I want to know how to pass more options to python @click.  Or do I need to restructure my file so each option has its own @click.command and its own python function?</p>\\n\\n<p>Sorry if this is duplicated, I could not find it since click is a very general term.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Keras ImageDataGenerator validation split not selected from shuffled dataset', '<python><validation><tensorflow><keras><training-data>', '<p>How can I randomly split my image dataset into training and validation datesets? More specifically, the <code>validation_split</code> argument in Keras <code>ImageDataGenerator</code> function is not randomly splitting my images into training and validation but is slicing the validation sample from an unshuffled dataset.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Why is this boolean not true even though the conditions are met?', '<python>', \"<pre><code>print(&quot;Tic Tac Toe created by Pher&quot;)\\nrow_a = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\nrow_b = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\nrow_c = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\n\\ndef ResetGame():\\n    row_a = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\n    row_b = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\n    row_c = [&quot;&quot;,&quot;&quot;,&quot;&quot;]\\n\\ndef DrawBoard():\\n    print()\\n    print(&quot;  0 1 2&quot;)\\n    print(&quot;A &quot;+row_a[0]+&quot; &quot;+row_a[1]+&quot; &quot;+row_a[2])\\n    print(&quot;B &quot;+row_b[0]+&quot; &quot;+row_b[1]+&quot; &quot;+row_b[2])\\n    print(&quot;C &quot;+row_c[0]+&quot; &quot;+row_c[1]+&quot; &quot;+row_c[2])\\n\\ndef VictoryCheck():\\n    #checking for x wins\\n    #hortizontal checks\\n    if row_a[0] == row_a[1] == row_a[2] == &quot;x&quot;:\\n        x_Victory = True\\n    if row_b[0] == row_b[1] == row_b[2] == &quot;x&quot;:\\n        x_Victory = True\\n    if row_c[0] == row_c[1] == row_c[2] == &quot;x&quot;:\\n        x_Victory = True\\n    #vertical checks\\n    if row_a[0] == row_b[0] == row_c[0] == &quot;x&quot;:\\n        x_Victory = True\\n    if row_a[1] == row_b[1] == row_c[1] == &quot;x&quot;:\\n        x_Victory = True\\n    if row_a[2] == row_b[2] == row_c[2] == &quot;x&quot;:\\n        x_Victory = True\\n    #diagonal checks\\n    if row_a[0] == row_b[1] == row_c[2] == &quot;x&quot;:\\n        x_Victory = True\\n    if row_a[2] == row_b[1] == row_c[0] == &quot;x&quot;:\\n        x_Victory = True\\n    else:\\n        x_Victory = False\\n   \\n    \\n    #checking for o wins\\n    #hortizontal checks\\n    if row_a[0] == row_a[1] == row_a[2] == &quot;o&quot;:\\n        o_Victory = True\\n    if row_b[0] == row_b[1] == row_b[2] == &quot;o&quot;:\\n        o_Victory = True\\n    if row_c[0] == row_c[1] == row_c[2] == &quot;o&quot;:\\n        o_Victory = True\\n    #vertical checks\\n    if row_a[0] == row_b[0] == row_c[0] == &quot;o&quot;:\\n        o_Victory = True\\n    if row_a[1] == row_b[1] == row_c[1] == &quot;o&quot;:\\n        o_Victory = True\\n    if row_a[2] == row_b[2] == row_c[2] == &quot;o&quot;:\\n        o_Victory = True\\n    #diagonal checks\\n    if row_a[0] == row_b[1] == row_c[2] == &quot;o&quot;:\\n        o_Victory = True\\n    if row_a[2] == row_b[1] == row_c[0] == &quot;o&quot;:\\n        o_Victory = True\\n    else:\\n        o_Victory = False\\n    \\n\\ndef x_turn():\\n    print()\\n    x_input = input(&quot;X PLAYS: &quot;)\\n    x_input = x_input.upper()\\n    x_row = str(x_input[0])\\n    x_col = int(x_input[1])\\n\\n    if x_row == &quot;A&quot;:\\n        row_a[x_col] = str(&quot;x&quot;)\\n        DrawBoard()\\n    if x_row == &quot;B&quot;:\\n        row_b[x_col] = str(&quot;x&quot;)\\n        DrawBoard()\\n    if x_row == &quot;C&quot;:\\n        row_c[x_col] = str(&quot;x&quot;)\\n        DrawBoard()\\n\\ndef o_turn():\\n    print()\\n    o_input = input(&quot;O PLAYS: &quot;)\\n    o_input = o_input.upper()\\n    o_row = str(o_input[0])\\n    o_col = int(o_input[1])\\n\\n    if o_row == &quot;A&quot;:\\n        row_a[o_col] = str(&quot;o&quot;)\\n        DrawBoard()\\n    if o_row == &quot;B&quot;:\\n        row_b[o_col] = str(&quot;o&quot;)\\n        DrawBoard()\\n    if o_row == &quot;C&quot;:\\n        row_c[o_col] = str(&quot;o&quot;)\\n        DrawBoard()\\n\\nResetGame()\\nDrawBoard()\\n\\nx_Victory = False\\no_Victory = False\\n \\n\\nfor x in range(1,10):\\n    VictoryCheck()\\n    if x_Victory == True:\\n        print(&quot;X HAS WON&quot;)\\n    if o_Victory == True:\\n        print(&quot;X HAS WON&quot;)\\n    if x % 2 == 0:\\n        o_turn()\\n        VictoryCheck()  \\n    if not x % 2 == 0:\\n        x_turn()\\n        VictoryCheck()\\n</code></pre>\\n<p>I'm very new to python so dont judge the sloppy code/terminology. The function VictoryCheck is called and the criteria is met in order for the boolean variable x_Victory to become true yet</p>\\n<pre><code>if x_Victory == True:\\n        print(&quot;X HAS WON&quot;)\\n</code></pre>\\n<p>doesnt run the program kind of sits there\\nDoes anyone know what the problem could possibly be im willing to give any more info if needed</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('reading multiple files with glob duplicates columns', '<python><python-3.x><pandas><dataframe><glob>', '<p>I\\'m trying read many txt files into my data frame and this code works below. However, it duplicates some of my columns, not all of them. I couldn\\'t find a solution. What can I do to prevent this? </p>\\n\\n<pre><code>import pandas as pd\\nimport glob\\n\\ndfs = pd.DataFrame(pd.concat(map(functools.partial(pd.read_csv, sep=\\'\\\\t\\', low_memory=False),\\n                    glob.glob(r\\'/folder/*.txt\\')), sort=False))\\n</code></pre>\\n\\n<p>Let\\'s say my data should look like this:</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/7JXyY.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\\n\\n<p>But it looks like this:\\n<a href=\"https://i.stack.imgur.com/3bqwo.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\\n\\n<p>I don\\'t want my columns to be duplicated. </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Flask test form submission', '<python><flask>', '<p>Im trying to write a test for some form that writes data to my database.\\nI don\\'t know why it doesn\\'t work.</p>\\n\\n<p>route:</p>\\n\\n<blockquote>\\n<pre><code>@admin.route(\\'/session/new\\', methods=[\\'POST\\', \\'GET\\']) @login_required def new_session():\\nform = AddSession()\\nif form.validate_on_submit():\\n    print(form.name.data)\\n    print(request)\\n    add_session = Session(name=form.name.data,\\n                          start_date=form.start_date.data,\\n                          end_date=form.end_date.data)\\n    db.session.add(add_session)\\n    db.session.commit()\\n    flash(\\'A session has been successfully added!\\', \\'success\\')\\n    return redirect(url_for(\\'admin.sessions_overview\\'))\\n\\nreturn render_template(\\'sessions/new_session.html\\', title=\\'Add Session\\', form=form)\\n</code></pre>\\n</blockquote>\\n\\n<p>test:</p>\\n\\n<blockquote>\\n  <p>class FlaskClientTestCase(unittest.TestCase):</p>\\n\\n<pre><code>def setUp(self):\\n    self.app = create_app(\\'testing\\')\\n    self.app_context = self.app.app_context()\\n    self.app_context.push()\\n    db.create_all()\\n    populate_db(db)\\n    self.client = self.app.test_client(use_cookies=True)\\n\\ndef tearDown(self):\\n    db.session.remove()\\n    db.drop_all()\\n    self.app_context.pop()\\n\\ndef test_new_session(self):\\n    response = self.client.post(\\'/login\\', data={\\n        \\'username\\': \\'joshn\\',\\n        \\'password\\': \\'123\\'\\n    }, follow_redirects=True)\\n    self.assertEqual(response.status_code, 200)\\n\\n    session_data = {\\n        \\'name\\': \\'test_session\\',\\n        \\'start_date\\': date(2019, 7, 20),\\n        \\'end_date\\': date(2019, 7, 21)\\n    }\\n    response = self.client.post(\\'/session/new\\', data={\\n        \\'name\\': \\'test_session\\',\\n        \\'start_date\\': date(2019, 7, 20),\\n        \\'end_date\\': date(2019, 7, 21)\\n    })\\n\\n    self.assertEqual(response.status_code, 200, \"Form wasn\\'t submitted\")  # Checks the form submission was valid\\n\\n    test_s = Session.query.filter_by(name=\\'test_session\\').first()\\n    self.assertIsNotNone(test_s, \"Session wasn\\'t added to database\")\\n\\n    self.assertEqual(session_data[\\'name\\'], test_s.name, \"Data wasn\\'t written properly to db\")\\n    self.assertEqual(session_data[\\'start_date\\'], test_s.start_date, \"Data wasn\\'t written properly to db\")\\n    self.assertEqual(session_data[\\'end_date\\'], test_s.end_date, \"Data wasn\\'t written properly to db\")\\n</code></pre>\\n</blockquote>\\n\\n<p>error message:</p>\\n\\n<blockquote>\\n  <p>Traceback (most recent call last):   File \"tests/test_admin.py\", line\\n  56, in test_new_session\\n      self.assertIsNotNone(test_s, \"Session wasn\\'t added to database\") AssertionError: unexpectedly None : Session wasn\\'t added to database</p>\\n</blockquote>\\n\\n<p>EDIT: ok i added an else to the route, but now i get a response code 400,\\nand when i checked the post request was empty.</p>\\n\\n<p>The updated route:</p>\\n\\n<pre><code>def new_session():\\n    form = AddSession()\\n    if form.validate_on_submit():\\n        print(form.name.data)\\n        print(request)\\n        add_session = Session(name=form.name.data,\\n                              start_date=form.start_date.data,\\n                              end_date=form.end_date.data)\\n        db.session.add(add_session)\\n        db.session.commit()\\n        flash(\\'A session has been successfully added!\\', \\'success\\')\\n        return redirect(url_for(\\'admin.sessions_overview\\'))\\n    else:\\n        print(request.method)\\n        if request.method == \\'POST\\':\\n            args = request.args\\n            print(args)\\n            add_session = Session(name=args[\\'name\\'],\\n                                  start_date=args[\\'start_date\\'],\\n                                  end_date=args[\\'end_date\\'])\\n            db.session.add(add_session)\\n            db.session.commit()\\n            return Response(status=302)\\n\\n    return render_template(\\'sessions/new_session.html\\', title=\\'Add Session\\', form=form)\\n</code></pre>\\n\\n<p>The message:</p>\\n\\n<pre><code>Traceback (most recent call last):\\n  File \"tests/test_admin.py\", line 53, in test_new_session\\n    self.assertEqual(response.status_code, 302, \"Form wasn\\'t submitted\")  # Checks the form submission was valid\\nAssertionError: 400 != 302 : Form wasn\\'t submitted\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Round is returning (100, 1) instead if 100', '<python><function>', '<p>I am trying to find the percentage of questions right but my percentage code is returning <code>(100, 1)</code> but I want it to return <code>100</code>. My code is </p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>accuracy = 100 # Setting a default.\\n\\ndef percentage(part, whole):\\n  return(round((part/whole)*100),1)\\n</code></pre>\\n\\n<p>and the code to print is</p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>accuracy = percentage(questionsright, questionscompleted)\\nprint(\"Your accuracy is now \" + str(accuracy) + \"% .\")\\n</code></pre>\\n\\n<p>Does anybody know why it isn\\'t returning 100? Please Help.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Troubles installing PyQt4', '<python><pyqt4><python-sip>', '<p>I\\'m following <a href=\"http://diotavelli.net/PyQtWiki/BuildPyQt4Windows\" rel=\"nofollow noreferrer\">this</a> guide.</p>\\n\\n<ul>\\n<li>Python is at C:\\\\Python31</li>\\n<li>PyQt4 is at C:\\\\Python31\\\\pyqt</li>\\n<li>sip is at C:\\\\Python31\\\\sip</li>\\n<li>Qt is at C:\\\\Qt\\\\4.6.0</li>\\n</ul>\\n\\n<p>I followed the instructions on that guide, but when I tried to test it (<code>from PyQt4.Qt install *</code>), it said the module didn\\'t exist. I checked all the files that guide said should exist, and none of them existed.</p>\\n\\n<p>What should I do?</p>\\n\\n<p>Oh:</p>\\n\\n<p>sip installed fine. <code>from sip import *</code> didn\\'t yield errors, <code>print(SIP_VERSION_STR)</code> output <code>4.10-snapshot-20091204</code>.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to upload zope site on my ftp?', '<python><frameworks><zope><zope.interface>', \"<p>Hey, I'd like to know how to upload my zope site on my ftp. I have a domain, and I like to upload it, like a upload normal files on my ftp. </p>\\n\\n<p>Thanks.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Why is debugging in eclipse/pydev so slow for my python program?', '<python><eclipse><performance><pydev><usability>', '<p>I have a relatively simple (no classes) python 2.7 program. The first thing the program does is read an sqlite dbase into a dictionary. The database is large, but not huge, around 90Meg on disk. It takes about 20 seconds to read in. After reading in the database I initialize some variables, e.g.</p>\\n\\n<pre><code>localMax = 0\\nlocalMin = 0\\nfirstTime = True\\n</code></pre>\\n\\n<p>When I debug this program in Eclipse-3.7.0/pydev - even these simple lines - each single-step in the debugger eats up 100% of a core, and takes between 5 and 10 seconds. I can see the python process goes to 100% cpu for 10 seconds. Single-step... wait 10 seconds... single-step... wait 10 seconds...  If I debug at the command line just using pdb, no problems. If I\\'m not debugging at all, the program runs at \"normal\" speed, nothing strange like in Eclipse.</p>\\n\\n<p>I\\'ve reproduced this on a dual core Win7 PC w/ 4G memory, my 8 core Ubuntu box w/ 8G of memory, and even my Mac Air. How\\'s that for multi-platform development! I kept thinking it would work <em>somewhere</em>. I\\'m never even close to running out of memory at any time.</p>\\n\\n<p>On each Eclipse single-step, why does the python process jump to 100% CPU, and take 10 seconds?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to make the data greater than or equal to the previous data', '<python><pandas>', \"<p>I have a dataframe, and I want every value in a specific column to be greater or equal to the previous value. </p>\\n\\n<p>In the example below, I want it to be applied on column 'd', so the expected result should replace 5 with 7.</p>\\n\\n<p>So how can I do it?</p>\\n\\n<p>The actual situation needs to consider efficiency issues, it is best not to use FOR.</p>\\n\\n<p>Thank you in advance for your reply.</p>\\n\\n<p>code:</p>\\n\\n<pre><code>&gt;&gt;&gt; df = pd.DataFrame({'a': [1,3,2,5], 'b': [2, 4,3,4], 'c':[3,5,4,3]})\\n&gt;&gt;&gt; df\\n   a  b  c\\n0  1  2  3\\n1  3  4  5\\n2  2  3  4\\n3  5  4  3\\n\\n&gt;&gt;&gt; df['d'] = df['a']+df['b']\\n&gt;&gt;&gt; df\\n   a  b  c  d\\n0  1  2  3  3\\n1  3  4  5  7\\n2  2  3  4  5\\n3  5  4  3  9\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Pandas Dataframe : How to add a vertical line with label to a bar plot when your data is time-series?', '<python><pandas>', '<p>i used Pandas and supposed we have the following DataFrame :</p>\\n\\n<pre><code>ax = madagascar_case[[\"Ratio\"]].loc[\\'3/17/20\\':]\\nax.tail()\\n</code></pre>\\n\\n<p>out : \\n       <a href=\"https://i.stack.imgur.com/zduz5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zduz5.png\" alt=\"enter image description here\"></a></p>\\n\\n<p>i would like to show a bar chart following ratio values and add a vertical line related to a specific date for instance : \\'4/20/20\\' :</p>\\n\\n<p>when I try the code below : </p>\\n\\n<pre><code>ax = madagascar_case[[\"Ratio\"]].loc[\\'3/17/20\\':].plot.bar(figsize=(17,7), grid = True)\\n# to add a vertical line\\nax.axvline(\"4/20/20\",color=\"red\",linestyle=\"--\",lw=2 ,label=\"lancement\")\\n</code></pre>\\n\\n<p>the result is the vertical line (red) is at the wrong date and there is no label  :</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/FQ9f7.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/FQ9f7.png\" alt=\"enter image description here\"></a></p>\\n\\n<p>So to fix that I try another code by using matplotlib:</p>\\n\\n<pre><code>p = \\'4/20/20\\'\\n# Dataframe \\nax = madagascar_case[[\"Ratio\"]].loc[\\'3/17/20\\':]\\n# plot a histogram based on ax \\nplt.hist(ax,label=\\'ratio\\')\\n# add vertical line \\nplt.axvline(p,color=\\'g\\',label=\"lancement\")\\n\\nplt.legend()\\nplt.show()\\n</code></pre>\\n\\n<p>The result was worse than expected. :</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/lzsPF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/lzsPF.png\" alt=\"enter image description here\"></a></p>\\n\\n<h2>is there an easiest way to fix that ?</h2>\\n\\n<p>RVA92 >> I followed your last code :</p>\\n\\n<pre><code>df  = madagascar_case.loc[\\'3/19/20\\':,\\'Ratio\\'].copy()\\nfig,ax = plt.subplots()\\n# plot bars \\ndf.plot.bar(figsize=(17,7),grid=True,ax=ax)\\nax.axvline(df.index.searchsorted(\\'4/9/20\\'), color=\"red\", linestyle=\"--\", lw=2, label=\"lancement\")\\nplt.tight_layout()\\n</code></pre>\\n\\n<p>the result is it works when I change the date to \\'4/9/20\\' for example , but when I change the date to \\'4/20/20\\' it doesn\\'t fit correctly I don\\'t know why ?</p>\\n\\n<pre><code>ax.axvline(df.index.searchsorted(\\'4/20/20\\'), color=\"red\", linestyle=\"--\", lw=2, label=\"lancement\")\\n</code></pre>\\n\\n<p><a href=\"https://i.stack.imgur.com/1DTLP.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1DTLP.png\" alt=\"enter image description here\"></a></p>\\n\\n<p><a href=\"https://i.stack.imgur.com/zpjpj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/zpjpj.png\" alt=\"enter image description here\"></a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to compare values of two dictionaries that have different keys in python', '<python><dictionary>', \"<p>I have the dictionary of football match results that looks like:</p>\\n<pre><code>results = {\\n    &quot;31 August 2019&quot;: [\\n        [\\n            {&quot;Lazio&quot;: 2}, \\n            {&quot;Roma&quot;: 1}\\n        ]\\n    ], \\n    &quot;1 September 2019&quot;: [\\n        [\\n            {&quot;AC Milan&quot;: 0}, \\n            {&quot;Napoli&quot;: 3}\\n        ],\\n        [\\n            {&quot;Udinese&quot;: 1}, \\n            {&quot;Fiorentina&quot;: 1}\\n        ]\\n    ]\\n}\\n</code></pre>\\n<p>[{&quot;Lazio&quot;: 2},{&quot;Roma&quot;: 1}] means Lazio VS Roma, score:2-1</p>\\n<p>What I need is to get the winner for each match by comparing two dictionaries for a match. I have try this:</p>\\n<pre><code>for date, matches in results.items():\\n    for match in matches:\\n        if match[0].value() &gt; match[1].value(): #I'm Stuck on this\\n            print(date)\\n            print(&quot;the winner is :&quot;, match[0].key())\\n        elif match[0].value() &lt; match[1].value(): #I'm Stuck on this\\n            print(date)\\n            print(&quot;the winner is :&quot;, match[1].key())\\n        else:\\n            print(date)\\n            print(&quot;the match between &quot;,match[0].key(),&quot; VS &quot;,match[1].key(),&quot; was even&quot;)\\n</code></pre>\\n<p>Of course that code didn't work but I hope you could understand what I mean.\\nif you have a better format to save the results, please tell me.\\nThanks a lot</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Most pythonic way to index each tuple contained within a list', '<python><arrays><numpy><tuples>', \"<p>Sort of a Python beginner, sorry if this is a basic question.</p>\\n<p>I have tuples of the form (i, j) contained inside a list of variable length. This list is output by a function that is selecting clusters of pixels inside an image and averaging their RGB values, so the tuples are indices. The function is recursive, here is the return statement:</p>\\n<pre><code>return ((red,blue,green), tuple_list, sum_n)\\n# [0] (r,g,b) values [1] list of indices as tuples [2] number of pixels gathered\\n</code></pre>\\n<p>I take the output from this function and write the new RGB values to my image matrix, which is a numpy array, like this by using a for loop:</p>\\n<pre><code>cluster = rgb_avg_cluster(depth = 0, row = i, column = j, image = newimg)\\n    # cluster[1] is the list of tuple indices\\n    for x in cluster[1]: \\n          newimg[x[0],x[1],0] = int(cluster[0][0])\\n          newimg[x[0],x[1],1] = int(cluster[0][1])\\n          newimg[x[0],x[1],2] = int(cluster[0][2])\\n</code></pre>\\n<p>My numpy array is [width, height, rgb], so for a 1200x600 image it would be (1200,600,3). Is there some quicker way to index the rgb values at each tuple index and change them to the new values?</p>\\n<p>As an example, if my output is <code>((150,40,40), [(35,35), (95,42)], 2)</code> is there a better/faster way to change pixels <code>(35,35)</code> and <code>(95,42)</code> in my numpy array to <code>rgb = (150,40,40)</code>? Like this:</p>\\n<pre><code>input: \\n        ((150,40,40), [(35,35), (95,42)], 2)\\n\\nresult: \\n        newimg[35,35,0] = 150\\n        newimg[35,35,1] = 40\\n        newimg[35,35,2] = 40\\n        newimg[95,42,0] = 150\\n        newimg[95,42,1] = 40\\n        newimg[95,42,2] = 40\\n</code></pre>\\n<p>I know vectorized operations are the way to go with numpy but I don't know how to implement it in this case. This function takes a while to execute as-is.</p>\\n<p>Thanks!</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Plotting candlestick and volume candels in Bokeh', '<python><pandas-bokeh>', '<p>I have plotted the candlestick using bokeh. Now i want to plot the volume candles in the same chart?\\nHow do I achieve that. I am reading the data from csv which has open,high,low,close and volume.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python PIL: How to save cropped image?', '<python><python-imaging-library><crop>', '<p>I have a script which creates an image and the it crops it. The problem is that after I call the crop() method it does not save on the disk</p>\\n\\n<pre><code>crop = image.crop(x_offset, Y_offset, width, height).load()\\nreturn crop.save(image_path, format)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Mesh grid functions in Python (meshgrid mgrid ogrid ndgrid)', '<python><numpy><scipy>', '<p>I\\'m looking for a clear comparison of meshgrid-like functions. Unfortunately I don\\'t find it!</p>\\n\\n<p>Numpy <a href=\"http://docs.scipy.org/doc/numpy/reference/\" rel=\"noreferrer\">http://docs.scipy.org/doc/numpy/reference/</a> provides</p>\\n\\n<ul>\\n<li><p><code>mgrid</code></p></li>\\n<li><p><code>ogrid</code></p></li>\\n<li><p><code>meshgrid</code></p></li>\\n</ul>\\n\\n<p>Scitools <a href=\"http://hplgit.github.io/scitools/doc/api/html/index.html\" rel=\"noreferrer\">http://hplgit.github.io/scitools/doc/api/html/index.html</a> provides</p>\\n\\n<ul>\\n<li><p><code>ndgrid</code></p></li>\\n<li><p><code>boxgrid</code></p></li>\\n</ul>\\n\\n<p>Ideally a table summarizing all this would be perfect!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python _socket.socket vs socket._socketobject, how to convert from one to the other', '<python><sockets><python-2.7>', '<p>I realised that my problem with wrapping sockets in <code>ssl</code>, when the socket is built from a <code>fd</code> is related to a <code>socket._socketobject</code> being converted (after rebuilding it from <code>fd</code>) into a <code>socket._socket</code>. </p>\\n\\n<p>Is there any way to turn the socket._socket back into a <code>_socketobject</code>?</p>\\n\\n<p>Thanks</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Specific website is not opening through Selenium', '<python><selenium><selenium-webdriver><web-scraping><proxy>', '<p>I\\'m trying to scrape some data from a website using selenium in python. Tried with chrome browser and firefox but this specific website is not opening, browser opens but website doesn\\'t show any content. I am able to open it without selenium but with selenium\\'s <code>driver.get(\\'https://www.eloan.co.il/market/2653\\')</code> method this website doesn\\'t open. I am assuming they have a bot detection or something.</p>\\n\\n<blockquote>\\n  <p><a href=\"https://www.eloan.co.il/market/2653\" rel=\"nofollow noreferrer\">https://www.eloan.co.il/market/2653</a></p>\\n</blockquote>\\n\\n<p>Attached is a recorded <a href=\"https://drive.google.com/file/d/1ggxrpjwC_t-XkfS2NGMoHFAzM8tpUnF4/view?usp=sharing\" rel=\"nofollow noreferrer\">video</a> of what\\'s actually happening </p>\\n\\n<p>I don\\'t see anything disallowed in their <a href=\"https://i.stack.imgur.com/N89sO.png\" rel=\"nofollow noreferrer\">robots.txt</a> related to /market which I am accessing. Any solution to overcome this?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Mocking auth decorator with pytest and flask', '<python><unit-testing><flask><pytest>', '<p>I have a flask application that uses an auth decorator to validate JWT tokens to an external service (auth0). The application looks like this:</p>\\n\\n<p><em>app/helpers/decorators.py</em></p>\\n\\n<pre><code>from functools import wraps\\n\\ndef check_auth(f):\\n    @wraps(f)\\n    def auth_check(*args, **kwargs):\\n        token = get_token_auth_header() # will get token from Bearer header\\n        jsonurl = urlopen(\"https://\"+AUTH0_DOMAIN+\"/.well-known/jwks.json\")\\n        ...[ pass token to auth0 ]\\n    return auth_check\\n</code></pre>\\n\\n<p><em>app/api/annotation_api.py</em></p>\\n\\n<pre><code>from flask.views import MethodView\\nfrom app.helpers.decorators import check_auth\\n\\nclass AnnotationMetricAPI(MethodView):\\n    @check_auth\\n    def get(self, id):\\n        return {status: 200}\\n\\nannotation_metric_view = AnnotationMetricAPI.as_view(\\'annotation_metric_view\\')\\n</code></pre>\\n\\n<p><em>app/routes/routes.py</em></p>\\n\\n<pre><code>from flask import Blueprint\\nfrom flask_cors import CORS\\nfrom app.api.annotation_api import annotation_metric_view\\n\\nroutes_blueprint = Blueprint(\\'routes\\', __name__)\\nCORS(routes_blueprint, max_age=30*86400)\\n\\nroutes_blueprint.add_url_rule(\\n    \\'/api/v1/annotation/metric/&lt;id&gt;\\',\\n    view_func=annotation_metric_view,\\n    methods=[\\'GET\\']\\n)\\n\\n</code></pre>\\n\\n<p><em>app/_ _init_ _.py</em></p>\\n\\n<pre><code>from flask import Flask\\nfrom flask_cors import CORS\\nfrom app.routes import routes_blueprint\\nimport logging\\n\\nlogging.basicConfig(level=logging.DEBUG)\\n\\n\\ndef create_app():\\n    app = Flask(__name__, instance_relative_config=False)\\n    app.config.from_object(\\'config.Config\\')\\n    CORS(app)\\n    with app.app_context():\\n        app.register_blueprint(routes_blueprint)\\n        return app\\n</code></pre>\\n\\n<p>Now I\\'d like to use pytest to replace the @check_auth decorator with a mock decorator. After reading these articles:\\n<a href=\"https://medium.com/@hmajid2301/testing-with-pytest-mock-and-pytest-flask-13cd968e1f24\" rel=\"nofollow noreferrer\">https://medium.com/@hmajid2301/testing-with-pytest-mock-and-pytest-flask-13cd968e1f24</a></p>\\n\\n<p><a href=\"https://stackoverflow.com/questions/47900727/mock-authentication-decorator-in-unittesting\">Mock authentication decorator in unittesting</a></p>\\n\\n<p>I\\'ve tried the following methods:</p>\\n\\n<p><strong>Method 1</strong>: using pytest-flask and pytest-mock plugins:</p>\\n\\n<p><em>tests/test_annotation_api1.py</em></p>\\n\\n<pre><code>import pytest\\n\\nfrom app import create_app\\n\\n@pytest.fixture\\ndef app(mocker):\\n    mocker.patch(\"app.helpers.decorators.check_auth\", return_value=True)\\n    app = create_app()\\n    return app\\n\\ndef test_get_metric_annotations(client):\\n    response = client.get(\\n        \\'/api/v1/annotation/metric/1\\',\\n        content_type=\\'application/json\\'\\n    )\\n    data = response.json\\n    assert data[\\'status\\'] == 200\\n</code></pre>\\n\\n<p><strong>Method 2</strong>: using mock.patch:</p>\\n\\n<p><em>tests/test_annotation_api2.py</em></p>\\n\\n<pre><code>from functools import wraps\\nfrom mock import patch\\n\\ndef mock_decorator(f):\\n    @wraps(f)\\n    def decorated_function(*args, **kwargs):\\n        return f(*args, **kwargs)\\n    return decorated_function\\n\\npatch(\\'app.helpers.decorators.check_auth\\', mock_decorator).start()\\n\\nfrom app import create_app\\n\\napp = create_app()\\napp.testing = True\\n\\ndef test_get_metric_annotations():\\n    with app.test_client() as client:\\n        response = client.get(\\n            \\'/api/v1/annotation/metric/1\\',\\n            content_type=\\'application/json\\'\\n        )\\n        data = response.json\\n        assert data[\\'status\\'] == 200\\n</code></pre>\\n\\n<p><strong>Method 3</strong>: using the @patch decorator:</p>\\n\\n<p><em>tests/test_annotation_api3.py</em></p>\\n\\n<pre><code>from functools import wraps\\nfrom mock import patch\\n\\ndef mock_decorator(f):\\n    @wraps(f)\\n    def decorated_function(*args, **kwargs):\\n        print(\"IN HEREEE\")\\n        return f(*args, **kwargs)\\n    return decorated_function\\n\\nfrom app import create_app\\n\\napp = create_app()\\napp.testing = True\\n\\n@patch(\\'app.helpers.decorators.check_auth\\')\\ndef test_get_metric_annotations(mock_auth):\\n    mock_auth.return_value = True\\n    with app.test_client() as client:\\n        response = client.get(\\n            \\'/api/v1/annotation/metric/1\\',\\n            content_type=\\'application/json\\'\\n        )\\n        data = response.json\\n        assert data[\\'status\\'] == 200\\n</code></pre>\\n\\n<p>With each of these methods I get the same result, the check_auth decorator fires, ie it isn\\'t being mocked properly:</p>\\n\\n<pre><code>============================= test session starts ==============================\\nplatform linux -- Python 3.6.9, pytest-5.4.2, py-1.8.1, pluggy-0.13.1\\nrootdir: /container\\nplugins: cov-2.8.1, mock-3.1.0, flask-1.0.0\\ncollected 1 item\\n\\ntests/test_annotation_api.py F                                           [100%]\\n\\n=================================== FAILURES ===================================\\n_________________ test_get_metric_annotations_multiple_results _________________\\n\\n    def test_get_metric_annotations_multiple_results():\\n        with app.test_client() as client:\\n            response = client.get(\\n                \\'/api/v1/annotation/metric/1\\',\\n&gt;               content_type=\\'application/json\\'\\n            )\\n\\n\\ntests/test_annotation_api.py:24: \\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n/usr/local/lib/python3.6/dist-packages/werkzeug/test.py:1006: in get\\n\\n...\\n/usr/local/lib/python3.6/dist-packages/flask/views.py:89: in view\\n    return self.dispatch_request(*args, **kwargs)\\n/usr/local/lib/python3.6/dist-packages/flask/views.py:163: in dispatch_request\\n    return meth(*args, **kwargs)\\napp/helpers/decorators.py:24: in auth_check\\n    token = get_token_auth_header()\\n\\ndef get_token_auth_header():\\n        \"\"\"Obtains the Access Token from the Authorization Header\\n        \"\"\"\\n        auth = request.headers.get(\"Authorization\", None)\\n        if not auth:\\n            raise AuthError({\"code\": \"authorization_header_missing\",\\n                            \"description\":\\n&gt;                               \"Authorization header is expected\"}, 401)\\nE           app.helpers.errorhandlers.AuthError: ({\\'code\\': \\'authorization_header_missing\\', \\'description\\': \\'Authorization header is expected\\'}, 401)\\n\\napp/helpers/jwt_handler.py:16: AuthError\\n</code></pre>\\n\\n<p>My guess is that I\\'m not targeting the check_auth decorator properly, but I\\'m at a loss for what to try next. Thoughts? Thanks.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Injecting Service (Composition) into Route method on Flask-RestPlus / Flask-RestX', '<python><flask><flask-restplus>', '<p>I am working on a Restful api using Flask-RestX (previously Flask-Restplus). In order to create a code easier to unit test, I am trying to have a route class that has a service method which can be passed as a parameter of the class or the method. That way I can mock the object and control the output of the method.</p>\\n<pre class=\"lang-py prettyprint-override\"><code>app = Flask(__name__)\\napi = Api(app)\\nns = api.namespace(\\'todos\\')\\n\\nclass TodoDAO():\\n    def getTodos(id):\\n        pass\\n    \\n    def create(data):\\n        pass\\n\\n@ns.route(\\'/&lt;int:id&gt;\\')\\nclass TodoList(Resource):\\n  def get(self, id):\\n        return TodoDAO.getTodos(id) ## This needs to be injected or passed via parameter\\n        \\nif __name__ == \\'__main__\\':\\n    app.run(debug=True)\\n</code></pre>\\n<p>How can I pass/inject the <code>TodoDAO.getTodos</code> method on this route?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to compile directories of python code', '<python>', '<p>I am new to python. I have a directory of *.py files and subdirectory of *.py files, how can I compile them to catch any syntax error?</p>\\n<p>Thank you.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('suppress/redirect stderr when calling python webrowser', '<python><browser><stderr>', \"<p>I have a python program that opens several urls in seperate tabs in a new browser window, however when I run the program from the command line and open the browser using </p>\\n\\n<pre><code>webbrowser.open_new(url)\\n</code></pre>\\n\\n<p>The stderr from firefox prints to bash. Looking at the docs I can't seem to find a way to redirect or suppress them</p>\\n\\n<p>I have resorted to using </p>\\n\\n<pre><code>browserInstance = subprocess.Popen(['firefox'], stdout=log, stderr=log)\\n</code></pre>\\n\\n<p>Where log is a tempfile &amp; then opening the other tabs with webbrowser.open_new. </p>\\n\\n<p>Is there a way to do this within the webbrowser module? </p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python read next()', '<python>', '<p><code>next()</code> in python does not work. What is an alternative to reading next line in Python? Here is a sample:</p>\\n\\n<pre><code>filne = \"D:/testtube/testdkanimfilternode.txt\"\\nf = open(filne, \\'r+\\')\\n\\nwhile 1:\\n    lines = f.readlines()\\n    if not lines:\\n        break\\n    for line in lines:\\n        print line\\n        if (line[:5] == \"anim \"):\\n            print \\'next() \\'\\n            ne = f.next()\\n            print \\' ne \\',ne,\\'\\\\n\\'\\n            break\\n\\nf.close()\\n</code></pre>\\n\\n<p>Running this on a file does not show \\'ne \\'.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Post method not available on localhost?', '<python><jupyter-notebook><localhost><httpresponse>', '<p>I\\'m trying to implement <a href=\"https://stackoverflow.com/a/17419188/9448090\">this answer:</a>:</p>\\n\\n<pre><code>import requests\\n\\nrequests.post(\\'http://localhost:8888\\', data={u\\'post\\': u\\'Andr\\\\xe9 T\\\\xe9chin\\\\xe9\\'})\\n</code></pre>\\n\\n<p>When I run it as-is in my Jupyter notebook I get:</p>\\n\\n<pre><code>&lt;Response [403]&gt;\\n</code></pre>\\n\\n<p>Ok, so access is forbidden. I then try it with my token:</p>\\n\\n<pre><code>requests.post(\\'http://localhost:8888/tree?token=xxx\\', data={u\\'post\\': u\\'Andr\\\\xe9 T\\\\xe9chin\\\\xe9\\'})\\n</code></pre>\\n\\n<p>But this time I get:</p>\\n\\n<pre><code>&lt;Response [405]&gt;\\n</code></pre>\\n\\n<p>So the <code>post</code> method is not allowed? Why, and how can I change that?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Is there a way to retrieve meta data of each website in google custom search python?', '<python><google-custom-search>', \"<p>I am using <code>google custom search engine API</code>. I wish to know if there is a way to filter results, based on the theme of the website. Hasn't I wish to avoid all results from the press sites. I believe if I get access to the metadata and look for keywords such as news, then I can ignore that website. However, after crosschecking the json result, there is no way for me to determine the website category. </p>\\n\\n<p>If there is any alternative way, can you please help me.  </p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Access denied while scraping with selenium in Python', '<python><selenium><web-scraping>', '<p>Is it possible to work around this \"access denied\" that I get when using this code on fantasy.premierleague.com? I tried using some random time delay but that doesn\\'t seem to have any effect.</p>\\n\\n<pre><code>import requests \\nimport time\\nfrom bs4 import BeautifulSoup \\nfrom selenium import webdriver\\n\\ndriver = webdriver.Firefox(executable_path=r\\'C:\\\\Users\\\\benja\\\\Desktop\\\\geckodriver.exe\\')\\n\\nfor y in range(7, 9):\\n    driver.get(\\'https://fantasy.premierleague.com/leagues/181/standings/c?phase=1&amp;page_new_entries=1&amp;page_standings=\\'+str(y))\\n    html = driver.execute_script(\"return document.documentElement.outerHTML\")\\n    sel_soup = BeautifulSoup(html, \\'html.parser\\')\\n    leaderboard = sel_soup.find(\\'table\\', { \\'class\\': \\'Table-ziussd-1 hOInPp\\' })\\n    tbody = leaderboard.find(\\'tbody\\')\\n\\n    for tr in tbody.find_all(\\'tr\\', {\\'class\\': \\'StandingsRow-fwk48s-0 jRzimt\\'}):\\n        navn = tr.find_all(\\'td\\')[1].find_all(\\'a\\')[0].text.strip()\\n        link = tr.find_all(\\'td\\')[1].find_all(\\'a\\')[0][\\'href\\']\\n        print(navn, link)\\n    time.sleep(random.randint(5, 10))\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Spark read key value pairs from the file into a Dataframe', '<python><scala><apache-spark><pyspark><apache-spark-sql>', '<p>I need to read a log file and convert it into a spark dataframe.</p>\\n<p><strong>Input File Content:</strong></p>\\n<pre><code>dateCreated   : 20200720\\ncustomerId    :  001\\ndateCreated   : 20200720\\ncustomerId    :  002\\ndateCreated   : 20200721\\ncustomerId    :  003\\n</code></pre>\\n<p><strong>Expected Dataframe:</strong></p>\\n<pre><code>---------------------------\\n|dateCreated | customerId |\\n---------------------------\\n|20200720    | 001        |\\n|20200720    | 002        |\\n|20200721    | 003        |\\n|------------|------------|\\n</code></pre>\\n<p><strong>Spark code :</strong></p>\\n<pre><code>val spark = org.apache.spark.sql.SparkSession.builder.master(&quot;local&quot;).getOrCreate\\n    val inputFile = &quot;C:\\\\\\\\log_data.txt&quot;\\n    val rddFromFile = spark.sparkContext.textFile(inputFile)\\n\\n    val rdd = rddFromFile.map(f =&gt; {\\n      f.split(&quot;:&quot;)\\n    })\\n\\n    rdd.foreach(f =&gt; {\\n      println(f(0) + &quot;\\\\t&quot; + f(1))\\n    })\\n</code></pre>\\n<p>Any idea on how to convert the above rdd to a required DF ?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('QGIS create LineString from QgsPointXY list', '<python><qgis>', \"<p>I have a list of QgsPointXY objects. I want to have a LineString layer from them.\\nI am using this code:</p>\\n<pre><code>    vl = QgsVectorLayer(&quot;LineString&quot;, &quot;temp&quot;, &quot;memory&quot;)\\npr = vl.dataProvider()\\n\\nwith edit(vl):\\n    pr.addAttributes([QgsField(&quot;id&quot;,  QVariant.Int)])\\n    vl.updateFields()\\n    points = route\\n    fields = pr.fields()\\n    feature = QgsFeature()\\n    feature.setGeometry(QgsGeometry.fromPolylineXY(route))\\n    feature.setFields(fields)\\n    feature.setAttribute('id', 1)\\n    vl.addFeature(feature)\\n\\nQgsProject.instance().addMapLayer(vl)\\n</code></pre>\\n<p>But the layer which is created has only the second coordinate of every point. So it looks like this:\\n&quot;0.0,5924692.45592564 0.0,5924726.27518673 0.0,5924731.97704595&quot; etc...\\nThe original &quot;route&quot; list has all the coordinates, I checked it</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('ValueError: operands could not be broadcast together with shapes (1,55) (42,)', '<python><python-3.x><pandas><list><python-2.7>', '<p><a href=\"https://drive.google.com/file/d/1Q4iJOHgRfuZDmQY-Iv2-M4t3A3ECpiTn/view?usp=sharing\" rel=\"nofollow noreferrer\">To Download Dataset click link</a></p>\\n<p>I am trying to find out disease type based on the symptoms, by using a machine learning model. All are going well but when I trying to predict the disease type based on given symptoms it gives me &quot;ValueError: operands could not be broadcast together with shapes (1,55) (42,) &quot;  that error. to solve this i have seen many of the similar post but not able to solve it.</p>\\n<pre><code>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline\\n\\nimport re\\nimport string\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom sklearn.metrics import f1_score\\nfrom sklearn.model_selection import train_test_split\\nfrom nltk.stem.snowball import SnowballStemmer\\nfrom nlppreprocess import NLP\\n\\nimport math\\nimport string\\npunct = string.punctuation\\nimport spacy\\nimport en_core_web_sm\\nnlp = en_core_web_sm.load()\\n#nlp = spacy.load(&quot;en_core_web_sm&quot;)\\nfrom spacy.lang.en.stop_words import STOP_WORDS\\n\\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report, roc_curve, auc\\n\\nfrom sklearn.naive_bayes import GaussianNB\\ngnb = GaussianNB()\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/ppEHm.png\" rel=\"nofollow noreferrer\">input data</a></p>\\n<pre><code>w = pd.read_csv(&quot;symptom_disease.csv&quot;)\\n\\nw = w.fillna(int(0))\\n\\nX = w.drop([&quot;Disease&quot;],axis=1)\\n\\nm = w[&quot;Disease&quot;]\\n\\ndata = [1,2,3,4,5,6,7,8,9,10]\\ny = pd.DataFrame(data,columns=[&quot;disease&quot;])\\n\\ngnb=gnb.fit(X,np.ravel(y))\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/EKaHs.png\" rel=\"nofollow noreferrer\">X.head()</a></p>\\n<pre><code>X.head()\\n\\noutput:\\n\\nPassing much less urine Bleeding from any body part Feeling extremely lethargic/weak    Excessive sleepiness/restlessness   Altered mental status   Seizure/fits    Breathlessness  Blood in sputum Chest pain  Sound/noise in breathing    ... diarrhoea   sweats and chills   difficulty breathing    sweating and shivering  rapid heartbeat sweating    shivering   loss of appetite    coughing up blood   vomiting\\n0   1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\\n1   0.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\\n2   0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\\n3   0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\\n4   0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\\n\\n\\n\\n\\n\\n\\n\\nimport spacy\\nnlp = spacy.load(&quot;en_core_web_sm&quot;)\\nt = [\\'Passing much less urine\\',\\'Bleeding from any body part\\',\\'Feeling extremely lethargic/weak\\',\\'Excessive sleepiness/restlessness\\',\\'Altered mental status\\',\\'Seizure/fits\\',\\'Breathlessness\\',\\'Blood in sputum\\',\\'Chest pain\\',\\'Sound/noise in breathing\\',\\'Drooling of saliva\\',\\'Difficulty in opening mouth\\',\\'Eye irritation\\',\\'Runny nose\\',\\'Stuffy nose\\',\\'watery eyes\\',\\'Sneezing\\',\\'itchy nose\\',\\'itchy throat\\',\\'fever\\',\\'headache\\',\\'intense pain\\',\\'fatigue\\',\\'dry cough\\',\\'bloody stools\\',\\'loose stools\\',\\'nausea\\',\\'shortness of breath\\',\\'tight chest\\',\\'cough\\',\\'short of breath\\',\\'muscle pains\\',\\'diarrhoea\\',\\'sweats and chills\\',\\'difficulty breathing\\',\\'sweating and shivering\\',\\'rapid heartbeat\\',\\'sweating\\',\\'shivering\\',\\'loss of appetite\\',\\'coughing up blood\\',\\'vomiting\\',\\'Weakness\\',\\'Stomach pain\\',\\'constipation\\',\\'Cough\\',\\'Chills\\',\\'Abdominal pain\\',\\'Yellow skin color\\',\\'skin color yellow\\',\\'Dark-colored urine\\',\\'clay-colored stool\\',\\'yellow color urine\\',\\'weight loss\\',\\'itchy skin\\']\\n#t = [\\'Passing much less urine\\', \\'Bleeding from any body part\\', \\'Feeling extremely lethargic/weak\\', \\'Excessive sleepiness/restlessness\\', \\'Altered mental status\\', \\'Seizure/fits\\', \\'Breathlessness\\', \\'Blood in sputum\\', \\'Chest pain\\', \\'Sound/noise in breathing\\', \\'Drooling of saliva\\', \\'Difficulty in opening mouth\\']\\ndocs = nlp.pipe(t)\\n\\nl1= []\\nfor doc in docs:\\n    clean_doc = &quot; &quot;.join([tok.lemma_.lower() for tok in doc if not tok.is_stop and not tok.is_punct])\\n    l1.append(clean_doc)\\n\\n\\n\\n\\n\\n\\n\\nl2=[]\\nfor i in range(0,len(l1)):\\n    l2.append(0)\\nprint(l2)\\n\\n\\nimport spacy\\nnlp = spacy.load(&quot;en_core_web_sm&quot;)\\n\\npsymptoms = [&quot;Blood in sputum&quot;,&quot;Chest pain&quot;,&quot;Sound/noise in breathing&quot;,&quot;Breathlessness&quot;]\\ndocs = nlp.pipe(psymptoms)\\n\\nsym= []\\nfor doc in docs:\\n    clean_doc = &quot; &quot;.join([tok.lemma_.lower() for tok in doc if not tok.is_stop and not tok.is_punct])\\n    sym.append(clean_doc)\\n\\n\\nfor k in range(0,len(l1)):\\n    for z in sym:\\n        #print(z)\\n        if(z==l1[k]):\\n            l2[k]=1\\n\\ninputtest = [l2]\\npredict = gnb.predict(inputtest)\\n---------------------------------------------------------------------------\\nValueError                                Traceback (most recent call last)\\n&lt;ipython-input-39-d99236746b75&gt; in &lt;module&gt;\\n      1 #print(inputtest)\\n----&gt; 2 predict = gnb.predict(inputtest)\\n\\n~\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\naive_bayes.py in predict(self, X)\\n     76         check_is_fitted(self)\\n     77         X = self._check_X(X)\\n---&gt; 78         jll = self._joint_log_likelihood(X)\\n     79         return self.classes_[np.argmax(jll, axis=1)]\\n     80 \\n\\n~\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\naive_bayes.py in _joint_log_likelihood(self, X)\\n    454             jointi = np.log(self.class_prior_[i])\\n    455             n_ij = - 0.5 * np.sum(np.log(2. * np.pi * self.sigma_[i, :]))\\n--&gt; 456             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\\n    457                                  (self.sigma_[i, :]), 1)\\n    458             joint_log_likelihood.append(jointi + n_ij)\\n\\nValueError: operands could not be broadcast together with shapes (1,55) (42,)\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/golhU.png\" rel=\"nofollow noreferrer\">Error msg picture</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python file.read() seeing junk characters at the beginning of a file', '<python><file-io>', '<p>I\\'m trying to use Python to concatenate a few javascript files together before minifying them, basically like so:</p>\\n\\n<pre><code>outfile = open(\"output.js\", \"w\")\\nfor somefile in a_list_of_file_names:\\n    js = open(somefile)\\n    outfile.write(js.read())\\n    js.close()\\noutfile.close()\\n</code></pre>\\n\\n<p>The minifier complains about illegal characters and syntax errors at the beginning of each file, so I did some diagnostics.</p>\\n\\n<pre><code>&gt;&gt;&gt; r = open(\"output.js\")\\n&gt;&gt;&gt; somestring = r.readline()\\n&gt;&gt;&gt; somestring\\n\\'\\\\xef\\\\xbb\\\\xbfvar $j = jQuery.noConflict(),\\\\n\\'\\n&gt;&gt;&gt; print somestring\\nvar $j = jQuery.noConflict(),\\n</code></pre>\\n\\n<p>The first line of the file should, of course be \"var $j = jQuery.noConflict(),\"</p>\\n\\n<p>In case it makes a difference, I\\'m working from within Windows. </p>\\n\\n<p>Any thoughts?</p>\\n\\n<p>Edit: Here\\'s what I\\'m getting from the minifier: </p>\\n\\n<pre><code>U:\\\\&gt;java -jar c:\\\\path\\\\yuicompressor-2.4.2.jar c:\\\\path\\\\somefile.js -o c:\\\\path\\\\bccsminified.js --type js -v\\n\\n[INFO] Using charset Cp1252\\n\\n[ERROR] 1:2:illegal character\\n\\n[ERROR] 1:2:syntax error\\n\\n[ERROR] 1:3:illegal character\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('MySQL: Get dates with and without category/subcategory in ONE query (and sorted)', '<python><mysql>', \"<p>I have a database with 4 tables with this structure:</p>\\n\\n<ul>\\n<li>categories</li>\\n<li>subcategories</li>\\n<li>dates</li>\\n<li>events</li>\\n</ul>\\n\\n<p>We have events, that can have multiple dates. Events are categorized in categories and subcategories, but can have only a category and no subcategory, too.</p>\\n\\n<p>I  tried this query:</p>\\n\\n<pre><code>SELECT\\n    t.id as sortid,\\n    t.numprint,\\n    s.titel,\\n    s.intro,\\n    s.inhalte,\\n    s.zielgruppe,\\n    s.methoden,\\n    s.kapitelprint,\\n    s.unterkapitelprint,\\n    t.ort,\\n    t.bundesland,\\n    t.email,\\n    t.telefon,\\n    t.preis,\\n    t.dateprint\\nFROM\\n    kapitel k\\nLEFT JOIN\\n    unterkapitel u\\n    ON u.parent = k.id\\nLEFT JOIN\\n    seminare s\\n    ON s.kapitel = k.id\\n    AND s.unterkapitel = u.id\\n    AND s.aktiv = 1\\nLEFT JOIN\\n    termine t\\n    ON t.parent = s.id\\n</code></pre>\\n\\n<p>But this doesn't get the events with no subcategory - they all have NONE in all fields.\\nIs there a way to get all dates in one query?</p>\\n\\n<p>Thanks in advance,\\nSebastian</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"How do I find the midpoint of two numbers that are represented as a string and partial fraction eg. '1 1/2 - 2'?\", '<python><pandas><data-conversion>', \"<p>l = ['1 1/2 - 2',\\n'1 - 1 1/2',\\n'1 1/4 - 2',\\n'1 1/4 - 2',\\n'1 - 11/2',\\n'3 - 5',\\n'1 1/4 - 2']</p>\\n\\n<p>How do I find the midpoint for each of ranges in the list? For example the first one '1 1/2 - 2' should be 1.75</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Find nearest neighbors for arrays of different dimentions', '<python><arrays><nearest-neighbor>', \"<p>I have to compute a similarity measure on several thousands of uneven arrays. \\nThe naive implementation is basically in O(n) and it's taking too long for the number of arrays I have.\\nHopefully, I'm interested only in the similarity for the most similar arrays. \\nSo far I used the sci-kit learn implementation of <code>NearestNeighbors</code> which does the job for arrays with the same number of dimensions. However, <code>NearestNeighbors</code> is based on a KD-tree and I think it's not possible to apply this algorithm for uneven arrays.</p>\\n\\n<p>Is there any alternative for arrays of different dimensions?</p>\\n\\n<p>Here is a code snippet summarizing the problem:</p>\\n\\n<pre><code>import numpy as np\\n\\nfrom sklearn.neighbors.unsupervised import NearestNeighbors\\n\\n\\ndef partial_mse(a: np.array, b: np.array) -&gt; float:\\n    def mse(a: np.array, b: np.array) -&gt; float:\\n        mse = (np.square(a - b)).mean()\\n        return -np.sqrt(mse)\\n\\n    if a.size == b.size:\\n        return mse(a, b)\\n\\n    # a is always the bigger one\\n    if a.size &lt; b.size:\\n        a, b = b, a\\n\\n    partial_mse = [mse(a[i:i + b.size], b) for i in range(a.size - b.size + 1)]\\n    return np.max(partial_mse)\\n\\nuneven_array = np.array([[1, 2, 3, 4], [3, 4], [3, 2, 6], [2, 1, 3], [3]])\\neven_array = np.array([[1, 2, 3, 4], [3,2, 4, 1], [3, 2, 6, 1], [2, 6, 1, 3], [3, 5, 2, 0]])\\n\\n\\nnnfit = NearestNeighbors(n_neighbors=2, algorithm='auto', n_jobs=-1,\\n                         metric=partial_mse, metric_params={}).fit(uneven_array)\\n</code></pre>\\n\\n<pre><code>ValueError: setting an array element with a sequence.\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Having problem with csv export in python with jupyter', '<python><pandas><csv><dataframe><arima>', '<p>i\\'ve tried several solutions that have on stack and each one give me some diferent error. The last one i tried is this:</p>\\n\\n<pre><code>df = pd.read_csv(\\'arima1.csv\\', sep=\\';\\',parse_dates={\\'Month\\':[0, 1]}, index_col = \\'Month\\')\\ndf.head()\\nplt.xlabel(\\'Data\\')\\nplt.ylabel(\\'Receita\\')\\nplt.plot(df)\\n</code></pre>\\n\\n<p>and i get this error:</p>\\n\\n<pre><code>IndexError: list index out of range\\n</code></pre>\\n\\n<p>this is my CSV file:\\n<a href=\"https://drive.google.com/file/d/1BlDo10_Oz1RzFEcosiVgdGickXs4elSA/view?usp=sharing\" rel=\"nofollow noreferrer\">https://drive.google.com/file/d/1BlDo10_Oz1RzFEcosiVgdGickXs4elSA/view?usp=sharing</a></p>\\n\\n<p>thks</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('creating columns with continuous values on individual csv files', '<python><dataframe><csv>', '<p>I have a large csv file which I have split into six individual files. I am using a \\'for loop\\' to read each file and create a column\\nin which the values ascend by one.</p>\\n<pre><code>whole_file=[\\'100Hz1-raw.csv\\',\\'100Hz2-raw.csv\\',\\'100Hz3-raw.csv\\',\\'100Hz4-raw.csv\\',\\'100Hz5-raw.csv\\',\\'100Hz6-raw.csv\\']\\n\\nfirst_file=True\\n\\nfor piece in whole_file:\\n    if not first_file:\\n        skip_row = [0] # if it is not the first csv file then skip the header row (row 0) of that file\\n    else:\\n        skip_row = []\\n    V_raw = pd.read_csv(piece)\\n    V_raw[\\'centiseconds\\'] = np.arange(len(V_raw)) #label each centisecond\\n</code></pre>\\n<p><a href=\"https://i.stack.imgur.com/oCF3k.png\" rel=\"nofollow noreferrer\">My output:</a></p>\\n<p><a href=\"https://i.stack.imgur.com/Ef3vR.png\" rel=\"nofollow noreferrer\">My desired output</a></p>\\n<p>Is there a clever way of doing what I intend.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Can i access Twitch API from my own webapp to get clips?', '<python><node.js><twitch><twitch-api>', \"<p>I am new to twitch api and I don't clearly know how to use it properly yet. I registered my application in Twitch developer and got my Client Id. But can I use Twitch API for free from my webapp to get info about users, clips, subscribers and so on?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to implement gimp like highlights and white point adjustment functionality using opencv?', '<python><python-3.x><opencv><computer-vision><opencv-python>', '<p>Gimp is a famous open source image editor. Is there any way to implement this <strong>gimp</strong> like highlights and white point adjustment functionality using OpenCV. I\\'m currently working on an image manipulation project. And, want to implement this functionality in my projects. I researched everything that is available on the internet but nothing actually works for me.</p>\\n<p>Specifically, I want to add a slider functionality that will adjust image highlights and white point adjustment.</p>\\n<p>As per the documentation in gimp:-</p>\\n<p><a href=\"https://docs.gimp.org/2.10/en/gimp-filter-shadows-highlights.html\" rel=\"nofollow noreferrer\">https://docs.gimp.org/2.10/en/gimp-filter-shadows-highlights.html</a></p>\\n<p><strong>High Lights Adjustment</strong>  This slider controls the effect on highlights; negative values will darken highlights while positive values will lighten them up.</p>\\n<p><strong>White Point Adjustment</strong> By default the algorithm of this modules leaves black point and white point untouched. In some cases an image might contain tonal variations beyond the white point, i.e. above a luminance value of 100. A negative shift in the white point adjustment slider allows to bring these values down into the proper range so that further details in the highlights get visible.</p>\\n<p>I want this same effect that gimp uses in this slider.\\nPlease help me to find</p>\\n<p><a href=\"https://i.stack.imgur.com/nK1nx.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nK1nx.png\" alt=\"Gimpp ScreenShot\" /></a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Debugging Python ctypes segmentation fault', '<c++><python><ctypes>', '<p>I am trying to port some Python <code>ctypes</code> code from a Windows-specific program to link with a Linux port of my library. The shortest Python code sample that describes my problem is shown below. When I try to execute it, I receive a segmentation fault in <code>examine_arguments()</code> in Python. I placed a <code>printf</code> statement in my library at the crashing function call, but it is never executed, which leads me to think the problem is in the ctypes code.</p>\\n\\n<pre><code>import ctypes\\n\\navidll = ctypes.CDLL(\"libavxsynth.so\")\\n\\n\\nclass AVS_Value(ctypes.Structure, object):\\n    def __init__(self, val=None):\\n        self.type=ctypes.c_short(105) # \\'i\\'\\n        self.array_size = 5\\n        self.d.i = 99\\n\\n\\nclass U(ctypes.Union):\\n    _fields_ = [(\"c\", ctypes.c_void_p),\\n                (\"b\", ctypes.c_long),\\n                (\"i\", ctypes.c_int),\\n                (\"f\", ctypes.c_float),\\n                (\"s\", ctypes.c_char_p),\\n                (\"a\", ctypes.POINTER(AVS_Value))]\\n\\n\\nAVS_Value._fields_ = [(\"type\", ctypes.c_short),\\n                      (\"array_size\", ctypes.c_short),\\n                      (\"d\", U)]\\n\\n\\navs_create_script_environment = avidll.avs_create_script_environment\\navs_create_script_environment.restype = ctypes.c_void_p\\navs_create_script_environment.argtypes = [ctypes.c_int]\\n\\navs_set_var = avidll.avs_set_var\\navs_set_var.restype = ctypes.c_int\\navs_set_var.argtypes = [ctypes.c_void_p, ctypes.c_char_p, AVS_Value]\\n\\n\\nenv = avs_create_script_environment(2)\\nval = AVS_Value()\\nres = avs_set_var(env, b\\'test\\', val)\\n</code></pre>\\n\\n<p>My library has the following in its headers, and a plain-C program doing what I describe above (calling <code>create_script_environment</code> followed by <code>set_var</code>) runs fine. Looking at logging information my library is putting onto the console, the crash happens when I try to enter <code>avs_set_var</code>.</p>\\n\\n<pre><code>typedef struct AVS_ScriptEnvironment AVS_ScriptEnvironment;\\ntypedef struct AVS_Value AVS_Value;\\nstruct AVS_Value {\\n  short type;  // \\'a\\'rray, \\'c\\'lip, \\'b\\'ool, \\'i\\'nt, \\'f\\'loat, \\'s\\'tring, \\'v\\'oid, or \\'l\\'ong\\n               // for some function e\\'rror\\n  short array_size;\\n  union {\\n    void * clip; // do not use directly, use avs_take_clip\\n    char boolean;\\n    int integer;\\n    float floating_pt;\\n    const char * string;\\n    const AVS_Value * array;\\n  } d;\\n};\\nAVS_ScriptEnvironment * avs_create_script_environment(int version);\\nint avs_set_var(AVS_ScriptEnvironment *, const char* name, AVS_Value val);\\n</code></pre>\\n\\n<p>I tried backtracing the call from GDB, but I don\\'t understand how to interpret the results nor really much about using GDB.</p>\\n\\n<pre><code>#0  0x00007ffff61d6490 in examine_argument () from /usr/lib/python2.7/lib-dynload/_ctypes.so\\n#1  0x00007ffff61d65ba in ffi_prep_cif_machdep () from /usr/lib/python2.7/lib-dynload/_ctypes.so\\n#2  0x00007ffff61d3447 in ffi_prep_cif () from /usr/lib/python2.7/lib-dynload/_ctypes.so\\n#3  0x00007ffff61c7275 in _ctypes_callproc () from /usr/lib/python2.7/lib-dynload/_ctypes.so\\n#4  0x00007ffff61c7aa2 in PyCFuncPtr_call.2798 () from /usr/lib/python2.7/lib-dynload/_ctypes.so\\n#5  0x00000000004c7c76 in PyObject_Call ()\\n#6  0x000000000042aa4a in PyEval_EvalFrameEx ()\\n#7  0x00000000004317f2 in PyEval_EvalCodeEx ()\\n#8  0x000000000054b171 in PyRun_FileExFlags ()\\n#9  0x000000000054b7d8 in PyRun_SimpleFileExFlags ()\\n#10 0x000000000054c5d6 in Py_Main ()\\n#11 0x00007ffff68e576d in __libc_start_main () from /lib/x86_64-linux-gnu/libc.so.6\\n#12 0x000000000041b931 in _start ()\\n</code></pre>\\n\\n<p>I\\'m at a loss as to how to approach this problem. I\\'ve looked at the details of the calling types, but I don\\'t see anything obviously incorrect there. Am I falling into any platform-specific usages of types?</p>\\n\\n<p><strong>Edit</strong> It seems there\\'s a problem with 32-bit vs 64-bit architectures in the ctypes module. When I tested this again with a 32-bit build of my library and 32-bit Python, it ran successfully. On 64-bit, it segfaults at the same place.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('PYQT5 - How to call another screen using PyQT (MVC)', '<python><python-3.x><qt><pyqt><pyqt5>', '<p>Guys!</p>\\n\\n<p>I\\'m working with QTDesigner and PyQT5, I\\'ve created two screens using QTDesi. A Login form and a Main form. I\\'m trying to call the main screen after the login screen. But it didn\\'t work. I\\'ve looked up to many tutorials, but non of them, worked for me. </p>\\n\\n<p>Here\\'s some code: </p>\\n\\n<p>To call the Login Screen, I\\'ve used this class (On Controller): </p>\\n\\n<pre><code>class LoginController(QtWidgets.QDialog, Ui_Dialog):\\n    def __init__(self, parent=None):\\n        QtWidgets.QMainWindow.__init__(self, parent=parent)\\n        super().__init__(parent)\\n        self.setupUi(self)\\n        self.txtLogo.setPixmap(QtGui.QPixmap(\\'../gui/img/icons/aperam.png\\'))\\n        self.action_performed()\\n\\n    def action_performed(self):\\n        self.pushButton.clicked.connect(self.valid_login)\\n\\n    def valid_login(self):\\n        user = self.txtUser.text()\\n        password = self.txtPassword.text()\\n        if model.validate_login(user, password):\\n            self.close()\\n            main = HomeScreen()\\n</code></pre>\\n\\n<p>Then, to call the Main Screen, I\\'m using this: </p>\\n\\n<pre><code>class HomeScreen(Ui_Model):\\n    def __init__(self):\\n        super(HomeScreen, self).__init__()\\n        self.ui = Ui_Model()\\n        self.main = QtWidgets.QMainWindow()\\n        self.login_home_screen()\\n\\n    def login_home_screen(self):\\n        self.ui.setupUi(self.main)\\n        self.main.show()\\n        self.ui.actionNovo.triggered.connect(self.user_screen_show)\\n        self.main.close()\\n</code></pre>\\n\\n<p>But It didn\\'t work for me. It only shows up a black screen then closes. </p>\\n\\n<p>The \"Start\" from the system is this code (Where I call the LoginScreen): </p>\\n\\n<pre><code>cd = LoginController()\\n\\n\\n\\nif __name__ == \"__main__\":\\n    import sys\\n    ui = LoginController()\\n    cd.show()\\n    sys.exit(app.exec_())\\n\\n</code></pre>\\n\\n<p>Can you help me? I\\'ve tried to many tutorials and articles, but both them didn\\'t work. I want to call another form after the login is sucessufuly. </p>\\n\\n<p>Thanks</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Writing a script for fetching the specific part of a web page in a loop for offline use', '<python><scripting><offline-browsing>', '<p>I have a specific use. I am preparing for GRE. Everytime a new word comes, I look it up at\\nwww.mnemonicdictionary.com, for its meanings and mnemonics. I want to write a script in python preferably ( or if someone could provide me a pointer to an already existing thing as I dont know python much but I am learning now) which takes a list of words from a text file, and looks it up at this site, and just fetch relevant portion (meaning and mnemonics) and store it another text file for offline use. Is it possible to do so ?? I tried to look up the source of these pages also. But along with html tags, they also have some ajax functions. \\nCould someone provide me a complete way how to go about this ??</p>\\n\\n<p>Example: for word impecunious:</p>\\n\\n<p>the related html source is like this </p>\\n\\n<pre><code>&lt;ul class=\\'wordnet\\'&gt;&lt;li&gt;&lt;p&gt;(adj.)&amp;nbsp;not having enough money to pay for necessities&lt;/p&gt;&lt;u&gt;synonyms&lt;/u&gt; : &lt;a href=\\'http://www.mnemonicdictionary.com/word/hard up\\' onclick=\"ajaxSearch(\\'hard up\\',\\'click\\'); return false;\"&gt;hard up&lt;/a&gt; , &lt;a href=\\'http://www.mnemonicdictionary.com/word/in straitened circumstances\\' onclick=\"ajaxSearch(\\'in straitened circumstances\\',\\'click\\'); return false;\"&gt;in straitened circumstances&lt;/a&gt; , &lt;a href=\\'http://www.mnemonicdictionary.com/word/penniless\\' onclick=\"ajaxSearch(\\'penniless\\',\\'click\\'); return false;\"&gt;penniless&lt;/a&gt; , &lt;a href=\\'http://www.mnemonicdictionary.com/word/penurious\\' onclick=\"ajaxSearch(\\'penurious\\',\\'click\\'); return false;\"&gt;penurious&lt;/a&gt; , &lt;a href=\\'http://www.mnemonicdictionary.com/word/pinched\\' onclick=\"ajaxSearch(\\'pinched\\',\\'click\\'); return false;\"&gt;pinched&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\\n</code></pre>\\n\\n<p>but the web page renders like this: </p>\\n\\n<p><strong>(adj.) not having enough money to pay for necessities\\nsynonyms : hard up , in straitened circumstances , penniless , penurious , pinched</strong></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Detecting blog or forum software using python?', '<python>', '<p>Is there a way beside checking for known signatures in the site content to find out what kind of software is the website running e.g vbbuliten,WP etc, preferably python.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Cant redirect stdout, stderr to another logger in Celery', '<python><celery>', \"<p>Cant redirect stdout to another logger in Celery, I have created special logger objects for Celery with special Handler. And I want to catch all exception occured when task are executed. I add handler for setup_logging signal in celery, to install my own loggers:</p>\\n\\n<pre><code>import sys\\nimport logging.config\\n\\nfrom pika.adapters import BlockingConnection\\nfrom pika.connection import ConnectionParameters\\nfrom pika import BasicProperties\\n\\nfrom celery.signals import setup_logging, after_setup_logger\\n\\n\\nclass RabbitMqHandler(logging.Handler):\\n    '''\\n    Special logging handler which stores log messages in RabbitMq server\\n    It can used for async delivering message to clients\\n    '''\\n\\n    HOST = 'localhost'\\n    QUEUE = 'hermes.standard'\\n\\n    def emit(self, record):\\n        con = BlockingConnection(ConnectionParameters(self.HOST))\\n        # Open the channel\\n        channel = con.channel()\\n\\n        # Declare the queue\\n        channel.queue_declare(queue=self.QUEUE, durable=True,\\n                              exclusive=False, auto_delete=False)\\n\\n        channel.basic_publish(exchange='', routing_key=self.QUEUE, body=self.format(record)) #','.join(dir(record)))\\n        con.close()\\n\\n\\nLOGGING = {\\n    'version': 1,\\n    'disable_existing_loggers': True,\\n    'formatters': {\\n        'verbose': {\\n            'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'\\n        },\\n        'simple': {\\n            'format': '%(levelname)s %(message)s'\\n        },\\n        'timed': {\\n            'format': '[%(asctime)s: %(levelname)s] %(message)s'\\n        },\\n    },\\n    'handlers': {\\n        'null': {\\n            'level':'DEBUG',\\n            'class':'django.utils.log.NullHandler',\\n        },\\n        'console':{\\n            'level':'DEBUG',\\n            'class':'logging.StreamHandler',\\n            'formatter': 'timed'\\n        },\\n        'rabbit': {\\n            'level': 'INFO',\\n            'class': 'logconfig.RabbitMqHandler',\\n            'formatter': 'timed'\\n        },\\n        'celery': {\\n            'level': 'ERROR',\\n            'class': 'logging.FileHandler',\\n            'filename': '1.log',\\n            'formatter': 'timed',\\n            }\\n    },\\n    'loggers': {\\n        'celery': {\\n            'handlers': ['celery'],\\n            'level': 'INFO',\\n        },\\n        'hermes': {\\n            'handlers': ['console', 'rabbit'],\\n            'level': 'INFO',\\n        }\\n    }\\n}\\n\\nfrom celery.log import LoggingProxy\\n\\n@setup_logging.connect\\ndef setup_logconfig(**kwargs):\\n    logging.config.dictConfig(LOGGING)\\n    #return logging.getLogger('hermes')\\n</code></pre>\\n\\n<p>My own logger named 'hermes' works properly, but all exception occured catch standard celery's logger name=celery. I tried to overrride with setting: </p>\\n\\n<p>CELERY_REDIRECT_STDOUTS =False</p>\\n\\n<p>But it doesn't works also. All exception goes to standard celery logger. </p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('in flask-WTF forms how to custom the size of text field?', '<python><flask><flask-wtforms>', '<p>In forms created by flask-wtf, how can I specify the height and width of text field input</p>\\n\\n<pre><code>{% extends \"base.html\" %}\\n{% block title %} Title {% endblock %}\\n{% block body %}\\n &lt;form method=\"POST\"&gt;\\n     {{ form.textfld.label }} &lt;br&gt;\\n     {{form.textfld(size=100)}}\\n &lt;/form&gt;\\n{% endblock %}\\n</code></pre>\\n\\n<p>This is the only example I can find which changes only the width but not height. I tried to add a class to it and target the class in base.html but nothing is changed.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"cannot import name 'Type'\", '<python><scikit-learn>', '<p>I would like to know what this error is about.\\nIt pops up after I run a small script using this lib --> </p>\\n\\n<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer\\n\\nTraceback (most recent call last):\\n  File \"C:/Users/migue/PycharmProjects/research4me/tfidf.py\", line 17, in &lt;module&gt;\\n    getUniqueWords(text)\\n  File \"C:/Users/migue/PycharmProjects/research4me/tfidf.py\", line 3, in getUniqueWords\\n    from sklearn.feature_extraction.text import TfidfVectorizer\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\__init__.py\", line 82, in &lt;module&gt;\\n    from .base import clone\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\base.py\", line 20, in &lt;module&gt;\\n    from .utils import _IS_32BIT\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\__init__.py\", line 20, in &lt;module&gt;\\n    from scipy.sparse import issparse\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\__init__.py\", line 156, in &lt;module&gt;\\n    from . import fft\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\fft\\\\__init__.py\", line 76, in &lt;module&gt;\\n    from ._basic import (\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\fft\\\\_basic.py\", line 1, in &lt;module&gt;\\n    from scipy._lib.uarray import generate_multimethod, Dispatchable\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\_lib\\\\uarray.py\", line 27, in &lt;module&gt;\\n    from ._uarray import *\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\_lib\\\\_uarray\\\\__init__.py\", line 114, in &lt;module&gt;\\n    from ._backend import *\\n  File \"C:\\\\Users\\\\migue\\\\PycharmProjects\\\\research4me\\\\venv\\\\lib\\\\site-packages\\\\scipy\\\\_lib\\\\_uarray\\\\_backend.py\", line 1, in &lt;module&gt;\\n    from typing import (\\nImportError: cannot import name \\'Type\\'\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Conda environments python and atom', '<python><conda><atom-editor><environment>', \"<p>I'm pretty new to coding, and am trying to improve the way I'm working. I'm using the anaconda3 distribution of python and do most of my code writing in Atom, then running the code via the command line. I've spent the afternoon reading about virtual environments and am going in circles a bit. My question is this:</p>\\n<p>Should I be defining a new conda environment (other than the base) for each project I create, as the first line of code for each new project?</p>\\n<p>Thanks I'm pretty aware this is a very noob question. I've found some good answers around this, but I think I'm missing some key aspects of the problem.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to turn a script into a function', '<python>', '<p>I have a script that I wrote earlier and am now trying to create a main page to run this script and others. I understand I have to turn this into a function then call it when nesicary but I am having some trouble in the function portion. Any help and advice is greatly appreciated. Below is the script I am referencing. </p>\\n\\n<pre><code>#A Python math script\\na = float(raw_input(\"Enter the first number: \"))\\nb = float(raw_input(\"Enter the second number: \"))\\n\\nprint \"Your answer is: \",(a*b)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python pandas best way to store dataset', '<python><pandas>', '<p>I have a dataset with thousands to entries like the following:\\n<a href=\"https://i.stack.imgur.com/MdoqA.png\" rel=\"nofollow noreferrer\">Dataset Img</a></p>\\n\\n<pre><code>row\\n1 timestamp type    side    strength    amor    health\\n2 23958722  robot_1 left    100         20      100\\n3                   right   200         25      100\\n4           robot_2 left    100         25      90\\n5                   right   80          10      19\\n6           robot_3 right   40          20      200\\n7           robot_4 left    100         100     20\\n8 1424121   robot_1 left    90          19      100\\n9           robot_2 left    90          25      10\\n</code></pre>\\n\\n<p>My questions: </p>\\n\\n<ol>\\n<li>Is it possible to transfer this data into a pandas DataFrame?</li>\\n<li>Will I have to store the timestamp 23958722 (row 2) also for row 3 to 7?</li>\\n<li>Do I have to provide the right side in timestamp 1424121 for robot_1 and robot_2?</li>\\n<li>Is it possible to avoid providing the robot_1 (row 2) again in row 3?</li>\\n</ol>\\n\\n<p>I\\'m also somewhat stuck with how I could set the index here. One query could be for example: Get the health values of all robot_1 on the right. Which should only return row 3.</p>\\n\\n<p>Any help is highly appreciated!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Can we record hangouts meet calls using Python?', '<python><hangouts-api>', '<p>Is there any possibility to record Hangouts calls using Python? I want to find any method that records hangouts call using Python. I was trying to find a method by referring to <a href=\"https://python-hangout-api.readthedocs.io/en/latest/\" rel=\"nofollow noreferrer\">Hangout Apis documentation</a>. But I was not able to get a proper solution by using it. As well as I have gone through the following GitHub questions. </p>\\n\\n<ol>\\n<li><p><a href=\"https://stackoverflow.com/questions/41627977/making-a-video-call-using-hangout-api\">Making a Video call using Hangout API [closed]\\n</a></p></li>\\n<li><p><a href=\"https://stackoverflow.com/questions/45253763/google-hangouts-meet-api-documentation\">Google Hangouts Meet API Documentation [closed]</a></p></li>\\n</ol>\\n\\n<p>But even those questions did not help me to get a good answer to my problem.</p>\\n\\n<p>If anyone has done a similar thing tho this please give me an answer to get this work done. It doesn\\'t matter whether that thing have done by using an API or background call recording script. </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('python: stale element reference: element is not attached to the page document', '<python><staleelementreferenceexception>', \"<p>I am facing problem error below:</p>\\n<p>stale element reference: element is not attached to the page document</p>\\n<p>I have to click value in table form to select the data and process to following steps.</p>\\n<p>These are my codes, and error line is the last one.</p>\\n<pre><code>from selenium import webdriver\\nfrom selenium.webdriver.common.keys import Keys\\nfrom selenium.webdriver.support.ui import WebDriverWait\\nfrom selenium.webdriver.support import expected_conditions as EC\\n\\n\\ndriver = webdriver.Chrome()\\ndriver.implicitly_wait(5)\\ndriver.get(&quot;https://tms.samil.com/ProjectMonitoring/ProjectActivityDetail&quot;)\\n\\n\\ndriver.find_element_by_xpath(&quot;//*[@id='searchHeadDiv']/button&quot;).click()\\n\\n\\ndriver.find_element_by_xpath(&quot;//*[@id='projectSearch']/div/div[1]/form/div[2]/a&quot;).click()\\ndriver.find_element_by_xpath(&quot;//*[@id='projectSearch']/div/div[1]/form/div[2]/div/div/div/ul/li[2]/a&quot;).click()\\nproject_code_input = driver.find_element_by_xpath(&quot;//*[@id='projectSearch']/div/div[1]/form/input&quot;)\\n\\n\\nproject_list = '00575-01-011'\\nproject_code_input.send_keys(project_list)\\nproject_code_input.send_keys(Keys.ENTER)\\n\\n\\ndriver.find_element_by_xpath(&quot;//*[@id='projectSearchGrid']/div[2]/table/tbody/tr[2]/td[2]&quot;).click()\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to intercept multiple warnings from a Python function?', '<python><warnings>', \"<p>Here's a bit of Python pseudocode to illustrate a problem (I'm working in Python 3.8, although I doubt that matters much):</p>\\n<pre><code>import warnings\\nfrom some_library import function, LibraryWarning  # (a library that I do not control)\\n\\nwarning_log = []\\nwith warnings.catch_warnings():\\n    warnings.simplefilter(&quot;error&quot;)\\n    try:\\n        result = function()\\n    except LibraryWarning as w:\\n        warning_log.append(w)\\n        with warnings.catch_warnings():\\n            warnings.simplefilter(&quot;ignore&quot;)\\n            result = function()\\n</code></pre>\\n<p>The main purpose of this code is to produce <code>result</code> without any warnings cluttering up the screen.  It accomplishes that.  However, I also want to document any warnings that occur for later review.  This code accomplishes that too, provided that <code>function()</code> only generates one warning.  However, sometimes <code>function()</code> produces TWO warnings.  Since I have to switch to ignoring warnings to get <code>result</code>, I never see the second warning and I can't append it to my log.</p>\\n<p>How can I perform a full accounting of all warnings generated, while still obtaining my final\\nresult?</p>\\n<p>Thanks for your advice.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"I have started writing a Flappy Bird game in Pygame and I'm stuck how to show Collision between The Bird and The Bamboo?\", '<python><pygame><collision>', \"<p>So I am pretty new to Pygame, and I am stuck on how to show the collision between the bird and the Bamboo in the flappy bird game and how to keep running it if it hasn't collided with the bamboo.\\nI haven't written the whole code yet, so please tell me what to write for showing collision(with steps and why is it used? In pygame) and also a source code to display after the collision the screen shows GAME OVER.(optional)\\n(Thanks in advance:)</p>\\n<pre><code>import pygame\\npygame.init()\\n\\nWINDOWWIDTH = 820\\nWINDOWHEIGHT = 480\\nwin = pygame.display.set_mode((WINDOWWIDTH, WINDOWHEIGHT))\\npygame.display.set_caption(&quot;The Flappy Bird Game&quot;)\\n\\nbirdload = [pygame.image.load('C:/Users/Vinod/Desktop/Flappy Bird/flapbird.png')]\\n\\nbgimg = pygame.image.load('C:/Users/Vinod/Desktop/Flappy Bird/bg.jpg')\\n\\nclock=pygame.time.Clock()\\n\\nUP = 'up'\\nDOWN ='down'\\nLEFT ='left'\\nRIGHT = 'right'\\n\\nWHITE =(255, 255, 255)\\nBLACK = (0, 0 ,0)\\nRED = (255, 0, 0)\\nGREEN = (0, 255, 0)\\nDARKGREEN = (0, 155,0)\\nDARKGRAY = (40, 40, 40)\\nYELLOW = (255, 255, 0)\\nORANGE = (255, 165, 0)\\nBGCOLOR = BLACK\\nBROWN = (90, 39, 41)\\n\\nscore = 0\\n\\n\\n\\ndef showstartscreen():\\n    global BASICFONT, FPS\\n    FPS = 15\\n    BASICFONT = pygame.font.Font('freesansbold.ttf', 18)\\n    titleFont = pygame.font.Font('freesansbold.ttf', 100)\\n    titleSurf1 = titleFont.render('The Flappy Bird!', True, WHITE, YELLOW)\\n    titleSurf2 = titleFont.render('The Flappy Bird!', True, ORANGE)\\n    degrees1 = 0\\n    degrees2 = 0\\n    while True:\\n        win.fill(BGCOLOR)\\n        rotatedSurf1= pygame.transform.rotate(titleSurf1, degrees1)\\n        rotatedRect1 = rotatedSurf1.get_rect()\\n        rotatedRect1.center= (WINDOWWIDTH / 2, WINDOWHEIGHT / 2)\\n        win.blit(rotatedSurf1, rotatedRect1)\\n        \\n        rotatedSurf2 = pygame.transform.rotate(titleSurf2, degrees2)\\n        rotatedRect2 = rotatedSurf2.get_rect()\\n        rotatedRect2.center = (WINDOWWIDTH / 2, WINDOWHEIGHT / 2)\\n        win.blit(rotatedSurf2,rotatedRect2)\\n        \\n        drawPressKeyMsg()\\n        \\n        pygame.display.update()\\n        clock.tick(FPS)\\n        degrees1 += 3 #rotate 3 degrees each frame\\n        degrees2 += 7 #rotate by 7 degrees per frame\\n        \\ndef drawPressKeyMsg():\\n    pressKeySurf = BASICFONT.render('Press a key to play.', True, DARKGRAY)\\n    pressKeyRect = pressKeySurf.get_rect()\\n    pressKeyRect.topleft = (WINDOWWIDTH - 200, WINDOWHEIGHT - 30)\\n    win.blit(pressKeySurf, pressKeyRect)\\n    \\n\\ndef terminate():\\n    pygame.quit()\\n    \\nclass bird(object):\\n    def __init__(self, x, y, width, height, end):\\n        self.x = x\\n        self.y = y\\n        self.width = width\\n        self.height = height\\n        self.end = end\\n        self.path = [self.x, self.end]\\n        self.flyCount = 0\\n        self.vel = 3\\n        self.hitbox = (self.x + 17, self.y + 2, 31, 57)\\n        self.visible = True\\n        \\n    def draw(self, win):\\n        if self.flyCount + 1 &gt;= 27:\\n            self.flyCount = 0\\n\\n        if not(self.standing):\\n            win.blit(birdload[self.flyCount//3], (self.x,self.y))\\n            self.flyCount +=1\\n        else:\\n            win.blit(birdload[0], (self.x, self.y))\\n        self.hitbox = (self.x + 17, self.y + 11, 29, 52)\\n        #pygame.draw.rect(win, (255,0,0), self.hitbox,2)\\n        \\n    def hit(self):\\n        self.isJump = False\\n        self.jumpCount = 10\\n        self.x = 100\\n        self.y = 410\\n        self.flyCount = 0\\n        font1 = pygame.font.SysFont('comicsans', 100)\\n        text = font1.render('-5', 1, (255,0,0))\\n        win.blit(text, (250 - (text.get_width()/2),200))\\n        pygame.display.update()\\n        i = 0\\n        while i &lt; 200:\\n            pygame.time.delay(10)\\n            i += 1\\n            for event in pygame.event.get():\\n                if event.type == pygame.QUIT:\\n                    i = 201\\n                    pygame.quit()\\n                    \\n    def fly(self):\\n        if self.vel &gt; 0:\\n            if self.x + self.vel &lt; self.path[1]:\\n                self.x += self.vel\\n            else:\\n                self.vel = self.vel * -1\\n                self.flyCount = 0\\n        else:\\n            if self.x - self.vel &gt; self.path[0]:\\n                self.x += self.vel\\n            else:\\n                self.vel = self.vel * -1\\n                self.flyCount = 0\\n                    \\n    \\ndef bamboo():\\n    bamb0 = pygame.draw.rect(win, BROWN,(310, 0, 28, 140))#left, top, width, height\\n    pygame.display.flip()\\n    bamb1 = pygame.draw.rect(win, BROWN, (310, 230 , 28, 250))\\n    pygame.display.flip()\\n    bamb2 = pygame.draw.rect(win, BROWN,(410, 0, 28, 100))#left, top, width, height\\n    pygame.display.flip()\\n    bamb3 = pygame.draw.rect(win, BROWN,(410, 160, 28,320))#left, top, width, height\\n    pygame.display.flip()\\n    bamb4 = pygame.draw.rect(win, BROWN,(510, 0, 28,110))#left, top, width, height\\n    pygame.display.flip()\\n    bamb5 = pygame.draw.rect(win, BROWN,(510, 180, 28,300))#left, top, width, height\\n    pygame.display.flip()\\n    bamb6 = pygame.draw.rect(win, BROWN,(600, 0, 28,240))#left, top, width, height\\n    pygame.display.flip()\\n    bamb7 = pygame.draw.rect(win, BROWN,(600, 320, 28,160))#left, top, width, height\\n    pygame.display.flip()\\n    bamb8 = pygame.draw.rect(win, BROWN,(700, 0, 28,120))#left, top, width, height\\n    pygame.display.flip()\\n    bamb9 = pygame.draw.rect(win, BROWN,(700, 200, 28,280))#left, top, width, height\\n    pygame.display.flip()\\n    bamb10 = pygame.draw.rect(win, BROWN,(770, 0, 28,190))#left, top, width, height\\n    pygame.display.flip()\\n    bamb11 = pygame.draw.rect(win, BROWN,(770, 250, 28,230))#left, top, width, height\\n    pygame.display.flip()\\n    \\n    \\nclass sticks(object):\\n    bamboo()\\n    \\n    \\n    def collision():\\n        if bird.x == sticks.x and bird.y == sticks.y:\\n            print(&quot;Game Over&quot;)\\n            gameover()\\n            while True:\\n                if checkForKeyPress():\\n                    pygame.event.get() # clear event queue\\n                    return\\n        else:\\n            True()\\n</code></pre>\\n<p>Please refer to the 'def collision' in the 'class sticks' in the last, i know the code i've added is probably wrong... please answer for this part only...\\nRegards,\\nNishita Thakur.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to download a file from an email and save it in C:\\\\', '<python><microsoft-graph-api><email-attachments>', \"<p>I have the attachment info (&quot;contentBytes&quot;: &quot;iVBORw0KGgoAAAANSUhEUgAAAOEAAADhCAMAAAAJbSJIAAAArlBMVEX...etc) (from a graph API request) and below is the code I'm using to convert it, and this is a success, but I need to save it to the C drive. Is there something extra to add to this or should I be going in a different direction?</p>\\n<pre><code>import base64\\nimgdata = base64.b64decode(contentBytes)\\nfilename = &quot;sample.png&quot;\\nwith open(filename, 'wb') as f:\\n    f.write(imgdata)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How is introspection useful?', '<python><introspection>', '<p>I have been programming mainly in PHP, and I am trying to make a switch to python.  I am skilled with PHP, and I have never needed to use introspection / introspection like capabilities.  What good is code introspection, and in what situations would I find it indispensable?  </p>\\n\\n<p>Here is the only way I find it useful:\\nFrom the examples I saw in \\'Dive into Python\\', introspection basically means that you can list all of the functions and attributes of an object.  To me it seems that introspection is just there as a \"user\\'s manual\" to an object.  It lets you look at the object and its functionality from the python shell.  </p>\\n\\n<p>I just do not see why or in what situation you would take an arbitrary object, introspect upon it, and do something useful.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Apache Spark Enron DataSet', '<python><apache-spark><pyspark><rdd>', \"<p>I am trying to analysis Enron DataSet on apache spark. I want to extract email from and to.\\nFirst created and rdd using following function:</p>\\n\\n<pre><code>def utf8_decode_and_filter(rdd):\\n    def utf_decode(s):\\n        try:\\n            return str(s, 'utf-8')\\n        except:\\n            pass\\n    return rdd.map(lambda x: utf_decode(x[1])).filter(lambda x: x != None)\\n</code></pre>\\n\\n<p>Called the above function with spark sequence </p>\\n\\n<pre><code>data = utf8_decode_and_filter(sc.sequenceFile('/user/ufac001/project1920/samples'))\\n</code></pre>\\n\\n<p>When I do:</p>\\n\\n<pre><code>data.collect()\\n</code></pre>\\n\\n<p>I can see data as list of string with email between the employees. I am guessing it's a list of strings</p>\\n\\n<p>Now to extract triples of email. I wrote following function:</p>\\n\\n<pre><code>def xml_to_emails(s):\\n    print(s)\\n    emailed = []\\n\\n    return s\\n\\nrdd = data.flatMap(lambda x: xml_to_emails(x)).map(lambda word: (word, 1)).reduceByKey(lambda a,b:a+b)\\n</code></pre>\\n\\n<p>My issue is First I cannot extract email because on xml_to_email function print(s) outputs nothing when I run collect on rdd I can print a tuple with letter and a number.</p>\\n\\n<p>How do I extract emails from this rdd?</p>\\n\\n<p>Please be nice I am newbie on spark</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python:How find index of element in column with some condition', '<python><pandas><dataframe>', '<p>This is my dataset</p>\\n\\n<pre><code>import pandas as pd\\ndf={\\'A\\':[\\'1@1\\',\\'2,3\\',\\'3,4\\',5]}\\ndf=pd.DataFrame(df1)\\ndf\\nA\\n0   1@1\\n1   2,3\\n2   3,4\\n3   5\\n</code></pre>\\n\\n<p>I want to find index of data in column A which have <code>\",\"</code></p>\\n\\n<p>I tried this code but it is not working</p>\\n\\n<pre><code>Index=[]\\nfor i in df[\"A\"]:\\n    if (\",\" in i):\\n        Index.append(df[\"A\"][i].index)\\n    else:\\n        continue\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Problem with azure-cognitiveservices-speech on heroku', '<python><azure><heroku>', '<p>I would like deploy my app to heroku server.\\nWhen I send request i response this log:</p>\\n\\n<blockquote>\\n  <p>2020-05-26T13:30:56.122694+00:00 app[web.1]:     _speech_py_impl = swig_import_helper()\\n  2020-05-26T13:30:56.122695+00:00 app[web.1]:   File \"/app/.heroku/python/lib/python3.6/site-packages/azure/cognitiveservices/speech/speech_py_impl.py\", line 16, in swig_import_helper\\n  2020-05-26T13:30:56.122695+00:00 app[web.1]:     return importlib.import_module(\\'_speech_py_impl\\')\\n  2020-05-26T13:30:56.122696+00:00 app[web.1]:   File \"/app/.heroku/python/lib/python3.6/importlib/<strong>init</strong>.py\", line 126, in import_module\\n  2020-05-26T13:30:56.122696+00:00 app[web.1]:     return _bootstrap._gcd_import(name[level:], package, level)\\n  2020-05-26T13:30:56.122702+00:00 app[web.1]: ModuleNotFoundError: No module named \\'_speech_py_impl\\'</p>\\n</blockquote>\\n\\n<p>I have problem with install <strong>ModuleNotFoundError: No module named \\'_speech_py_impl\\'</strong></p>\\n\\n<p>My file requirement.txt</p>\\n\\n<pre><code>Flask\\nrequests\\ngunicorn\\nazure-cognitiveservices-speech\\n</code></pre>\\n\\n<p>Also I have a problem run this command on heroku:</p>\\n\\n<pre><code>sudo apt-get install build-essential libssl1.0.0 libasound2\\n</code></pre>\\n\\n<p>How to solve this problem?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Keras custom loss function : intersection', '<python><tensorflow><keras><loss-function>', \"<p>I want to develop a custom Keras loss function which y_pred is 2 tensor, hereafter I will call this tensor A and B.</p>\\n<p>Where A and B shape is (batch_size, timestep, vector)</p>\\n<p>My loss function is abs(sum(diff(A, intersect(A, B)))-sum(diff(B, intersect(A, B))))</p>\\n<pre><code>    A = [[1.1, 1.2, 1.3],[2.1, 2.2, 2.3], [3.1, 3.2, 3.3], [4.1, 4.2, 4.3], [7.1, 7.2, 7.3]]\\n    B = [[1.1, 1.2, 1.3],[5.1, 5.2, 5.3], [6.1, 6.2, 6.3], [3.1, 3.2, 3.3], [4.1, 4.2, 4.3]]\\n    C = intersect(A, B)\\n        # set operation\\n        # now C should be like [[1.1, 1.2, 1.3], [3.1, 3.2, 3.3], [4.1, 4.2, 4.3]]\\n        # because it's in A and B\\n    D = diff(A, C)\\n        # set operation A-C\\n        # then D should be like  [[2.1, 2.2, 2.3], [7.1, 7.2, 7.3]]]\\n</code></pre>\\n<p>For the sum() and abs() work like reduce_sum and normal abs function</p>\\n<p>So, how can I compute the loss function like this?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('create yaml with AWS CloudFormation references', '<python><yaml><amazon-cloudformation>', \"<p>I need a python code that would create the yaml code below.</p>\\n<pre><code>    Tags:\\n    - Key: key1\\n      Value: !Ref 'AWS::StackName'\\n    - Key: Key2\\n      Value: !Ref 'AWS::StackId'\\n</code></pre>\\n<p>Here is what I have that doesn't do the trick.</p>\\n<pre><code>def generate_resource(ami, source_data):\\n    resource = {\\n         &quot;Type&quot;: &quot;AWS::EC2::Instance&quot;,\\n         &quot;Properties&quot;: {\\n             &quot;ImageId&quot;: ami[&quot;ImageId&quot;],\\n             &quot;InstanceType&quot;: ami[&quot;InstanceType&quot;],\\n             &quot;PrivateIpAddress&quot;: ami[&quot;PrivateIpAddress&quot;],\\n             &quot;KeyName&quot;: ami[&quot;KeyName&quot;]\\n             &quot;SubnetId&quot;: { &quot;Ref&quot;: &quot;SubnetId&quot; },\\n             &quot;SecurityGroupIds&quot;: { &quot;Ref&quot;:  &quot;SecurityGroupId&quot; }, \\n             &quot;Tags&quot;: [\\n                 { &quot;Key&quot;: &quot;key1&quot;, &quot;Value&quot;: &quot;{!Ref 'AWS::StackName'}&quot;},\\n                 { &quot;Key&quot;: &quot;key2&quot;, &quot;Value&quot;: &quot;{!Ref 'AWS::StackId'}&quot;}\\n             ]\\n         }\\n     }\\n</code></pre>\\n<p>The <code>yaml</code> output from this code is not properly formatted so it simply copies <code>{!Ref 'AWS::StackName'}</code>, as the value.</p>\\n<pre><code>import os, sys\\nimport lib.aws as aws, lib.cft as cft, lib.inventory as inventory \\n\\nBUCKET_NAME = 'testbucket'\\n\\n\\ndef generate_cft(commit_hash, file_dict, dry_run):\\n    return (\\n        &quot;# Autogenerated CFT for commit hash &quot; + commit_hash + &quot;\\\\n&quot; + \\n        cft.generate(inventory.read(file_dict[&quot;path&quot;]))\\n    )\\n\\n\\ndef upload_cft(commit_hash, file_dict, cft_text):\\n    target_key = commit_hash + &quot;/&quot; + file_dict[&quot;name&quot;].split(&quot;_&quot;)[0] +    &quot;.yaml&quot;\\n\\n    aws.upload(BUCKET_NAME, target_key, cft_text)\\n\\n\\ndef show_cft(file_dict, cft_text):\\n    print(file_dict[&quot;path&quot;] + &quot; generates the following cft:&quot;)\\n    print(&quot;&quot;)\\n    print(cft_text)\\n    print(&quot;&quot;)\\n\\n\\ndef generate_and_upload(commit_hash, file_dict, dry_run):\\n    cft_text = generate_cft(commit_hash, file_dict, dry_run)\\n\\n    aws.validate_cft(cft_text)\\n\\n    if dry_run: \\n        show_cft(file_dict, cft_text)\\n    else:\\n        upload_cft(commit_hash, file_dict, cft_text)\\n\\n\\ndef generate_and_upload_all(commit_hash, dry_run):\\n    for file_dict in inventory.list():\\n        print(&quot;generating cft for &quot; + file_dict[&quot;path&quot;])\\n        generate_and_upload(commit_hash, file_dict, dry_run)\\n\\n\\nif __name__ == &quot;__main__&quot;:\\n    if not os.getcwd().endswith(&quot;ci&quot;):\\n        print(&quot;Please run this script from the ci directory&quot;)\\n        exit()\\n\\n    commit_hash = sys.argv[1] if len(sys.argv) &gt;= 2 else &quot;test&quot;\\n    generate_and_upload_all(commit_hash, False)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Airflow spinning up multiple subprocess for a single task and hanging', '<python><airflow><airflow-scheduler><airflow-operator><airflow-worker>', '<p>Airflow version = 1.10.10</p>\\n<p>Hosted on Kubernetes, Uses Kubernetes executor.</p>\\n<h3>DAG setup</h3>\\n<p>DAG - Is generated using the dynamic dag</p>\\n<p>Task - Is a PythonOperator that pulls some data, runs an inference, stores the predictions.</p>\\n<p>Where does it hang? - When running the inference using tensorflow</p>\\n<h3>More details</h3>\\n<p>One of our running tasks, as mentioned above, was hanging for 4 hours. No amount of restarting can help it to recover from that point. We found out that the pod had almost 30+ subprocess and 40GB of memory used.</p>\\n<p><a href=\"https://i.stack.imgur.com/6iTfQ.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6iTfQ.png\" alt=\"enter image description here\" /></a></p>\\n<p>We weren\\'t convinced because when running on a local machine, the model doesn\\'t consume more than 400MB. There is no way it can suddenly bump up to 40GB in memory.</p>\\n<p>Another suspicion was maybe it\\'s spinning up so many processes because we are dynamically generating around 19 DAGS. I changed the generator to generate only 1, and the processes didn\\'t vanish. The worker pods still had 35+ subprocesses with the same memory.</p>\\n<p>Here comes the interesting part, I wanted to be really sure that it\\'s not the dynamic DAG. Hence I created an independent DAG that prints out 1..100000 while pausing for 5 seconds each. The memory usage was still the same but not the number of processes.</p>\\n<p><a href=\"https://i.stack.imgur.com/ujK6j.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ujK6j.png\" alt=\"enter image description here\" /></a></p>\\n<p>At this point, I am not sure which direction to take to debug the issue further.</p>\\n<h3>Questions</h3>\\n<ol>\\n<li>Why is the task hanging?</li>\\n<li>Why are there so many sub-processes when using dynamic dag?</li>\\n<li>How can I debug this issue further?</li>\\n<li>Have you faced this before, and can you help?</li>\\n</ol>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Is it possible to prohibit axes rotation with the mouse in Mayavi?', '<python><mayavi>', '<p>I am creating a 2-D plot using Mayavi, in order to take advantage of some of the rendering features. Since it is a 2-D (x,y) plot, placed in 3-D space, I would like restrain the mouse interaction with the plot such that the plot cannot be rotated with the mouse, only zoomed or panned. Is this possible?</p>\\n\\n<p>There is a similar question <a href=\"https://stackoverflow.com/questions/14225512/constrain-mayavi-mouse-drag-to-rotating-earth-around-its-axis\">here</a>, but has not been answered as yet. The code there would apply to my case as well, even though it\\'s 3-D.</p>\\n\\n<p>Regards,</p>\\n\\n<p>-Mark</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Updating library in Raspberry', '<python><raspberry-pi><raspberry-pi3><can-bus><python-can>', '<p>i need your help. I got Raspberry PI 3, I\\'m programming in Python to get CAN messages via PiCAN duo. Program is working perfectly fine, but to get reasonable informations from the source i need to send every 100mS messages to the source. I used this:\\n<code>task = can.send_periodic(\\'can0\\',msg,0.1)\\ntask.start()</code></p>\\n\\n<p>But the program shows me error. I assumed it\\'s because of old library Python_can-1.4.1. So I downloaded newest version of this from Pypi. When i open Manage plugins and click to Install from local file (or any other way) it show me internall error:</p>\\n\\n<p>Traceback (most recent call last):\\n  File \"/usr/lib/python3.7/tkinter/<strong>init</strong>.py\", line 1705, in <strong>call</strong>\\n    return self.func(*args)\\n  File \"/usr/lib/python3/dist-packages/thonny/plugins/pip_gui.py\", line 658, in _handle_install_file_click\\n    initialdir=get_workbench().get_local_cwd,\\n  File \"/usr/lib/python3/dist-packages/thonny/ui_utils.py\", line 1920, in askopenfilename\\n    return _get_dialog_provider().askopenfilename(**options)\\n  File \"/usr/lib/python3/dist-packages/thonny/ui_utils.py\", line 1960, in askopenfilename\\n    args = cls._convert_common_options(\"Open file\", **options)\\n  File \"/usr/lib/python3/dist-packages/thonny/ui_utils.py\", line 1994, in _convert_common_options\\n    filename = _options_to_zenity_filename(options)\\n  File \"/usr/lib/python3/dist-packages/thonny/ui_utils.py\", line 2036, in _options_to_zenity_filename\\n    return options[\"initialdir\"] + os.path.sep\\nTypeError: unsupported operand type(s) for +: \\'method\\' and \\'str\\'</p>\\n\\n<p>I\\'tried to find answer for a very long time. I did Upgrade of PI, but nothing worked. Could you help me? Thank you for your answer</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"elastic beanstalk cron seem dosen't working\", '<python><linux><cron><amazon-elastic-beanstalk>', \"<p>I am trying to deploy a website using Elastic Beanstalk.</p>\\n<p>After crawling every hour and saving it as a .txt file, when the user accesses it, the .txt file loads but it doesn't seem to work.</p>\\n<p>When connected, only the .txt file from the initial deployment is loaded.</p>\\n<p>The current .zip configuration is</p>\\n<pre><code>-.ebextensions\\n     &gt;cron-linx.config\\n-static\\n-templates\\n-application.py\\n-Enterprise.txt\\n-requirements.txt\\n-test.py\\n</code></pre>\\n<p>cron-linux.config</p>\\n<pre><code>files:\\n    &quot;/etc/cron.d/mycron&quot;:\\n        mode: &quot;000644&quot;\\n        owner: root\\n        group: root\\n        content: |\\n            */5 * * * * root /usr/local/bin/myscript.sh\\n\\n    &quot;/usr/local/bin/myscript.sh&quot;:\\n        mode: &quot;000755&quot;\\n        owner: root\\n        group: root\\n        content: |\\n            #!/bin/bash\\n\\n            python3 /var/app/current/test.py\\n\\n            exit 0\\n\\ncommands:\\n    remove_old_cron:\\n        command: &quot;rm -f /etc/cron.d/mycron.bak&quot;\\n</code></pre>\\n<p>test.py</p>\\n<pre><code>import time\\nnow = time.strftime('%H%M%S')\\nf=open('Enterprise.txt','w',encoding='UTF-8')\\nf.write(str(now))\\nf.close()\\n</code></pre>\\n<p>What should I do? For Linux, I would appreciate it if you could explain it in detail, as I only know simple commands</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to pass and retrieve multiple parameters in lambda function?', '<python><amazon-web-services><aws-lambda><serverless-framework><aws-serverless>', '<p>I\\'m currently developing a REST API using the serverless framework with python and dynamoDB. I would like to know how I can pass and retrieve parameters in my lambda function. My configuration on <code>serverless.xml</code> looks like:</p>\\n<pre><code>getNearestConvenios:\\n  handler: src/controllers/convenio_controller.get_nearest_convenios\\n  events:\\n    - http:\\n        path: convenios/nearest\\n        method: get\\n        cors: True\\n        request:\\n          template:\\n            application/json: \\'{ &quot;lat&quot; : &quot;$input.params(\\'\\'lat\\'\\')&quot;,  &quot;long&quot; : &quot;$input.params(\\'\\'long\\'\\')&quot;}\\'\\n</code></pre>\\n<p>and I\\'m trying to retrieve the parameters like this:</p>\\n<pre><code>def get_nearest_convenios(event, context):\\n  try:\\n    parameters = event[\\'pathParameters\\']\\n    convenios = service.get_nearest_convenios(parameters[\\'lat\\'], parameters[\\'long\\'])\\n    return http.ok(convenios)\\n  except Exception as ex:\\n    logger.warn(&quot;WARNING: Request id: {0}, Error: {1}, Info: {2}&quot;.format(context.aws_request_id, type(ex), ex.args))\\n    return http.bad_request(str(ex))\\n</code></pre>\\n<p>I followed the <a href=\"https://www.serverless.com/framework/docs/providers/aws/events/apigateway#custom-request-templates\" rel=\"nofollow noreferrer\">Custom Request Templates</a> provided on the official documentation, but I had no success until now. Also, in CloudWatch the following error is being showed:</p>\\n<pre class=\"lang-non prettyprint-override\"><code>    [WARNING]   2020-08-14T09:04:11.783Z    3c9222b2-4601-4460-ba7c-3cd89ba3b04b    WARNING: Request id: 3c9222b2-4601-4460-ba7c-3cd89ba3b04b, Error: &lt;class \\'TypeError\\'&gt;, Info: (&quot;\\'NoneType\\' object is not subscriptable&quot;,)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('python skipping inner loop in nested for loop', '<python><nested-loops>', '<p>I am using some python to do some variable name generation. For some reason I am only getting part of what I need.</p>\\n\\n<pre><code>import sys\\nimport csv\\n\\nparams = csv.reader(open(\\'params.csv\\'), delimiter=\\',\\', skipinitialspace=True)\\n\\nflags_r = []\\nflags_w = []\\nnumbers_r = []\\nnumbers_w = []\\nstation = [\\'AC1\\',\\'DC1\\',\\'DC1\\']\\ndrive = [\\'\\',\\'Fld\\',\\'Arm\\']\\n\\nfor i in range(3):\\n    for p in params:\\n        try:\\n            desc = p[1].split(\\' \\')\\n            desc = [part.capitalize() for part in desc]\\n            desc = \"\".join(desc)\\n        except IndexError, e:\\n            print \\'IndexError: %s\\' %(e,)\\n            continue\\n        print station[i],drive[i],p[0]\\n        flags_r.append( \\'mod%(station)s_%(drive)sP%(param)04dr_%(desc)s\\' % \\\\\\n                          { \\'station\\' : station[i], \\'drive\\' : drive[i], \\'param\\': int(p[0]), \\'desc\\':desc })\\n        flags_w.append( \\'mod%(station)s_%(drive)sP%(param)04dw_%(desc)s\\' % \\\\\\n                          { \\'station\\' : station[i], \\'drive\\' : drive[i], \\'param\\': int(p[0]), \\'desc\\':desc })\\n        numbers_r.append( \\'mod%(station)s_%(drive)sP%(param)04drn_%(desc)s\\' % \\\\\\n                          { \\'station\\' : station[i], \\'drive\\' : drive[i], \\'param\\': int(p[0]), \\'desc\\':desc })\\n        numbers_w.append( \\'mod%(station)s_%(drive)sP%(param)04dwn_%(desc)s\\' % \\\\\\n                          { \\'station\\' : station[i], \\'drive\\' : drive[i], \\'param\\': int(p[0]), \\'desc\\':desc })\\n\\n    print i\\n</code></pre>\\n\\n<p>params.csv:</p>\\n\\n<pre><code>100, Speed Reference\\n101, Speed Feedback\\n</code></pre>\\n\\n<p>for some reason it is outputting:</p>\\n\\n<blockquote>\\n  <p>AC1  100<br>\\n  AC1  101<br>\\n  0<br>\\n  1<br>\\n  2  </p>\\n</blockquote>\\n\\n<p>the reason for the try/except is to catch any blank rows or missing second fields in the csv file.</p>\\n\\n<p>It appears that the inner loop only get executed on the first pass. The only reason I can see for this to happen would be the try/except as I have done an interactive example to test it.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python: adding 1 print Kills my code?', '<python><sudoku>', '<p>I was playing with this sudoku solver, that I found.</p>\\n\\n<p>Like quoted here it works perfect, but if I uncomment that single <code>print a</code>, that I commented out (line 13), then it stops before finding a full solution...?</p>\\n\\n<pre><code>import sys\\nfrom datetime import datetime # for datetime.now()\\n\\ndef same_row(i,j): return (i/9 == j/9)\\ndef same_col(i,j): return (i-j) % 9 == 0\\ndef same_block(i,j): return (i/27 == j/27 and i%9/3 == j%9/3)\\n\\ndef r(a):\\n    i = a.find(\\'.\\')\\n    if i == -1: # All solved !\\n        print a\\n    else:\\n        #print a\\n        excluded_numbers = set()\\n        for j in range(81):\\n            if same_row(i,j) or same_col(i,j) or same_block(i,j):\\n                excluded_numbers.add(a[j])        \\n        for m in \\'123456789\\':\\n            if m not in excluded_numbers:\\n                # At this point, m is not excluded by any row, column, or block, so let\\'s place it and recurse\\n                r(a[:i]+m+a[i+1:])\\n\\nif __name__ == \\'__main__\\':\\n    if len(sys.argv) == 2:\\n        filI = open(sys.argv[1])\\n        for pusI in filI:\\n            pusI.strip()\\n            print \"pussle:\\\\n\",pusI\\n            timStart = datetime.now()\\n            r(pusI) # &lt;- Calling the recursive solver ...\\n            timEnd = datetime.now()\\n            print \"Duration (h:mm:ss.dddddd): \"+str(timEnd-timStart)\\n    else:\\n        print str(len(sys.argv)) \\n        print \\'Usage: python sudoku.py puzzle\\'\\n</code></pre>\\n\\n<p>The program needs to be called with a file. That file should hold 1 sudoku per line.</p>\\n\\n<p>For testing I used this:</p>\\n\\n<pre><code>25...1........8.6...3...4.1..48.6.9...9.4.8...1..29.4.9.53.7....6..5...7.........\\n</code></pre>\\n\\n<p><strong>QUESTION:</strong></p>\\n\\n<p>I can\\'t understand how that single \\'print a\\' manage to break the recursive loop, before it\\'s done. Can anyone give an explanation?</p>\\n\\n<p>Best regards\\nMartin@Hvidberg.net</p>\\n\\n<p>Credit: I originally found the above sudoku solver code here:\\n<a href=\"http://www.scottkirkwood.com/2006/07/shortest-sudoku-solver-in-python.html\" rel=\"nofollow noreferrer\">http://www.scottkirkwood.com/2006/07/shortest-sudoku-solver-in-python.html</a>\\nit\\'s also shown here on StackOverflow:\\n<a href=\"https://stackoverflow.com/questions/201461/shortest-sudoku-solver-in-python-how-does-it-work\">Shortest Sudoku Solver in Python - How does it work?</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Created Dataframe with dictionary', '<python><pandas><dataframe><dictionary><multi-index>', \"<p>I would like to create a dataframe with a dictionnary. I created my dictionnary, i would like convert this in Dataframe with one columns for the months and the second for value. </p>\\n\\n<p>Do you have an idea for to resolve my problem ? </p>\\n\\n<p>My dictionary : {'Jan': [1, 5], 'Apr': [2, 6], 'Mar': [3, 7], 'June': [4, 8]}</p>\\n\\n<pre><code>            import pandas as pd\\n        from collections import defaultdict\\n\\n\\n        # d = {('20170330', 'A'): {'earn': '16.02'},('20170331', 'A'): {'earn': '25.68'},('20170330', 'AA'): {'earn': '321321'}}\\n\\n        months = ['Jan','Apr','Mar','June','Jan','Apr','Mar','June']\\n        days = [1,2,3,4,5,6,7,8]\\n\\n        zipped = zip(months, days)\\n\\n        d = {}\\n        for items in zipped:\\n            res = d.setdefault(items[0], [])\\n            res.append(items[1])\\n\\n        print(d)\\n</code></pre>\\n\\n<p>Thnks you !</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to ignore Pandas reorganizing string indexes?', '<python><pandas>', '<p>I am creating a dataframe from a nested dictionary which looks like this:</p>\\n\\n<pre class=\"lang-py prettyprint-override\"><code>dict = {\\n  \\'Loop1\\': {\\n    \\'pv\\': 1, \\'sp\\': 2, \\'op\\': 3, \\'string_mode\\': 4, \\'auto_mode\\': 5, \\'cascade_mode\\': \\'NaN\\', \\'operational\\': 6, \\'operational_min\\': 1.0, \\'operational_max\\': 10.0\\n  },\\n  \\'Loop2\\': {\\n    \\'pv\\': 7, \\'sp\\': 8, \\'op\\': 9, \\'string_mode\\': 10, \\'auto_mode\\': 11, \\'cascade_mode\\': \\'NaN\\', \\'operational\\': 12, \\'operational_min\\': 1.0, \\'operational_max\\': 10.0\\n  }\\n}\\n</code></pre>\\n\\n<p>when I use <code>df = pd.DataFrame(dict)</code> I get this output:</p>\\n\\n<pre><code>                      Loop1    Loop2  \\n    auto_mode          5        11           \\n    cascade_mode       NaN     NaN          \\n    op                 3        9      \\n    operational        6        12         \\n    operational_max   10.0     10.0            \\n    operational_min   1.0      1.0      \\n    pv                 1       7   \\n    sp                 2       8        \\n    string_mode        4       10    \\n</code></pre>\\n\\n<p>As you can see the indexes for the dataframe are automatically reorganizing themselves alphabetically.</p>\\n\\n<p>Is there any way to keep Pandas from automatically reorganizing the indexes so that it preserves the order in the dictionary?</p>\\n\\n<p>NOTE:\\nI have tried using pandas.DataFrame.sort_index(dict, inplace=True) and got the following error:</p>\\n\\n<pre><code>AttributeError: \\'dict\\' object has no attribute \\'_get_axis_number\\'\\n</code></pre>\\n\\n<p>Any Help would be greatly appreciated!</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('opencv python : install in rapberry and failed to find a specific file', '<python><opencv>', \"<p>i tried to install opencv-python in my raspberry. i tried in many ways, including :</p>\\n<pre><code>pip install opencv-python\\n</code></pre>\\n<p>but the process take so much time. (almost 2 hours untill now)</p>\\n<p>so i tried another way, which is installing from it's tar.gz file. i downloaded the tar.gz file, unarchive that, and run this command :\\npython setup.py install</p>\\n<p>with the result is error after 4 hours waiting. the error messages is :</p>\\n<pre><code>Traceback (most recent call last):\\n\\n\\nFile &quot;setup.py&quot;, line 449, in &lt;module&gt;\\n    main()\\n  File &quot;setup.py&quot;, line 249, in main\\n    cmake_source_dir=cmake_source_dir,\\n  File &quot;/home/pi/lucky/test_krsbi/lib/python3.7/site-packages/skbuild/setuptools_wrap.py&quot;, line 625, in setup\\n    cmake_source_dir, skbuild_kw['cmake_install_dir'])\\n  File &quot;setup.py&quot;, line 362, in _classify_installed_files_override\\n    raise Exception(&quot;Not found: '%s'&quot; % relpath_re)\\nException: Not found: 'python/cv2[^/]*\\\\.cpython\\\\-37m\\\\-arm\\\\-linux\\\\-gnueabihf\\\\.so'\\n</code></pre>\\n<p>can you guys help me? i tried many things before this problem happen. but now, i really stuck, no thing in the internet can help me</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Failed to download images using map()', '<python><image><web-scraping><python-requests>', \"<pre><code>import requests\\n\\ndef download_jpg(img_name,img_url):\\n   img_data = requests.get(img_url).content\\n   with open(img_name,'wb') as handler:\\n        handler.write(img_data)\\n        handler.close()\\n        \\nurl = &quot;https://keithgalli.github.io/web-scraping/&quot;  \\nimages=webpage.select(&quot;div.row div.column img&quot;)\\n#print(images)\\nimg_name=[image[&quot;alt&quot;]+&quot;jpg&quot; for image in images]\\nimg_url=[url+image[&quot;src&quot;] for image in images]\\n\\nprint(img_name)\\nprint(img_url)\\n\\nfor x,y in zip(img_name,img_url):\\n    download_jpg(x,y)\\n        \\n#map(download_jpg,img_name,img_url)\\n</code></pre>\\n<p>I can use the loop with the defined function &quot;download_jpg&quot; to download images. However, when i want to use map() [last line of the code] to simplify it, it failed. Does anyone know why? Thank you.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Crawl Images, Whole Web Pages and cache them', '<python>', '<p>I am starting a project and wonder the relationship between the characters in images and the whole web page where the images reside.</p>\\n\\n<p>I want to crawl some images and their web pages. I need to save the crawl result in local disk for further analysis. I wonder if there is any open source for this issue? </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Difficulty with installing gasp in windows 7 64 bit', '<python><python-2.7><gasp>', '<p>I am having difficulty installing gasp in windows 7. Although I have the read instructions <a href=\"http://dev.laptop.org/pub/gasp/downloads/\" rel=\"nofollow\">here</a> but they were not helpful. I am currently using python 2.7.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Problem login in to a website with python requests', '<python><python-requests>', '<p>I\\'m trying to login to a website using pythons requests module</p>\\n\\n<p>I\\'ve looked into the website using chrome. That\\'s what the post looks like</p>\\n\\n<pre><code>username: aaa\\npassword: aaa\\ncmd[doStandardAuthentication]: Anmelden\\n</code></pre>\\n\\n<p>this is my code:</p>\\n\\n<pre><code>payload = {\\n    \\'username\\': \"noah.kamara\",\\n    \\'password\\': \"nkitBest1602uNi\",\\n    \\'cmd[doStandardAuthentication]:\\': \\'Anmelden\\'\\n}\\nwith requests.Session() as session:\\n    login_page = session.get(login_url)\\n    post = session.post(login_url, data=payload)\\n    print(post.status_code)\\n    r = session.get(request_url)\\n    print(r.status_code)\\n    print(r.content) \\n\\n</code></pre>\\n\\n<p>I always get back to the login page and don\\'t know why</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Comparing values between columns in Pandas Dataframe generates \"Cannot index with multidimensional key\" error', '<python><pandas><dataframe>', \"<p>I have a dataframe:</p>\\n<pre><code>    Date                Time      A\\n0   2019-06-20 07:00:00 70000   -322\\n1   2019-06-20 07:05:00 70500   -439\\n2   2019-06-20 07:10:00 71000   -528\\n3   2019-06-20 07:15:00 71500   -606\\n4   2019-06-20 07:20:00 72000   -642\\n5   2019-06-20 07:25:00 72500   -663\\n6   2019-06-20 07:30:00 73000   -620\\n7   2019-06-20 07:35:00 73500   -561\\n8   2019-06-20 07:40:00 74000   -592\\n9   2019-06-20 07:45:00 74500   -614\\n10  2019-06-20 07:50:00 75000   -630\\n11  2019-06-20 07:55:00 75500   -719\\n12  2019-06-20 08:00:00 80000   -613\\n13  2019-06-20 08:05:00 80500   -127\\n14  2019-06-20 08:10:00 81000   -235\\n</code></pre>\\n<p>and I want to compare values from column 'A' based on two time values.<br>\\nLet's say I'd like to know if A at time 7:20 is smaller than at 7:40<br>\\nI tried it this way, but i get an error:</p>\\n<pre><code>df.A.loc[df.loc[df['Time'] == 72000]] &lt; df.A.loc[df.loc[df['Time'] == 74000]]\\n\\nerror: Cannot index with multidimensional key\\n</code></pre>\\n<p>How do I get rid of this error?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to save data in DataFrame from combination of List and Dict as show below', '<python><dataframe>', \"<p>Hello There I wants to save data in data frame</p>\\n<p>I have following type of data</p>\\n<pre><code>data = [\\n{'time':1.00,'a':11, 'b':12, 'c':13, 'd':14}, \\n{'time':2.00,'a':21, 'b':22, 'c':23, 'd':24},\\n{'time':3.00,'a':31, 'b':32, 'c':33, 'd':34},\\n{'time':4.00,'a':41, 'b':42, 'c':43, 'd':44}\\n]\\n</code></pre>\\n<p>I am little confused with above type of data structure.</p>\\n<p>Output I am expecting in DataFrame:</p>\\n<pre><code>    Time    a    b    c    d\\n0   1.00    11   12   13   14\\n1   2.00    21   22   23   24\\n2   3.00    31   32   33   34\\n3   4.00    41   42   43   44\\n</code></pre>\\n<p>I am looking for solution which give result in least time</p>\\n<p>I have tried this code:</p>\\n<pre><code>for d in data:\\n    print d\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Matplotlib scatter plot with different text at each point', '<python><pandas><matplotlib><scatter-plot>', '<p>Let\\'s Say I have 3 series</p>\\n<pre class=\"lang-py prettyprint-override\"><code>&gt;&gt;&gt; df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Cost\\']\\n0     2300.00\\n1     3200.00\\n4     1350.00\\n7     1352.00\\n8     4056.00\\n9       79.00\\n10    1595.00\\nName: Cost, dtype: float64\\n&gt;&gt;&gt;df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Rank\\']\\n0      1\\n1      1\\n4      1\\n7      2\\n8      2\\n9      2\\n10     2\\nName: Rank, dtype: int64\\n&gt;&gt;&gt;df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Univ/Org\\']\\n0     Massachusetts Institute of Technology \\n1     Massachusetts Institute of Technology \\n4                                    EDX/MIT\\n7                        Stanford University\\n8                        Stanford University\\n9               Coursera/Stanford University\\n10                       Stanford University\\nName: Univ/Org, dtype: object\\n</code></pre>\\n<p>Now I want to draw a scatter plot with Cost at the y-axis, Rank at the X-axis, and Name of Univ/Org at each data point.</p>\\n<p>Now What I am able to do yet after referring to <a href=\"https://stackoverflow.com/questions/14432557/matplotlib-scatter-plot-with-different-text-at-each-data-point\">this</a> question is</p>\\n<pre class=\"lang-py prettyprint-override\"><code>plt.scatter(df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Rank\\'], df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Cost\\'],marker=\\'2\\', edgecolors=\\'black\\')\\nfor i, txt in enumerate(df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Univ/Org\\']):\\n    plt.annotate(txt, (df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Rank\\'][i], df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Cost\\'][i]))\\n</code></pre>\\n<p>It is naming 2 data points and then giving an error.</p>\\n<p>Plot is :\\n<a href=\"https://i.stack.imgur.com/QYxbR.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/QYxbR.png\" alt=\"enter image description here\" /></a></p>\\n<p>And Error is:</p>\\n<pre><code>---------------------------------------------------------------------------\\nKeyError                                  Traceback (most recent call last)\\n&lt;ipython-input-111-0d31107a166a&gt; in &lt;module&gt;\\n      1 plt.scatter(df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Rank\\'], df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Cost\\'],marker=\\'2\\', edgecolors=\\'black\\')\\n      2 for i, txt in enumerate(df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Univ/Org\\']):\\n----&gt; 3     plt.annotate(txt, (df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Rank\\'][i], df[df[\\'Type\\']==&quot;Machine Learning&quot;][\\'Cost\\'][i]))\\n\\n~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __getitem__(self, key)\\n    869         key = com.apply_if_callable(key, self)\\n    870         try:\\n--&gt; 871             result = self.index.get_value(self, key)\\n    872 \\n    873             if not is_scalar(result):\\n\\n~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_value(self, series, key)\\n   4403         k = self._convert_scalar_indexer(k, kind=&quot;getitem&quot;)\\n   4404         try:\\n-&gt; 4405             return self._engine.get_value(s, k, tz=getattr(series.dtype, &quot;tz&quot;, None))\\n   4406         except KeyError as e1:\\n   4407             if len(self) &gt; 0 and (self.holds_integer() or self.is_boolean()):\\n\\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\\n\\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_value()\\n\\npandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()\\n\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item()\\n\\npandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item()\\n\\nKeyError: 2\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Retrieve index of 'i' in for loop, Python, Django-QuerySet\", '<python><for-loop><indexing><django-queryset>', \"<p>I've got two model objects inside of a query set</p>\\n\\n<pre><code>x = [&lt;model.object&gt;]\\ny = [&lt;model.object&gt;]\\n</code></pre>\\n\\n<p>I need to process each object through a script for each of the sets</p>\\n\\n<pre><code>for i in [x,y]:\\n    i.attribute_1\\n    i.attribute_2\\n</code></pre>\\n\\n<p>This wont work though because in this example 'i' is going to represent a query set not an object</p>\\n\\n<pre><code>for i in [x,y]:\\n    i[0].attribute_1\\n    i[0].attribute_2\\n</code></pre>\\n\\n<p>Seems cumbersome</p>\\n\\n<pre><code>for i in [x[0],y[0]]:\\n    i.attribute_1\\n    i.attribute_2\\n</code></pre>\\n\\n<p>Same problem</p>\\n\\n<pre><code>for i[0] in [x,y]:\\n    i.attribute_1\\n    i.attribute_2\\n</code></pre>\\n\\n<p>Doesnt work.</p>\\n\\n<p>Is there a better soloution than</p>\\n\\n<pre><code>for i in [x,y]:\\n    i = i[0]\\n    i.attribute_1\\n    i.attribute_2\\n</code></pre>\\n\\n<p>?\\nOr better yet</p>\\n\\n<pre><code>z = 0\\nfor i in [x,y]:\\n    i = i[z]\\n    i.attribute_1\\n    i.attribute_2\\n    z += 1\\n</code></pre>\\n\\n<p>?\\nThanks :)</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Eval class/def/logic with one key in Python Interactive (Emacs)', '<python><emacs>', '<p>Is there any implementation in which when you are in the middle of some function/class/, and evaluate the entire (logical!) block of code?</p>\\n\\n<p>Basically I want to be able to evaluate:</p>\\n\\n<pre><code>import re\\nimport os\\n</code></pre>\\n\\n<p>and</p>\\n\\n<pre><code>if bla == \\'bla\\':\\n   print \\'bla\\'\\nelse:\\n   print \\'bla\\'\\n</code></pre>\\n\\n<p>also</p>\\n\\n<pre><code>def bla():\\n    return 1\\n</code></pre>\\n\\n<p>and finally</p>\\n\\n<pre><code>class Bla():\\n    def __init__(self):\\n        self.x = 1 \\n\\n    def bla(self):\\n        self.bla = \\'bla\\'\\n</code></pre>\\n\\n<p>Earlier I tried to do this with \"mark-paragraph\". This worked great in many cases (since I especially blocked code together without extra newlines in between). But I\\'m now looking for a better solution. I started with a function that tries to find the starting point of a code block.</p>\\n\\n<p>I\\'m trying to run this function from any point:</p>\\n\\n<pre><code>(defun python-test-eval-any ()\\n  (interactive)\\n  (when (not (and transient-mark-mode mark-active))\\n    (move-end-of-line 1)\\n    (let ((start (search-backward-regexp \"^[a-zA-Z0-9#]\" 0 t))\\n          (pre (search-backward-regexp \"^$\" 0 t)) \\n          (middle (search-forward-regexp \"^$\" 10000 t 1))\\n          (second (search-forward-regexp \"^[a-zA-Z0-9#]\" 10000 t 2))) \\n      (previous-line)\\n      (right-char)\\n      ;; this now prints what we matched, can be used to check\\n      (message (buffer-substring pre (- second 1)))))\\n  )\\n</code></pre>\\n\\n<p>But it still fails. I\\'m still sure it is possible. Does anyone have an idea how to properly evaluate any interactive python?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('find the change from uppercase to lowercase in a sentence and separate the text (print)', '<python><python-3.x><python-2.7>', \"<p>I have a problem, i need to separate a text between uppercase to lowercase sentences and print them.</p>\\n\\n<p>Sample:<br>\\nWE, THE PEOPLE OF INDIA, having solemnly resolved to constitute India into a SOVEREIGN, SOCIALIST, SECULAR, DEMOCRATIC REPUBLIC and to secure to all its citizens</p>\\n\\n<p>Result:<br>\\nWE, THE PEOPLE OF INDIA,<br>\\nhaving solemnly resolved to constitute India into a <br>\\nSOVEREIGN, SOCIALIST, SECULAR, DEMOCRATIC REPUBLIC <br>\\nand to secure to all its citizens </p>\\n\\n<p>I have this:</p>\\n\\n<pre><code>i=0\\ns='WE, THE PEOPLE OF INDIA, having solemnly resolved, to constitute India into a SOVEREIGN, SOCIALIST, SECULAR, DEMOCRATIC REPUBLIC and to secure to all its citizens'\\nt= ''\\nwhile i &lt; len(s):\\n    if not(s[i].isalpha())==True:\\n       i += 1\\n       continue\\n    if s[i].isupper()==s[i+1].islower():\\n        i += 1\\n        t = t+','\\n        print(s[i])\\n        break\\n    t=t+s[i]\\n    #print(t)\\n    i += 1\\nprint(t)\\nprint(i)\\n</code></pre>\\n\\n<p>but, this is my result:</p>\\n\\n<p><strong>WETHEPEOPLEOFINDIAhavin,</strong></p>\\n\\n<p>I don't understand why it doesn't stop at the 'h'.</p>\\n\\n<p>Please, help me!.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('add input user values from while loop', '<python><while-loop><user-input>', '<p>Im a complete beginner and doing an assignment. The different weights for the parcel have different prices, the user has to be able to input the amount of parcels and their individual weight and the program has to tell the total price of all the parcels. This is what ive got so far,(i dont know what but something seems off) i cant seem to figure out how to make the total price the sum of all the different prices of the parcels (p.s not allowed to use for-loops). Appreciate any help or advice and thanks in advance.</p>\\n<pre><code>parcel = int(input(&quot;How many parcels do you want to send?&quot;))\\ni = 1\\nwhile i &lt; parcel+1:\\n  print(&quot;State the weight for parcel&quot;,i,&quot;:&quot;)\\n  weight = int(input())\\n  if (i == parcel):\\n    break\\n  i += 1\\nif weight &lt; 2:\\n    price = 30\\nelif weight == 2 or weight &lt; 6:\\n    price = 28\\nelif weight == 6 or weight &lt; 12:\\n    price = 25\\nelif weight &gt;= 12:\\n    price = 23\\ntot_price = \\nprint(&quot;The total price will be:&quot;,tot_price)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Directing non class callbacks into class methods', '<python>', \"<p>I'm trying to wrap an existing MQTT client with a helper class.</p>\\n\\n<p>The functions defined by <code>paho.mqtt.client</code> defined as follows:</p>\\n\\n<pre><code>def on_connect(client, userdata, flags, rc):\\ndef on_message( client, userdata, msg):\\n</code></pre>\\n\\n<p>The wrapper class looks as follows:</p>\\n\\n<pre><code>import paho.mqtt.client as mqtt\\n\\nHOST = ''\\nPORT = 1883\\n\\nclass MqttHandler:\\n    def __init__(self):\\n        self.client = mqtt.Client()\\n        self.client.connect(HOST, PORT)\\n        # How can I direct those callbacks into the class functions?\\n        self.client.on_connect = on_connect \\n        self.client.on_message = on_message \\n        self.client.loop_forever()\\n\\n    def terminate(self):\\n        self.client.disconnect()\\n\\n    def on_connect(self, client, userdata, flags, rc):\\n        pass\\n\\n    def on_message(self, client, userdata, msg):\\n        pass\\n</code></pre>\\n\\n<p>The <code>paho.mqtt.client</code> <code>on_connect</code> property is expecting a function with a signature            of a non class function (without the leading <code>self</code> variable), how can I redirect those callbacks into my class functions?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to remove all emoji (unicode) characters from a string python', '<python><regex><string><python-regex>', '<p>I have the following string:</p>\\n\\n<pre><code>tweet = \"Get $10 worth of AMAL!!\\\\\\\\nThis campaign will be final AirDrop before official release!!\\\\\\\\nhttps://form.run/@airdrop-e\\\\xa0\\\\\\\\n\\\\\\\\nRT please!\\\\\\\\n\\\\\\\\n#amanpuri #AMAL\\\\\\\\n#BTC #XRP #ETH \\\\\\\\n#cryptocurrency  \\\\\\\\n#China #bitcoin \\\\\\\\n#\\\\\\\\xe3\\\\\\\\x82\\\\\\\\xa2\\\\\\\\xe3\\\\\\\\x83\\\\\\\\x9e\\\\\\\\xe3\\\\\\\\x83\\\\\\\\xb3\\\\\\\\xe3\\\\\\\\x83\\\\\\\\x97\\\\\\\\xe3\\\\\\\\x83\\\\\\\\xaa\"\\n</code></pre>\\n\\n<p>And I need to cleen it up, but I stuck with getting rid of the symbols at the end of the string aka <code>\\\\\\\\n#\\\\\\\\xe3\\\\\\\\x82\\\\\\\\xa2\\\\\\\\xe3</code>  which are most likely unicode symbols, emoji and new line symbols <code>\\\\\\\\n</code> \\nHere is what I do:</p>\\n\\n<pre><code>pat1 = r\\'@[A-Za-z0-9]+\\' # this is to remove any text with @ (links)\\npat2 = r\\'https?://[A-Za-z0-9./]+\\'  # this is to remove the urls\\npat3 = r\\'[^a-zA-Z0-9$]\\' # to remove every other character except a-z &amp; 0-9 &amp; $\\ncombined_pat2 = r\\'|\\'.join((r\\'|\\'.join((pat1, pat2)),pat3)) # combine pat1, pat2 and pat3 to pass it in the cleaning steps\\n</code></pre>\\n\\n<p>And I obtain the following output:</p>\\n\\n<pre><code>get $10 worth of amal   nthis campaign will be final airdrop before official release   n   e  n nrt please  n n amanpuri  amal n btc  xrp  eth  n cryptocurrency   n china  bitcoin  n  xe3 x82 xa2 xe3 x83 x9e xe3 x83 xb3 xe3 x83 x97 xe3 x83 xaa\\n</code></pre>\\n\\n<p>So I still have all these <strong>n\\'s</strong> and <strong>xe3\\'s</strong> Can anybody suggest a python regular expression for this purpose? Thx in advance.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python - Joining multiple 2D arrays into one 3D array', '<python><arrays>', \"<p>So I have multiple files that can be accessed and be treated as 2D arrays.\\nWhat I would like to do is take all those 2D arrays and put them in a single 3D array.\\nFor example, if I have 10 files with the shapes (100,100), when I combine them, I should be left with a 3D array of shape (10,100,100). The following attempt I have is the following:</p>\\n<pre><code>filenames = glob.glob('source')\\npreset = np.empty([100,100], dtype = 'int16')\\nfor file in filenames:\\n    data = fits.open(file)[0].data\\n    np.vstack([preset,data]).reshape((10,100,100))\\n</code></pre>\\n<p>But what I'm getting is the following error:</p>\\n<pre><code>ValueError: cannot reshape array of size 20000 into shape (10,100,100)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to run my function only when button is pressed and held with pyqt5 in python', '<python><pyqt5>', \"<p>How can I make a Button which executes the code under it only when the Button is pressed and held (let's say for one second) and stops when it is released?</p>\\n<pre><code>from PyQt5.QtWidgets import QApplication, QWidget, QPushButton\\nfrom PyQt5.QtGui import QIcon\\nfrom PyQt5.QtCore import pyqtSlot\\n\\n\\nclass App(QWidget):\\n\\n    def __init__(self):\\n        super().__init__()\\n        self.title = 'PyQt5 button '\\n        self.left = 500\\n        self.top = 200\\n        self.width = 320\\n        self.height = 200\\n        self.initUI()\\n\\n    def initUI(self):\\n        self.setWindowTitle(self.title)\\n        self.setGeometry(self.left, self.top, self.width, self.height)\\n\\n        button = QPushButton('PyQt5 button', self)\\n        button.setToolTip('This is an example button')\\n        button.move(100, 70)\\n        button.clicked.connect(self.on_click)\\n\\n        self.show()\\n\\n    @pyqtSlot()\\n    def on_click(self):\\n        print('PyQt5 button click')\\n\\n\\nif __name__ == '__main__':\\n    app = QApplication(sys.argv)\\n    ex = App()\\n    sys.exit(app.exec_()) ```\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('python removing duplicates', '<python><list><duplicates><tuples>', \"<p>In an array I have the following tuples: \\n<pre><code>  ('0000233/02', 50.0, None, None, None, None, 'Yes') \\n  ('0000233/02', 200.0, None, None, None, None, 'Yes') </pre></code></p>\\n\\n<p>if im iterating through the list, how could I eliminate duplicates based solely on the first element?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('reassigning xarray data variable to xarray coordinate', '<python><dataframe><netcdf><python-xarray>', '<p>I have a pandas dataframe of spatial data that I would like to convert to a netCDF. I have found my way to xarray and converted my dataframe into an xarray dataset: </p>\\n\\n<pre><code># create xray Dataset from Pandas DataFrame\\nxr = xarray.Dataset.from_dataframe(df)\\n</code></pre>\\n\\n<p>Now, I want to set the <code>lon</code> and <code>lat</code> variables as the coordinates of my xarray dataset.\\nI have tried <code>xarray.Dataset.assign_coords</code> but cant seem to get it to work?</p>\\n\\n<p>My xarray dataset looks like:</p>\\n\\n<pre><code>&lt;xarray.Dataset&gt;\\nDimensions:  (index: 58705)\\nCoordinates:\\n  * index    (index) int64 0 1 2 3 4 5 6 ... 58699 58700 58701 58702 58703 58704\\nData variables:\\n    x_km     (index) float64 5.274e+03 5.273e+03 ... 2.873e+03 2.873e+03\\n    y_km     (index) float64 0.0 46.02 92.03 138.0 ... -75.23 -50.15 -25.07 -0.0\\n    z_km     (index) float64 3.575e+03 3.575e+03 ... 1.947e+03 1.947e+03\\n    dv_v     (index) float64 0.2407 0.1774 0.1786 ... -0.2163 -0.2035 -0.3197\\n    rxy      (index) float64 5.274e+03 5.273e+03 ... 2.873e+03 2.873e+03\\n    lon      (index) float64 0.0 0.5 1.0 1.5 2.0 ... -2.0 -1.5 -1.0 -0.5 -0.0\\n    lat      (index) float64 34.13 34.13 34.13 34.13 ... 34.11 34.12 34.12 34.13\\n    rxyz     (index) float64 6.371e+03 6.371e+03 ... 3.471e+03 3.471e+03\\n    depth    (index) float64 0.04665 0.04747 0.04766 ... 2.9e+03 2.9e+03 2.9e+03\\nAttributes:\\n    Conventions:  CF-1.6\\n    title:        Data\\n    summary:      Data generated\\n</code></pre>\\n\\n<p>Any help is appreciated :D</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Another way to get to the element instead of xpath', '<python><selenium><xpath>', '<p><a href=\"https://i.stack.imgur.com/ZAdEv.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/ZAdEv.png\" alt=\"enter image description here\"></a> </p>\\n\\n<p>I want to extract data [\"Over/Under +0.5\", \"1.04\", \"11.46\", \"95.3%\"] by using python(selenium) for more than 10 pages but I have a problem with getting the exact value with Xpath inside the table the number inside div[] change in each web page\\nis there any way to get to the same value inside the table?\\nfor example :\\npage1</p>\\n\\n<p>\\'//*[@id=\"odds-data-table\"]/div[12]/div/strong\\'</p>\\n\\n<p>page2</p>\\n\\n<p>\\'//*[@id=\"odds-data-table\"]/div[11]/div/strong\\'</p>\\n\\n<p><a href=\"https://www.oddsportal.com/soccer/england/premier-league-2017-2018/newcastle-utd-arsenal-vLKS6e2j/?r=1#over-under;2\" rel=\"nofollow noreferrer\">https://www.oddsportal.com/soccer/england/premier-league-2017-2018/newcastle-utd-arsenal-vLKS6e2j/?r=1#over-under;2</a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('could not serialize access due to concurrent update while creating pos picking from a job', '<python><postgresql><odoo><odoo-12>', \"<p>Impacted versions:\\n12.0</p>\\n<p>Steps to reproduce:\\nI have made a customization to postpone the creation of pos order picking\\nand delegate the task to a job\\nsome time i get the error below</p>\\n<p>Current behavior:\\n2020-06-18 17:49:24,588 1370 ERROR cafe9.rabeh.io odoo.addons.base.models.ir_cron: Call from cron POS Orders: Process Pending Orders for server action #610 failed in Job #24\\nTraceback (most recent call last):</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/addons/base/models/ir_cron.py&quot;, line 102, in _callback\\nself.env['ir.actions.server'].browse(server_action_id).run()</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/addons/base/models/ir_actions.py&quot;, line 569, in run\\nres = func(action, eval_context=eval_context)</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/addons/base/models/ir_actions.py&quot;, line 445, in run_action_code_multi\\nsafe_eval(action.sudo().code.strip(), eval_context, mode=&quot;exec&quot;, nocopy=True)  # nocopy\\nallows to return 'action'</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/tools/safe_eval.py&quot;, line 350, in safe_eval\\nreturn unsafe_eval(c, globals_dict, locals_dict)</p>\\n<p>File &quot;/opt/rabeh-12/rabeh_addons/pos_pending_session/models/pos_order.py&quot;, line 68, in pending_picking_creation\\npo_order.create_picking()</p>\\n<p>File &quot;/opt/rabeh-12/rabeh_addons/pos_pending_session/models/pos_order.py&quot;, line 36, in\\ncreate_picking\\nres = super(PosOrder, orders).create_picking()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/point_of_sale/models/pos_order.py&quot;, line 841, in create_picking\\norder._force_picking_done(order_picking)</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/point_of_sale/models/pos_order.py&quot;, line 856, in _force_picking_done\\npicking.action_done()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/stock/models/stock_picking.py&quot;, line 631, in action_done\\ntodo_moves._action_done()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/purchase_stock/models/stock.py&quot;, line 96, in _action_done\\nres = super(StockMove, self)._action_done()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/stock_account/models/stock.py&quot;, line 389, in _action_done\\nres = super(StockMove, self)._action_done()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/stock/models/stock_move.py&quot;, line 1137, in _action_done\\nmoves_todo.mapped('move_line_ids')._action_done()</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/stock/models/stock_move_line.py&quot;, line 445, in _action_done\\nQuant._update_available_quantity(ml.product_id, ml.location_dest_id, quantity, lot_id=ml.lot_id, package_id=ml.result_package_id, owner_id=ml.owner_id, in_date=in_date)</p>\\n<p>File &quot;/opt/rabeh/odoo/addons/stock/models/stock_quant.py&quot;, line 216, in _update_available_quantity\\nself._cr.execute(&quot;SELECT 1 FROM stock_quant WHERE id = %s FOR UPDATE NOWAIT&quot;, [quant.id], log_exceptions=False)</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/sql_db.py&quot;, line 148, in wrapper\\nreturn f(self, *args, **kwargs)</p>\\n<p>File &quot;/opt/rabeh/odoo/odoo/sql_db.py&quot;, line 225, in execute\\nres = self._obj.execute(query, params)</p>\\n<p>psycopg2.errors.SerializationFailure: could not serialize access due to concurrent update</p>\\n<p>Expected behavior:\\ni think this line should generate could not obtain lock\\ni was just wondering when it could generate &quot;could not serialize access due to concurrent update&quot;</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('sort df based on multiple conditions', '<python><pandas>', \"<p>I have a df as shown below</p>\\n<p>df:</p>\\n<pre><code>product_x  year     total_price      total_sale\\nA          2016     50               200           \\nB          2016     200              100           \\nA          2017     250              250           \\nB          2017     1000             300           \\nA          2018     100              50           \\nB          2018     900              600\\nK          2016     20               300\\nD          2016     100              450\\n</code></pre>\\n<p>I would like to sort df as shown below.</p>\\n<pre><code>product_x  year_c   total_price      total_sale\\nD          2016     100              450\\nA          2016     50               200           \\nB          2016     200              100\\nK          2016     20               300\\nB          2017     1000             300 \\nA          2017     250              250\\nB          2018     900              600\\nA          2018     100              50\\n</code></pre>\\n<p>first preference is increasing order of year_c and then decreasing order of toatal_sale.</p>\\n<p>I tried below code.</p>\\n<pre><code>df = df.sort_values(['year_c', \\n                    'total_sale'], ascending=False)\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to configure isort to import from current module after other firstparty modules?', '<python><isort>', \"<p>I have a django project with several (firstparty) modules, possibly with submodules</p>\\n<pre><code>module1\\nmodule1/controller\\nmodule1/controller/__init__.py\\nmodule1/controller/foo.py\\nmodule1/models.py\\nmodule1/views.py\\n\\nmodule2\\nmodule2/documents.py\\nmodule2/models.py\\n</code></pre>\\n<p>The style convention that I would like to enforce is that, in module2, all imports from module1 are before imports from module2, and vice-versa.\\nSo for example, here's a valid imports section for <code>module1/views.py</code>:</p>\\n<pre><code>import module2.models\\nfrom module2 import documents\\n\\nimport module1.controller\\nfrom . import models\\n</code></pre>\\n<p>But the outpout from isort is rather this:</p>\\n<pre><code>import module1.controller\\nimport module2.models\\nfrom module2 import documents\\n\\nfrom . import models\\n</code></pre>\\n<p>Note: my point is not about &quot;from ... import ...&quot; vs &quot;import ...&quot;, but rather than <code>import module1.controller</code> is in another section than <code>from . import models</code>, which is not what I want.</p>\\n<p>How can I configure isort to match the style I want to enforce ?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Multithreading programming with python', '<python><multithreading>', '<p>I am doing a little bit of python multithreading programming and found the result of my code vary strange, not parallel at all (8 cores, 8 threads, 13% cpu utilization). Then I have found a python GIL term and these slides (<a href=\"http://www.dabeaz.com/python/GIL.pdf\" rel=\"nofollow\">http://www.dabeaz.com/python/GIL.pdf</a>). Is it real that python is not parallelizable?\\nWill the multiprocessing module help to utilize computational resources or there is another performance issue with that?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to use Python get same date hour or minute from datetime list?', '<python><algorithm><datetime>', \"<p>I have a list of times and I need to get all the elements in the list that have the same hour or minute or second and form them into new lists.</p>\\n\\n<p>example:\\nlist</p>\\n\\n<pre><code>['10:20:01', '10:20:02', '10:21:00', '10:21:01', '10:22:00', '10:22:01']\\n</code></pre>\\n\\n<p>out</p>\\n\\n<pre><code>['10:20:01', '10:20:02']\\n['10:21:00', '10:21:01']\\n['10:22:00', '10:22:01']\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How do you add Gaussian Noise to a tif image file in python?', '<python><tensorflow><scikit-image><cv2>', \"<p>I am trying to add Gaussian noise to a set of tif files. I have used both scikit-image and cv2.</p>\\n\\n<p>Scikit-Image: <code>noise_img = random_noise(np_img, mode='gaussian', seed=None, clip=True)</code></p>\\n\\n<p>CV2:</p>\\n\\n<pre><code>gauss = gauss.reshape(np_img.shape[0], np_img.shape[1], np_img.shape[2]).astype('uint8')\\nnoise_img = cv2.add(np_img, gauss)\\n</code></pre>\\n\\n<p>I used both methods on traditional jpeg and png images and they work. However, they don't seem to work on tif files. Any help would be appreciated!</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('PyMongo + Flask: How to render content with jinja?', '<python><flask><jinja2><pymongo>', '<p>I use Flask in an application that displays some data from a Mongo database. Scrapy spider writes data. My problem is that the application displays text without a separator. How to keep indents and remove quotes?</p>\\n\\n<p>For example, a database entry has the following text:\\n<a href=\"https://i.stack.imgur.com/5GQwp.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5GQwp.png\" alt=\"enter image description here\"></a></p>\\n\\n<p>spider:</p>\\n\\n<pre><code>Reviews = response.css(\\'.listing-review-text::text, .blurred.read-more::text, .response-question::text,\\' +\\n                           \\'.response-answer::text, .listing-review-name::text, .review_name::text\\').getall() \\n</code></pre>\\n\\n<p>jinja:</p>\\n\\n<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\\r\\n<div class=\"snippet-code\">\\r\\n<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>{% if card.Reviews %}\\r\\n   &lt;h3 class=\"font-weight-normal\"&gt;Reviews&lt;/h3&gt;\\r\\n   &lt;p&gt;{{card.Reviews}}&lt;/p&gt;\\r\\n{% endif %}</code></pre>\\r\\n</div>\\r\\n</div>\\r\\n</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Vim keybindings in Jupyter/Colab', '<python><google-colaboratory>', '<p>I\\'ve started using the <code>vim</code> shortcuts in Google Colab. It\\'s great when it works, but it seems to be hit-or-miss with the features that are supported. When I press <code>/</code> I get a search-like command prompt:</p>\\n<p><a href=\"https://i.stack.imgur.com/eb4CF.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/eb4CF.png\" alt=\"enter image description here\" /></a></p>\\n<p>And doing the <code>:</code> command gives me what seems like the <code>vim</code> command-line mode:</p>\\n<p><a href=\"https://i.stack.imgur.com/OaDZ1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OaDZ1.png\" alt=\"enter image description here\" /></a></p>\\n<p>However, other than the <code>s</code>(ubstitute) command, it doesn\\'t seem like anything else works:</p>\\n<p><a href=\"https://i.stack.imgur.com/CkLWW.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/CkLWW.png\" alt=\"enter image description here\" /></a></p>\\n<p>Is there any documentation on what\\'s supported here? Where could I find it? The current setting I have enabled is as follows:</p>\\n<p><a href=\"https://i.stack.imgur.com/a5AdB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/a5AdB.png\" alt=\"enter image description here\" /></a></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Process data frame in parallel chunks', '<python><pandas><dataframe>', \"<p>I have a dataframe (df) with 2 million rows. Due to memory error I want to split the data into chunks perfrom the split and concat them back into (df2).</p>\\n<p>I am still getting memory with the <code>split_function</code></p>\\n<p><code>df</code> is from process before this snippet</p>\\n<pre><code>def parallelize_dataframe(df, func, n_cores=4):\\n    df_split = np.array_split(df, n_cores)\\n    pool = Pool(n_cores)\\n    df = pd.concat(pool.map(fun, df_split))\\n    pool.close()\\n    pool.join()\\n    return df\\n\\ndef split_func(df):\\n    df2 = df['info'].str.split('  //  ',expand=True)\\n    return df2\\ndf2 = parallelize_dataframe(df, split_func(df))\\n</code></pre>\\n<p>Without the parallelize function I get memory error when I split the <code>df['info']</code></p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('cProfile taking a lot of memory', '<python><memory><cprofile>', '<p>I am attempting to profile my project in python, but I am running out of memory. </p>\\n\\n<p>My project itself is fairly memory intensive, but even half-size runs are dieing with \"MemoryError\" when run under cProfile. </p>\\n\\n<p>Doing smaller runs is not a good option, because we suspect that the run time is scaling  super-linearly, and we are trying to discover which functions are dominating during large runs.  </p>\\n\\n<p>Why is cProfile taking so much memory?  Can I make it take less? Is this normal?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Setting Pandas index to be a given DateTimeindex', '<python><pandas><indexing>', \"<p>I am trying to pull some daily data, and some data is missing.  I would like to fill with something (havent decided on 0's, nans or average filling).  I can get a df1 that has an index of the form:</p>\\n\\n<pre><code>print(df1.columns)\\nDatetimeIndex(['2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09',\\n               '2020-01-10', '2020-01-13', '2020-01-14', '2020-01-15'],\\n          dtype='datetime64[ns]', name='Date', freq=None)\\n</code></pre>\\n\\n<p>Now I try to pull down some df2, that is missing, lets say '2020-01-08'. Is there a way I can assert that <code>df2.index = df1.index</code>, with there being a column for the missing date, but the data (probably just NaNs that can be ffilled).</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to sort a pandas Series on values while randomizing the order of ties?', '<python><pandas><sorting>', \"<p>I'm using sort_values() to sort values in a pandas Series from largest to smallest. I wonder if there is an easy way of randomizing the order of ties(?). It appears that the indexes of ties come in the descending order given as argument in this case:</p>\\n\\n<pre><code>s = pd.Series([3.0, 15.0, 1.0, 22.0, 11.0, 12.0, 2.0, 5.0, 3.0, 12.0, 2.0, 3.0])\\ns.sort_values(ascending=False)\\n</code></pre>\\n\\n<p>Out:</p>\\n\\n<pre><code>3     22.0\\n1     15.0\\n9     12.0\\n5     12.0\\n4     11.0\\n7      5.0\\n11     3.0\\n8      3.0\\n0      3.0\\n10     2.0\\n6      2.0\\n2      1.0\\n</code></pre>\\n\\n<p>I have read the documentation that there are different kinds of sort that can be given as argument: quicksort, mergesort, heapsort. However, as far as I understand none of them will randomize the order of ties.</p>\\n\\n<p>I guess I could write a custom function, but curious to know if something exists.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('pytorch - design model for chord recognition?', '<python><pytorch>', '<p>I am trying to do a CNN for chord recognition in PyTorch. I\\'m following a paper, but I\\'m a beginner at this so now I\\'m stuck with the network model.</p>\\n<p>This is the explanation of the CNN:</p>\\n<p><a href=\"https://i.stack.imgur.com/4LZcs.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/4LZcs.png\" alt=\"CNN explanation\" /></a></p>\\n<p>For now i have this:</p>\\n<pre><code>class CNN(nn.Module):\\n    def __init__(self):\\n        super(CNN, self).__init__()\\n        \\n        in_channels=1\\n        out_channels=1\\n        kernel_size=(1,16,6,25)\\n        \\n        self.conv1 = nn.Sequential(nn.Conv3d(in_channels,\\n                     out_channels,kernel_size,stride=1,\\n                     padding=2),nn.Conv3d(in_channels,\\n                     out_channels,kernel_size,stride=1,\\n                     padding=2))\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Can't find a KIVY function related with video on Windows\", '<python><python-3.x><kivy><kivy-language>', '<p>I want to make an app that will start when the user will tap the screen on Windows, I render the animation but I don\\'t know what to write so the video widget (uix) can detect if the user tapped and execute a defined function, for now only write CLICK in the terminal. </p>\\n\\n<p>Thank you!</p>\\n\\n<pre><code>import kivy\\nfrom kivy.app import App\\nfrom kivy.lang import Builder\\nfrom kivy.base import runTouchApp\\nfrom kivy.uix.button import Button\\nfrom kivy.config import Config\\nfrom kivy.uix.videoplayer import Video\\nfrom kivy.uix.screenmanager import ScreenManager, Screen\\nfrom kivy.properties import ObjectProperty\\nfrom kivy.uix.widget import Widget\\nfrom kivy.uix.gridlayout import GridLayout\\nfrom kivy.uix.video import Video\\n\\n\\nkivy.require(\\'1.9.1\\') # the kivy version required      \\n\\nclass MyVideoApp(App):\\n        def build(self):\\n                self.video = Video(source=\"C:\\\\TouchHereToStart.mov\",  state=\\'play\\', options={\\'allow_stretch\\': False})\\n                self.video.options = {\\'eos\\': \\'loop\\'}\\n                return self.video\\n\\n        def writeclick(self, instance):\\n                print(\"Click\")\\n\\nConfig.set(\\'graphics\\', \\'fullscreen\\', \\'auto\\')\\nConfig.set(\\'graphics\\', \\'window_state\\', \\'maximized\\')\\nConfig.set(\\'graphics\\', \\'rotation\\', 0)\\nConfig.write()\\n\\nMyVideoApp().run()\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Python: How to join table by time condition', '<python><python-3.x><pandas>', '<p>Hi I have an original data called df1. I would like to join df2 to df1 with the following <strong>conditions</strong>:<br><br>\\n1) Match <code>CaseNo</code> col of df2 to df1.<br>\\n2) For each <code>CaseNo</code>, the <code>Request Date</code> col of df2 must fall between the Movement_Start_Date of the current row and proceeding/following row.<br>\\n3) If there is > 1 <code>RequestDate</code> that satisfies condition 2, we choose the latest date (max 1 <code>RequestDate</code> per <code>Movement_Sequence_No</code>).</p>\\n\\n<p>How do I go about this in Python?<br><br>\\ndf1:<br>\\n<a href=\"https://i.stack.imgur.com/I9ng0.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/I9ng0.png\" alt=\"enter image description here\"></a><br>\\ndf2:<br>\\n<a href=\"https://i.stack.imgur.com/XkSN1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/XkSN1.png\" alt=\"enter image description here\"></a><br>\\nExpected Output:<br><br>\\n<a href=\"https://i.stack.imgur.com/moQO6.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/moQO6.png\" alt=\"enter image description here\"></a></p>\\n\\n<pre><code>df1 = pd.DataFrame({\\'CaseNo\\':[1,1,1,1,2,2,2,2],\\n                    \\'Movement_Sequence_No\\':[1,2,3,4,1,2,3,4],\\n                    \\'Movement_Start_Date\\':[\\'2020-02-09 22:17:00\\',\\'2020-02-10 17:19:41\\',\\'2020-02-17 08:04:19\\',\\n                                           \\'2020-02-18 11:22:52\\',\\'2020-02-12 23:00:00\\',\\'2020-02-24 10:26:35\\',\\n                                           \\'2020-03-03 17:50:00\\',\\'2020-03-17 08:24:19\\'],\\n                    \\'Movement_End_Date\\':[\\'2020-02-10 17:19:41\\',\\'2020-02-17 08:04:19\\',\\'2020-02-18 11:22:52\\',\\n                                         \\'2020-02-25 13:55:37\\',\\'2020-02-24 10:26:35\\',\\'2020-03-03 17:50:00\\',\\n                                         \\'9999-12-31 23:59:59\\',\\'2020-03-18 18:50:00\\'],\\n                    \\'Category\\':[\\'A\\',\\'A\\',\\'A\\',\\'A\\',\\'B\\',\\'B\\',\\'B\\',\\'B\\']})\\n\\ndf2 = pd.DataFrame({\\'CaseNo\\':[1,1,1,1,1,1,2,2,2,2,2],\\n                    \\'RequestDate\\':[\\'2020-02-16 13:04:20\\',\\'2020-02-17 09:10:10\\',\\'2020-02-18 07:11:11\\',\\n                                   \\'2020-02-20 14:03:55\\',\\'2020-02-21 21:30:30\\',\\'2020-02-27 12:52:10\\',\\n                                   \\'2020-02-13 22:00:00\\',\\'2020-03-15 09:40:00\\',\\'2020-03-17 09:45:20\\',\\n                                  \\'2020-03-18 09:26:19\\',\\'2020-03-18 15:10:10\\'],\\n                    \\'Platelets\\':[\\'189\\',\\'207\\',\\'190\\',\\'195\\',\\'188\\',\\'241\\',\\'328\\',\\'266\\',\\'180\\',\\'210\\',\\'310\\']})\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"CMD recognizes 'py', but PowerShell doesn't\", '<python><powershell>', \"<p>Python does not work in PowerShell anymore.</p>\\n<p>I've never had any problems, until recently. CMD still recognizes the <code>py</code> command, but powershell doesn't recognize any of the basic python commands: <code>py</code>,<code>py3</code>,<code>python</code>,<code>python3</code>.\\nMy problem occured after I installed MinGW and added its path to the Path variable.</p>\\n<p>I have restarted my computer many times, while trying new things.</p>\\n<p>Things I've tried:</p>\\n<ul>\\n<li>I have tried removing MinGW from the Path variable.</li>\\n<li>I have tried uninstalling MinGW.</li>\\n<li>I have tried reinstalling python.</li>\\n<li>I have tried manually adding the Python path.</li>\\n<li>I have tried letting Python automatically add my Python path.</li>\\n<li>I have tried adding the Python path to both the user environment variables and the system variables.</li>\\n<li>I have tried running PowerShell as administrator.</li>\\n</ul>\\n<p>Finally, this is what my Path variable looks like now:</p>\\n<p><strong>User Path Variable:</strong></p>\\n<pre><code>C:\\\\Users\\\\lcdew\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\nC:\\\\Users\\\\lcdew\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin\\n</code></pre>\\n<p><strong>System Path Variable:</strong></p>\\n<pre><code>C:\\\\Program Files\\\\Python38\\\\Scripts\\nC:\\\\Program Files\\\\Python38\\nC:\\\\Program Files\\\\Scripts\\nC:\\\\Program Files\\nC:\\\\Program Files (x86)\\\\Scripts\\nC:\\\\Program Files (x86)\\nC:\\\\Program Files (x86)\\\\Razer Chroma SDK\\\\bin\\nC:\\\\Program Files\\\\Razer Chroma SDK\\\\bin\\nC:\\\\Windows\\\\system32\\nC:\\\\Windows\\nC:\\\\Windows\\\\System32\\\\Wbem\\nC:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\nC:\\\\Windows\\\\System32\\\\OpenSSH\\nC:\\\\Windows\\\\system32\\\\config\\\\systemprofile\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\nC:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR\\nC:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common\\n</code></pre>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('kivy installation with pip', '<python><installation><pip><kivy>', \"<p>this is out when i'm installing kivy with pip on cmd</p>\\n<pre><code>'''\\nERROR: Command errored out with exit status 1:\\n command: 'C:\\\\Users\\\\xeryd\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38-32\\\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'C:\\\\\\\\Users\\\\\\\\xeryd\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\pip-install-f59y46nt\\\\\\\\kivy\\\\\\\\setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'C:\\\\\\\\Users\\\\\\\\xeryd\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\pip-install-f59y46nt\\\\\\\\kivy\\\\\\\\setup.py'&quot;'&quot;';f=getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__);code=f.read().replace('&quot;'&quot;'\\\\r\\\\n'&quot;'&quot;', '&quot;'&quot;'\\\\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' egg_info --egg-base 'C:\\\\Users\\\\xeryd\\\\AppData\\\\Local\\\\Temp\\\\pip-pip-egg-info-egy9la7d'\\n     cwd: C:\\\\Users\\\\xeryd\\\\AppData\\\\Local\\\\Temp\\\\pip-install-f59y46nt\\\\kivy\\\\\\n</code></pre>\\n<p>what should I do?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"Can't exec_command() with paramiko over SSH tunnel\", '<python><paramiko><send><execcommand>', \"<p>I don't have direct access to the device, so I first create an SSH tunnel to an intermediate device; then login to far end remote device; then execute. This works well over CLI.</p>\\n<pre><code>ssh user@127.0.0.1 -p 2222 -oKexAlgorithms=+diffie-hellman-group1-sha1 -c aes128-cbc\\nuser@127.0.0.1's password: \\n</code></pre>\\n<p>When using Paramiko, I can login correctly, but cannot send commands over. I've enabled loggin to see what's going on, but can't find a clue.</p>\\n<pre><code>import paramiko\\nconn2rtr = paramiko.SSHClient()\\nconn2rtr.load_system_host_keys()\\nconn2rtr.set_missing_host_key_policy(paramiko.AutoAddPolicy())\\nconn2rtr.connect(hostname='127.0.0.1', port=2222, username='user', password='pass')\\nDEBUG:paramiko.transport:Adding ssh-rsa host key for [127.0.0.1]:2222: b'feaaa6e6e79b979e3a99c213e92a0b34'\\nDEBUG:paramiko.transport:userauth is OK\\nINFO:paramiko.transport:Authentication (password) successful!\\n</code></pre>\\n<p>But when I want to send a command (i.e. <code>exec_command</code>) I get an Exception EOFError.</p>\\n<pre><code>stdin, stdout, stderr = conn2rtr.exec_command(&quot;show version\\\\n&quot;)                                                                                                                                                                     \\nDEBUG:paramiko.transport:[chan 0] Max packet in: 32768 bytes\\nDEBUG:paramiko.transport:[chan 0] Max packet out: 32768 bytes\\nDEBUG:paramiko.transport:Secsh channel 0 opened.\\nDEBUG:paramiko.transport:EOF in transport thread\\n---------------------------------------------------------------------------\\nEOFError                                  Traceback (most recent call last)\\n&lt;ipython-input-20-01669f7eafd5&gt; in &lt;module&gt;\\n----&gt; 1 stdin, stdout, stderr = conn2rtr.exec_command(&quot;show version\\\\n&quot;)\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/client.py in exec_command(self, command, bufsize, timeout, get_pty, environment)\\n    512         if environment:\\n    513             chan.update_environment(environment)\\n--&gt; 514         chan.exec_command(command)\\n    515         stdin = chan.makefile_stdin(&quot;wb&quot;, bufsize)\\n    516         stdout = chan.makefile(&quot;r&quot;, bufsize)\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/channel.py in _check(self, *args, **kwds)\\n     70         ):\\n     71             raise SSHException(&quot;Channel is not open&quot;)\\n---&gt; 72         return func(self, *args, **kwds)\\n     73 \\n     74     return _check\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/channel.py in exec_command(self, command)\\n    255         self._event_pending()\\n    256         self.transport._send_user_message(m)\\n--&gt; 257         self._wait_for_event()\\n    258 \\n    259     @open_only\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/channel.py in _wait_for_event(self)\\n   1224         if e is None:\\n   1225             e = SSHException(&quot;Channel closed.&quot;)\\n-&gt; 1226         raise e\\n   1227 \\n   1228     def _set_closed(self):\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/transport.py in run(self)\\n   2053                         self._send_kex_init()\\n   2054                     try:\\n-&gt; 2055                         ptype, m = self.packetizer.read_message()\\n   2056                     except NeedRekeyException:\\n   2057                         continue\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/packet.py in read_message(self)\\n    457         :raises: `.NeedRekeyException` -- if the transport should rekey\\n    458         &quot;&quot;&quot;\\n--&gt; 459         header = self.read_all(self.__block_size_in, check_rekey=True)\\n    460         if self.__etm_in:\\n    461             packet_size = struct.unpack(&quot;&gt;I&quot;, header[:4])[0]\\n\\n/usr/local/lib/python3.8/dist-packages/paramiko/packet.py in read_all(self, n, check_rekey)\\n    301                 x = self.__socket.recv(n)\\n    302                 if len(x) == 0:\\n--&gt; 303                     raise EOFError()\\n    304                 out += x\\n    305                 n -= len(x)\\n\\nEOFError: \\n</code></pre>\\n<p>The same happens if I define a <code>bufsize</code> inside the <code>exec_command()</code>.</p>\\n<p>Any hint? Thanks!</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('sqlite3 - table has no column named', '<python><python-3.x><sqlite>', \"<p>I am attempting to create a file to handle sqlite3 databases for me (mostly for practice).</p>\\n<p>I have tried to add an _id column (integer and primary key), and it doesn't seem to be creating correctly.</p>\\n<p>The driver code is as below</p>\\n<pre><code>class DB(My_SQL):\\n\\n  column_headings = [&quot;FName&quot;, &quot;SName&quot;]\\n\\n  def __init__(self):\\n\\n    self.create_table()\\n\\ndb = DB()\\n\\ndb.add_record(&quot;User&quot;, &quot;1&quot;)\\ndb.add_record(&quot;User&quot;, &quot;2&quot;)\\n</code></pre>\\n<p>The code in the My_SQL class is as below:</p>\\n<pre><code>import sqlite3\\n\\nclass My_SQL:\\n  \\n  def create_table(self):\\n    self.records = 0\\n    self.db_name = My_SQL.__subclasses__()[0].__name__\\n    columns = [&quot;_id INTEGER PRIMARY KEY&quot;]\\n    for column in self.column_headings:\\n      type_column = {int: 'integer', str: 'text', bool: 'BIT'}[type(column)]\\n      columns.append(f&quot;{column} {type_column}&quot;)\\n    self.sql_create(columns)\\n\\n  def sql_create(self, columns):\\n    \\n    self.conn = sqlite3.connect(f&quot;{self.db_name}.db&quot;)\\n    self.cursor = self.conn.cursor()\\n\\n    table = f'''CREATE TABLE IF NOT EXISTS {self.db_name} ({&quot;, &quot;.join(columns)});'''\\n\\n    self.cursor.execute(table)\\n  \\n  def add_record(self, *args):\\n\\n    self.records += 1\\n\\n    args = self.format_args(args)\\n    \\n    self.cursor.execute(f&quot;INSERT INTO {self.db_name} ({', '.join(self.column_headings)}) VALUES ({', '.join(args)})&quot;)\\n  \\n  def format_args(self, args):\\n\\n    args = list(args)\\n\\n    for index, arg in enumerate(args):\\n\\n      if type(arg) == str:\\n        args[index] = f&quot;\\\\&quot;{arg}\\\\&quot;&quot;\\n    \\n    args.insert(0, str(self.records))\\n\\n    return args\\n  \\n  def show_table(self):\\n\\n    self.cursor.execute(f&quot;SELECT * FROM {self.db_name}&quot;)\\n    rows = self.cursor.fetchall()\\n\\n    for row in rows:\\n      print(row)\\n</code></pre>\\n<p>When it is run, it throws the following error:</p>\\n<pre><code>&gt;&gt;&gt; Line 29, in add_record\\n&gt;&gt;&gt; sqlite3.OperationError: 3 values for 2 columns\\n</code></pre>\\n<p>When I replace <code>self.cursor.execute(f&quot;INSERT INTO {self.db_name} ({', '.join(self.column_headings)}) VALUES ({', '.join(args)})&quot;)</code> in <code>add_record</code> with <code>self.cursor.execute(f&quot;INSERT INTO {self.db_name} (_id, FName, SName) VALUES ({', '.join(args)})&quot;)</code>, it throws the following error:</p>\\n<pre><code>&gt;&gt;&gt; Line 29, in add_record\\n&gt;&gt;&gt; sqlite3.OperationError: table DB has no column named _id\\n</code></pre>\\n<p>I'm not particularly adept with SQL, so after looking this up, I have no idea what's wrong or how to fix it. I have tried running a select statement to check if it exists, and it doesn't appear to throw an error. Any help?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('python, generic functions', '<python>', '<p>How to create generic stack in python?\\nMy stack implementation in python:</p>\\n\\n<pre><code>class Node(object):\\n    def __init__(self, d):\\n        self.data = d\\n        self.nextNode = None\\n\\nclass Stack(object):\\n    def __init__(self):\\n        self.top = None\\n\\n    def push(self, item):\\n        newNode = Node(item)\\n        newNode.nextNode = self.top\\n        self.top = newNode\\n\\n    def pop(self):\\n        if self.top == None:\\n            return None\\n        item = self.top.data\\n        self.top = self.top.nextNode\\n        return item\\n</code></pre>\\n\\n<p>Now I am putting objects of class Node, but how implement generic Stack so that I can put there anything. For example, if I want create new type of nodes</p>\\n\\n<pre><code>class NodeWithMin:\\n    def __init__(self, value, minval):\\n        self.data = value\\n        self.minval = minval\\n</code></pre>\\n\\n<p>And be able create stack based on these type of nodes, so it should be something like this (of course it does not work):</p>\\n\\n<pre><code>class StackWithMin(qs.Stack):\\n    def push(self, val):\\n        if self.peek() != None:\\n            minval = min(self.peek().value, val)\\n        else:\\n            minval = val\\n        qs.Stack.push(NodeWithMinV2(val, minval))\\n</code></pre>\\n\\n<p>any idea?</p>\\n\\n<p>EDIT:\\nit did not work because I have next error:</p>\\n\\n<pre><code>unbound method push() must be called with Stack instance as first argument (got NodeWithMinV2 instance instead)\\n</code></pre>\\n\\n<p>I missed <code>self</code></p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to do implement a paging solution with a dict object in Python', '<python><dictionary><paging>', \"<p>Is there a better way to implement a paging solution using <code>dict</code> than this?</p>\\n\\n<p>I have a <code>dict</code> with image names and URLs. \\nI need to 16 key value pairs at a time depending on the user's request, i.e. page number.\\nIt's a kind of paging solution. \\nI can implement this like:</p>\\n\\n<p>For example :</p>\\n\\n<pre><code>dict = {'g1':'first', 'g2':'second', ... }\\n</code></pre>\\n\\n<p>Now I can create a mapping of the keys to numbers using:</p>\\n\\n<pre><code>ordered={}\\nfor i, j in enumerate(dict):\\n    ordered[i]=j\\n</code></pre>\\n\\n<p>And then retrieve them:</p>\\n\\n<pre><code>dicttosent={}\\nfor i in range(paegnumber, pagenumber+16):\\n  dicttosent[ordered[i]] = dict[ordered[i]]\\n</code></pre>\\n\\n<p>Is this a proper method? Or will this give random results?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Converting the endianness type of an already existing binary file', '<python><endianness><data-conversion>', \"<p>I have a binary file on my PC that contains data in big-endian. The file contains around 121 MB.<br>\\nThe problem is I would like to convert the data into little-endian with a python script. </p>\\n\\n<p>What is currently giving me headaches is the fact that I don't know how to convert an entire file. If I would have a short hex string I could simply use struct.pack to convert it into little-endian but if I see this correctly I can't give struct.pack a binary file as input.</p>\\n\\n<p>Is there an other function/utility that I can use to do that or how should my approach look like?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Replace climbing sequence with its average', '<python><list>', '<p>I have a random list like this</p>\\n\\n<pre><code>X = [0, 1, 5, 6, 7, 10, 15]\\n</code></pre>\\n\\n<p>and need to find and replace every climbing sequence with its average.\\nIn the end it should look like this:</p>\\n\\n<pre><code>X = [0, 6, 10, 15]       #the 0 and 1 to 0; and the 5,6,7 to 6\\n</code></pre>\\n\\n<p>I tried to find the sequence by subtracting the second value from the first like this:</p>\\n\\n<pre><code>y = 0\\nz = []\\nwhile X[y +1] -X[y] == 1: \\n            z.append(X[y])\\n\\n            y = y +1\\n</code></pre>\\n\\n<p>And now I dont know how to delete for example 5,6 and 7 and replace it with the average 6. </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Psycopg2 - SQL script returning no output', '<python><psycopg2>', \"<p>I am trying to pass a few arguments as variable to a SQL script but I am having issues returning an output.</p>\\n\\n<p>Given below is my code:</p>\\n\\n<pre><code>start_date = '2020-03-01'\\nend_date = '2020-03-02'\\n</code></pre>\\n\\n<p>I pass these into the below query</p>\\n\\n<pre><code>cursor.execute('select bill_number from table \\n                where created_at between {} and {}'.format(start_date, end_date))\\n</code></pre>\\n\\n<p>The above returns no output but I know data exists for this SQL script</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('How to skip empty dates (weekends) in a financial Matplotlib Python graph?', '<python><graph><matplotlib><financial>', '<pre><code>ax.plot_date((dates, dates), (highs, lows), \\'-\\')\\n</code></pre>\\n\\n<p>I\\'m currently using this command to plot financial highs and lows using <a href=\"http://en.wikipedia.org/wiki/Matplotlib\" rel=\"noreferrer\">Matplotlib</a>. It works great, but how do I remove the blank spaces in the x-axis left by days without market data, such as weekends and holidays?</p>\\n\\n<p>I have lists of dates, highs, lows, closes and opens. I can\\'t find any examples of creating a graph with an x-axis that show dates but doesn\\'t enforce a constant scale. </p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Method within Class not activating', '<python><class><methods>', '<p>Here is my code, my issue is as the title above states, the input text does not appear and neither does the print below. I am new to Python so sorry for a simple mistake</p>\\n\\n<pre><code>class Horse:\\n    colour = \\'\\'\\n    height = \\'\\'\\n    speed = 0\\n\\n    def __init__(self):\\n        self.speed = input(\"Enter an integer: \")\\n\\n        if(self.speed != 0):\\n            self.gallop = (3 * self.speed)\\n\\n        print(self.gallop)\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Efficiently apply several different operations to a dataset', '<python><pandas><pandas-groupby>', '<p>I have to do several different operations to many columns of a DataSet, I did it but not in a very efficient way... </p>\\n\\n<p>As an example, I have this table:</p>\\n\\n<pre><code>|   A  |   B  |   C  |   D  |   E  |\\n|------|------|------|------|------|\\n|  1.0 |  1.0 |  1.0 |  2.0 |   a  |\\n|  2.0 |  1.0 |  1.5 |  5.0 |   a  |\\n|  3.0 |  1.0 |  2.0 |  3.0 |   b  |\\n|  1.0 |  2.0 |  2.0 |  6.0 |   a  |\\n|  2.0 |  2.0 |  3.0 |  4.0 |   b  |\\n|  3.0 |  2.0 |  4.0 |  2.0 |   b  |\\n|  1.0 |  3.0 |  5.0 |  5.0 |   b  |\\n|  2.0 |  3.0 |  6.0 |  1.0 |   a  |\\n|  3.0 |  3.0 | 10.0 |  2.0 |   a  |\\n</code></pre>\\n\\n<p>And I need to get the following result:</p>\\n\\n<pre><code># I dont need the A column, the criteria is the B column, apply the mean \\n# to the C, the sum to the D and the most frequent on E\\n|   B  |   C  |   D  |   E  |\\n|------|------|------|------|\\n|  1.0 |  1.5 | 10.0 |   a  |\\n|  2.0 |  3.0 | 12.0 |   b  |\\n|  3.0 |  7.0 |  8.0 |   a  |\\n</code></pre>\\n\\n<p>Here is my attempt but is extremely slow. My original dataset has 2.000.000 of rows. Transforming it to 130.000 takes more than 30 minutes and I have to apply it three times... this is why I need something more efficient.</p>\\n\\n<pre><code>import pandas as pd\\ndf = pd.DataFrame({\"A\":[1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0], \\n                   \"B\":[1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0], \\n                   \"C\":[1.0, 1.5, 2.0, 2.0, 3.0, 4.0, 5.0, 6.0, 10.0],\\n                   \"D\":[2.0, 5.0, 3.0, 6.0, 4.0, 2.0, 5.0, 1.0, 2.0],\\n                   \"E\":[\\'a\\', \\'a\\', \\'b\\', \\'a\\', \\'b\\', \\'b\\', \\'b\\', \\'a\\', \\'a\\']}) \\n\\nprint(df)\\n\\ndict_ds = { \\'B\\' : [], \\'C\\' : [], \\'D\\' : [], \\'E\\' : []}\\ndf2 = pd.DataFrame(dict_ds)\\n\\ndf=df.groupby(\\'B\\')\\nfor n in df.first().index:\\n    data    = df.get_group(n)\\n    partial = data.mean()\\n    new_C   = partial[\\'C\\']\\n    partial = data.sum()\\n    new_D   = partial[\\'D\\']\\n    new_E   = data[\\'E\\'].mode()[0]\\n    df2.loc[len(df2)] = (n,new_C,new_D,new_E)\\n\\nprint(df2)\\n</code></pre>\\n\\n<hr>\\n\\n<hr>\\n\\n<hr>\\n\\n<hr>\\n\\n<p>This part is after getting the solution.\\nIf I apply the operation <code>unique</code> to the <code>agg</code>:</p>\\n\\n<pre><code>df.groupby(\\'B\\').agg({\\n                     \\'A\\': \\'unique\\',\\n                     \\'C\\': \\'mean\\',\\n                     \\'D\\': \\'sum\\',\\n                     \\'E\\': lambda x: x.mode()\\n                     }).reset_index()\\n</code></pre>\\n\\n<p>I have the next result:</p>\\n\\n<pre><code>     B                A    C     D  E\\n0  1.0  [1.0, 2.0, 3.0]  1.5  10.0  a\\n1  2.0  [1.0, 2.0, 3.0]  3.0  12.0  b\\n2  3.0  [1.0, 2.0, 3.0]  7.0   8.0  a\\n</code></pre>\\n\\n<p>But I need to have it in this other way:</p>\\n\\n<pre><code>     A    B     C    D   E\\n0  1.0  1.0   1.5  10.0  a\\n1  2.0  1.0   1.5  10.0  a\\n2  3.0  1.0   1.5  10.0  a\\n3  1.0  2.0   3.0  12.0  b\\n4  2.0  2.0   3.0  12.0  b\\n5  3.0  2.0   3.0  12.0  b\\n6  1.0  3.0   7.0   8.0  a\\n7  2.0  3.0   7.0   8.0  a\\n8  3.0  3.0   7.0   8.0  a\\n</code></pre>\\n\\n<p>Is it possible to have something similar? A very efficent way?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"googletrans python AttributeError: 'NoneType' object has no attribute 'group'\", '<python><discord><discord.py><google-translate><translators>', '<p>So, I\\'ve prepared code like this:</p>\\n<pre><code>async def cv_local(ctx, country=&quot;&quot;):\\n    translator = Translator()\\n    try:\\n        country = translator.translate(country, dest=\\'en\\').text\\n        now = datetime.datetime.now()\\n        # startTime = time.time()\\n        if country == &quot;&quot;:\\n            country = &quot;world&quot;\\n            print(&quot;At &quot; + str(now.hour) + &quot;:&quot; + str(now.minute) + &quot; user &quot; + str(ctx.message.author.name) + &quot;(Id: &quot; + str(\\n                ctx.message.author.id) + &quot;)&quot; +\\n                  &quot; didn\\'t mention any country, sent data for world&quot;)\\n        else:\\n            print(&quot;At &quot; + str(now.hour) + &quot;:&quot; + str(now.minute) + &quot; user &quot; + str(ctx.message.author.name) + &quot;(Id: &quot; + str(\\n                ctx.message.author.id) + &quot;)&quot; + &quot; searched for: &quot; +\\n                  str(Library.exceptionCheck(country)[1]))\\n\\n        if str(country).lower() == &quot;world&quot; or str(country).lower() == &quot;kw&quot; or str(country).lower() == &quot;za&quot;:\\n            url = \\'https://www.worldometers.info/coronavirus/\\'\\n            code = Library.HttpsRead(url, &quot;wiat&quot;, config[str(ctx.message.guild.id)][\\'lang\\'])\\n        else:\\n            temp1 = Library.exceptionCheck(country)[0]\\n            url = \\'https://www.worldometers.info/coronavirus/country/\\' + temp1\\n            code = Library.HttpsRead(url, country, config[str(ctx.message.guild.id)][\\'lang\\'])\\n\\n        message = await ctx.send(embed=code)\\n        await message.add_reaction(&quot;&quot;)\\n        # print(&quot;execution took %s seconds \\\\n&quot; % (time.time() - startTime))\\n    except UnboundLocalError:\\n        await ctx.send(&quot;That\\'s strange... It seems like you wanted data for country that doesn\\'t exist in my database\\\\nImportant message: if you would like to look for countries named with multiple words insert \\\\&quot;-\\\\&quot; instead of &quot;\\n                       &quot;spaces or use shortcuts f.e. \\\\&quot;uk\\\\&quot; instead of \\\\&quot;United Kingdom\\\\&quot; or \\\\&quot;south-africa\\\\&quot; instead of \\\\&quot;South Africa\\\\&quot;\\\\n\\\\n If error will be repeating report it to &lt;@!287258679609393152&gt;&quot;)\\n        print(&quot;Error occurred, user missed name of country&quot;)\\n        # print(&quot;execution took %s seconds \\\\n&quot; % (time.time() - startTime))\\n    except:\\n        await ctx.send(&quot;That\\'s strange... Translator occurred some kind of error\\\\nJust try again and everything should be just fine\\\\n\\\\n If error will be repeating report it to &lt;@!287258679609393152&gt;&quot;)\\n        print(&quot;Error occurred, informed user&quot;)\\n        # print(&quot;execution took %s seconds \\\\n&quot; % (time.time() - startTime))\\n</code></pre>\\n<p>It\\'s discord bot, and everything used to work perfectly, but lately it started to crash more and more frequently, here\\'s an error log:</p>\\n<pre><code>Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\discord\\\\ext\\\\commands\\\\core.py&quot;, line 85, in wrapped\\n    ret = await coro(*args, **kwargs)\\n  File &quot;C:/Users/grzes/PycharmProjects/CoronaBot/bot.py&quot;, line 222, in cv_local\\n    country = translator.translate(country, dest=\\'en\\').text\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\client.py&quot;, line 172, in translate\\n    data = self._translate(text, dest, src)\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\client.py&quot;, line 75, in _translate\\n    token = self.token_acquirer.do(text)\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\gtoken.py&quot;, line 186, in do\\n    self._update()\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\gtoken.py&quot;, line 65, in _update\\n    code = unicode(self.RE_TKK.search(r.text).group(1)).replace(\\'var \\', \\'\\')\\nAttributeError: \\'NoneType\\' object has no attribute \\'group\\'\\n</code></pre>\\n<p>I\\'ve read a little bit about it and tried few solutions from <a href=\"https://stackoverflow.com/questions/52455774/googletrans-stopped-working-with-error-nonetype-object-has-no-attribute-group/52487148#52487148\">here</a>, but nothing seems to work for me, maybe it\\'s different problem than this one? I\\'ve just got no idea what else to do, can anyone help with this?</p>\\n<p>EDIT: added <code>os.environ[&quot;HTTPX_LOG_LEVEL&quot;] = &quot;DEBUG&quot;</code>\\nAnd output is like this:</p>\\n<pre><code>Traceback (most recent call last):\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\discord\\\\ext\\\\commands\\\\core.py&quot;, line 85, in wrapped\\n    ret = await coro(*args, **kwargs)\\n  File &quot;C:/Users/grzes/PycharmProjects/CoronaBot/bot.py&quot;, line 242, in cv_local\\n    code = Library.HttpsRead(url, country, config[str(ctx.message.guild.id)][\\'lang\\'])\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\Library.py&quot;, line 221, in HttpsRead\\n    embed = discord.Embed(title=translator.translate(&quot;Dane o chorobie&quot;, dest=currLang).text, description=&quot;[Support bot](https://kickstarter.com), [vote](https://top.gg), [support me](https://patreon.com)&quot;, color=0xf00000)\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\client.py&quot;, line 172, in translate\\n    data = self._translate(text, dest, src)\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\client.py&quot;, line 75, in _translate\\n    token = self.token_acquirer.do(text)\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\gtoken.py&quot;, line 186, in do\\n    self._update()\\n  File &quot;C:\\\\Users\\\\grzes\\\\PycharmProjects\\\\CoronaBot\\\\venv\\\\lib\\\\site-packages\\\\googletrans-2.3.0-py3.8.egg\\\\googletrans\\\\gtoken.py&quot;, line 65, in _update\\n    code = unicode(self.RE_TKK.search(r.text).group(1)).replace(\\'var \\', \\'\\')\\nAttributeError: \\'NoneType\\' object has no attribute \\'group\\'\\n</code></pre>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('app-engine and python. how to go to subpath', '<python><google-app-engine>', \"<p>I know <code>users.create_logout('example')</code> can direct to users to the path under the current path. like <code>/main/example/</code>, but what if i want to direct the users to the subpath of the example, say <code>/main/example/example1</code>, how do I do that? Thank you a lot</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('re-run Python script in started in docker-compose with MySQL server running', '<python><mysql><docker>', \"<p>Using <code>docker compose</code> I've created a container for my MySQL DB and one for my Python script. When I use the command <code>docker compose up</code>, my images are built for my Python app container and my MySQL DB container, and the python script is run. After execution, the shell just hangs since MySQL server is still running and my script has completed execution. How can I either stop the MySQL server after my script runs, or re-run my script while the MySQL server continues to run?</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('My discord.py bot always loses connection to my MySQL database on Heroku', '<python><mysql><heroku><discord.py><mysql-connector-python>', \"<p>So, I've got a problem with my bot hosted on Heroku. Indeed, my bot manages a level system that I've made with MySQL. My system seems to be working perfectly, but, only for a few minutes after starting the bot. During this period, all the commands are working. After 5 minutes, at least, that my bot has started, no more command related to the database works. When a command is written, the logs write this:</p>\\n<pre><code>2020-10-08T21:51:00.344273+00:00 app[worker.1]: Ignoring exception in on_message\\n2020-10-08T21:51:00.346163+00:00 app[worker.1]: Traceback (most recent call last):\\n2020-10-08T21:51:00.346212+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/discord/client.py&quot;, line 333, in _run_event\\n2020-10-08T21:51:00.346213+00:00 app[worker.1]: await coro(*args, **kwargs)\\n2020-10-08T21:51:00.346215+00:00 app[worker.1]: File &quot;pabBot.py&quot;, line 96, in on_message\\n2020-10-08T21:51:00.346217+00:00 app[worker.1]: await upgrade_level(message.author, message)\\n2020-10-08T21:51:00.346236+00:00 app[worker.1]: File &quot;pabBot.py&quot;, line 19, in upgrade_level\\n2020-10-08T21:51:00.346238+00:00 app[worker.1]: cursor.execute(&quot;SELECT exp, lvl, exp_time FROM level_users WHERE id=%s;&quot;, (user.id, ))\\n2020-10-08T21:51:00.346241+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/cursor.py&quot;, line 551, in execute\\n2020-10-08T21:51:00.346241+00:00 app[worker.1]: self._handle_result(self._connection.cmd_query(stmt))\\n2020-10-08T21:51:00.346262+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/connection.py&quot;, line 490, in cmd_query\\n2020-10-08T21:51:00.346263+00:00 app[worker.1]: result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))\\n2020-10-08T21:51:00.346281+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/connection.py&quot;, line 267, in _send_cmd\\n2020-10-08T21:51:00.346281+00:00 app[worker.1]: return self._socket.recv()\\n2020-10-08T21:51:00.346300+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/network.py&quot;, line 243, in recv_plain\\n2020-10-08T21:51:00.346300+00:00 app[worker.1]: raise errors.InterfaceError(errno=2013)\\n2020-10-08T21:51:00.346325+00:00 app[worker.1]: mysql.connector.errors.InterfaceError: 2013: Lost connection to MySQL server during query\\n2020-10-08T21:51:00.346399+00:00 app[worker.1]: Ignoring exception in command level:\\n2020-10-08T21:51:00.347478+00:00 app[worker.1]: Traceback (most recent call last):\\n2020-10-08T21:51:00.347541+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/discord/ext/commands/core.py&quot;, line 85, in wrapped\\n2020-10-08T21:51:00.347541+00:00 app[worker.1]: ret = await coro(*args, **kwargs)\\n2020-10-08T21:51:00.347557+00:00 app[worker.1]: File &quot;pabBot.py&quot;, line 168, in level\\n2020-10-08T21:51:00.347557+00:00 app[worker.1]: cursor.execute(&quot;SELECT exp, lvl FROM level_users WHERE id=%s&quot;, (user.id, ))\\n2020-10-08T21:51:00.347572+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/cursor.py&quot;, line 551, in execute\\n2020-10-08T21:51:00.347572+00:00 app[worker.1]: self._handle_result(self._connection.cmd_query(stmt))\\n2020-10-08T21:51:00.347574+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/connection.py&quot;, line 490, in cmd_query\\n2020-10-08T21:51:00.347574+00:00 app[worker.1]: result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))\\n2020-10-08T21:51:00.347591+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/connection.py&quot;, line 267, in _send_cmd\\n2020-10-08T21:51:00.347591+00:00 app[worker.1]: return self._socket.recv()\\n2020-10-08T21:51:00.347594+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/mysql/connector/network.py&quot;, line 243, in recv_plain\\n2020-10-08T21:51:00.347595+00:00 app[worker.1]: raise errors.InterfaceError(errno=2013)\\n2020-10-08T21:51:00.347622+00:00 app[worker.1]: mysql.connector.errors.InterfaceError: 2013: Lost connection to MySQL server during query\\n2020-10-08T21:51:00.347625+00:00 app[worker.1]:\\n2020-10-08T21:51:00.347625+00:00 app[worker.1]: The above exception was the direct cause of the following exception:\\n2020-10-08T21:51:00.347625+00:00 app[worker.1]:\\n2020-10-08T21:51:00.347641+00:00 app[worker.1]: Traceback (most recent call last):\\n2020-10-08T21:51:00.347669+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/discord/ext/commands/bot.py&quot;, line 903, in invoke\\n2020-10-08T21:51:00.347669+00:00 app[worker.1]: await ctx.command.invoke(ctx)\\n2020-10-08T21:51:00.347688+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/discord/ext/commands/core.py&quot;, line 859, in invoke\\n2020-10-08T21:51:00.347688+00:00 app[worker.1]: await injected(*ctx.args, **ctx.kwargs)\\n2020-10-08T21:51:00.347709+00:00 app[worker.1]: File &quot;/app/.heroku/python/lib/python3.6/site-packages/discord/ext/commands/core.py&quot;, line 94, in wrapped\\n2020-10-08T21:51:00.347709+00:00 app[worker.1]: raise CommandInvokeError(exc) from exc\\n2020-10-08T21:51:00.347734+00:00 app[worker.1]: discord.ext.commands.errors.CommandInvokeError: Command raised an exception: InterfaceError: 2013: Lost connection to MySQL server during query\\n</code></pre>\\n<p>Here is my <em>requirements.txt</em>:</p>\\n<pre><code>discord.py\\ndnspython==1.16.0\\nmysql-connector\\n</code></pre>\\n<p>Of course, I noticed that the error is:\\n<code>mysql.connector.errors.InterfaceError: 2013: Lost connection to MySQL server during query</code></p>\\n<p>I've been looking for information about this error, and I didn't really get it.\\nI still don't know if the error is an server-side error, or client-side, or if it's because of my code. For information, my database is hosted on <strong>remotemysql.com</strong>.\\nAlso, I tried to reproduce the error locally, and it works too. So, I don't think the error comes from Heroku.</p>\\n<p>My code is very large, so I don't think it's a good idea to send it in full, but I have some fonctions that allow me to check my level, someone else's level and to make a leaderboard.</p>\\n<p>If you guys know why my bot doesn't work and what the error is about, i'll gladly take your information! Also, if you need more details, i'll send them.</p>\\n<p>(Sorry for my bad english, I'm a french guy ^^')</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('scipy with py2exe', '<python><scipy><py2exe>', '<p>I get the following error message using python v2.7.3 and scipy v0.11.0 with py2exe v0.6.10 on a 64 bit machine using 64 bit versions of the packages from <a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs\" rel=\"noreferrer\">Christoph Gohlke</a>.  If anyone can provide relevant and useful suggestions I would greatly appreciate it.  Here is the error message:</p>\\n\\n<pre><code>Traceback (most recent call last):\\n  File \"test2.py\", line 4, in &lt;module&gt;\\n  File \"scipy\\\\sparse\\\\__init__.pyo\", line 191, in &lt;module&gt;\\n  File \"scipy\\\\sparse\\\\csgraph\\\\__init__.pyo\", line 146, in &lt;module&gt;\\n  File \"scipy\\\\sparse\\\\csgraph\\\\_shortest_path.pyo\", line 12, in &lt;module&gt;\\n  File \"scipy\\\\sparse\\\\csgraph\\\\_shortest_path.pyo\", line 10, in __load\\n  File \"_shortest_path.pyx\", line 18, in init scipy.sparse.csgraph._shortest_path (scipy\\\\sparse\\\\csgraph\\\\_shortest_path.c:14235)\\nImportError: No module named _validation\\n</code></pre>\\n\\n<p>Compiling and running the executable worked on an old 32 bit laptop (with 32 bit versions of everything) so I think I may not be including everything I need.  My newly created test2.exe file properly creates and displays the same graph as shown at <a href=\"http://www.scipy.org/Getting_Started\" rel=\"noreferrer\">scipy\\'s Getting Started page</a>. Here is my test script:</p>\\n\\n<pre><code># test2.py\\n# code is from the scipy web site example and works in Idle\\n\\nfrom scipy import sparse\\nfrom scipy import optimize\\nfrom scipy import special\\nfrom numpy import *\\nfrom pylab import *\\n\\nx = arange(0,10,0.01)\\nfor k in arange(0.5,5.5):\\n     y = special.jv(k,x)\\n     plot(x,y)\\n     f = lambda x: -special.jv(k,x)\\n     x_max = optimize.fminbound(f,0,6)\\n     plot([x_max], [special.jv(k,x_max)],\\'ro\\')\\ntitle(\\'Different Bessel functions and their local maxima\\')\\nshow()\\n</code></pre>\\n\\n<p>And here is my setup.py file:</p>\\n\\n<pre><code># setup.py\\nfrom distutils.core import setup\\nimport py2exe\\nimport os\\nimport matplotlib\\nsetup(\\n    windows=[{\\'script\\': r\\'test2.py\\'}],\\n    data_files = matplotlib.get_py2exe_datafiles(),\\n    options = {\\n        \\'py2exe\\': {\\n            r\\'compressed\\': True,\\n            r\\'optimize\\': 2,\\n            r\\'includes\\': [\\n                r\\'matplotlib\\',\\n                r\\'matplotlib.backends.backend_tkagg\\',\\n                r\\'matplotlib.pyplot\\',\\n                #r\\'mpl_toolkits\\',\\n                r\\'pytz\\'\\n                ],\\n            r\\'dll_excludes\\': [r\\'MSVCP90.dll\\'],\\n            r\\'excludes\\': [\\n                \\'_gtkagg\\',\\n                \\'_tkagg\\',\\n                \\'_agg2\\',\\n                \\'_cairo\\',\\n                \\'_cocoaagg\\',\\n                \\'_fltkagg\\',\\n                \\'_gtk\\',\\n                \\'_gtkcairo\\',\\n                \\'tcl\\'\\n                ]\\n            }\\n        },\\n    )\\nos.system(\"pause\")  # leaves the command prompt box open so I can read it\\n</code></pre>\\n\\n<p>Both test2.py and setup.py reside in c:\\\\python27\\\\ and I get a successfully compliled test2.exe on the 64 bit machine.  On a (probably) related note, I can read that scipy v0.11.0 introduced new sparse graphing tools and I suspect this is where the error message is trying to point me to.  Am I missing something I need to explicitly include?  It would be nice if scipy had a <em>get_py2exe_datafiles()</em> function like matplotlib to help bundle things correctly.</p>\\n\\n<p>Thank you in advance for any help you can provide, and for reading this far.</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('PyQt application screen change notification', '<python><pyqt>', '<p>I checked some information. C++ has an onScreenChanged function to notify us of screen changes, but I tried it and found that PyQt does not have this onScreenChanged function. How should I know that the application has changed the screen display?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('how to concatenate dataframes as new group?', '<python><pandas>', \"<p>kind of new to pandas.</p>\\n<p>I have</p>\\n<pre><code>df1 = pd.Dataframe(\\n    [\\n    {'a': 1},\\n    {'a': 2},\\n    {'a': 3},\\n    ]\\n)\\n\\ndf2 = pd.Dataframe(\\n    [\\n    {'a': 4},\\n    {'a': 5},\\n    ]\\n)\\n</code></pre>\\n<p>I want</p>\\n<pre><code> df_id  a\\n 1      1\\n        2\\n        3\\n 2      4\\n        5\\n        \\n</code></pre>\\n<p>Assume I have a list of dfs like <code>df1</code> and <code>df2</code>. What is the correct way to get the result df?</p>\\n<p>Am I supposed to also declare some column as a key? or a primary key? Notice that I want to retain the option to slice this dataframe by <code>df_id</code> to get back the original dfs.</p>\\n<p>Also, what is this operation called? I didn't even know what to search for.</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row((\"'NoneType' error while running calendar api python3\", '<python><python-3.x><api>', \"<p>I'm working on python script which captures all my events in google calendar. this code will show the list of all the events in a day.</p>\\n<p>Below is the code.</p>\\n<pre><code>from __future__ import print_function\\nimport httplib2\\nimport os\\nimport datetime\\n\\nfrom apiclient import discovery\\nimport oauth2client\\nfrom oauth2client import client\\nfrom oauth2client import tools\\nfrom oauth2client.file import Storage\\n\\nimport datetime\\n\\ntry:\\n    import argparse\\n    flags = argparse.ArgumentParser(parents=[tools.argparser]).parse_args()\\nexcept ImportError:\\n    flags = None\\n\\n# If modifying these scopes, delete your previously saved credentials\\n# at ~/.credentials/calendar-python-quickstart.json\\nSCOPES = 'https://www.googleapis.com/auth/calendar.readonly'\\nCLIENT_SECRET_FILE = 'credentials.json'\\nAPPLICATION_NAME = 'Google Calendar API Python Quickstart'\\n\\n\\ndef get_credentials():\\n    &quot;&quot;&quot;Gets valid user credentials from storage.\\n    If nothing has been stored, or if the stored credentials are invalid,\\n    the OAuth2 flow is completed to obtain the new credentials.\\n    Returns:\\n        Credentials, the obtained credential.\\n    &quot;&quot;&quot;\\n    home_dir = os.path.expanduser('~')\\n    credential_dir = os.path.join(home_dir, '.credentials')\\n    if not os.path.exists(credential_dir):\\n        os.makedirs(credential_dir)\\n    credential_path = os.path.join(credential_dir,\\n                                   'calendar-python-quickstart.json')\\n\\n    store = oauth2client.file.Storage(credential_path)\\n    credentials = store.get()\\n    if not credentials or credentials.invalid:\\n        flow = client.flow_from_clientsecrets(CLIENT_SECRET_FILE, SCOPES)\\n        flow.user_agent = APPLICATION_NAME\\n        if flags:\\n            credentials = tools.run_flow(flow, store, flags)\\n        else: # Needed only for compatibility with Python 2.6\\n            credentials = tools.run(flow, store)\\n        print('Storing credentials to ' + credential_path)\\n    return credentials\\n\\ndef main():\\n    &quot;&quot;&quot;Shows basic usage of the Google Calendar API.\\n    Creates a Google Calendar API service object and outputs a list of the next\\n    10 events on the user's calendar.\\n    &quot;&quot;&quot;\\n    credentials = get_credentials()\\n    http = credentials.authorize(httplib2.Http())\\n    service = discovery.build('calendar', 'v3', http=http)\\n\\n    now = datetime.datetime.utcnow().isoformat() + 'Z' # 'Z' indicates UTC time\\n    print('Getting the upcoming 10 events')\\n    eventsResult = service.events().list(\\n        calendarId='primary', timeMin=now, maxResults=10, singleEvents=True,\\n        orderBy='startTime').execute()\\n    events = eventsResult.get('items', [])\\n\\n    if not events:\\n        print('No upcoming events found.')\\n    for event in events:\\n        start = event['start'].get('dateTime')\\n#        print(start)\\n        start = start[:-9]\\n\\n#        print(start)\\n        start = datetime.datetime.strptime(start,&quot;%Y-%m-%dT%H:%M&quot;)\\n\\n        pretty_time = start.strftime(&quot;%I:%M&quot;)\\n        pretty_date = start.strftime(&quot;%B %d, %Y&quot;)\\n                \\n        print(event['summary'],&quot;at&quot;,pretty_time,&quot;on&quot;,pretty_date)\\n\\n\\nif __name__ == '__main__':\\n    main()\\n    \\n</code></pre>\\n<p>below is the error which I'm getting. Not able to find the what is the mistake I made. please help.</p>\\n<p>below is the error which I'm getting. Not able to find the what is the mistake I made. please help.</p>\\n<pre><code>Traceback (most recent call last):\\n  File &quot;/Users/mbhamidipati/python-practice/change/getevents.py&quot;, line 86, in &lt;module&gt;\\n    main()\\n  File &quot;/Users/mbhamidipati/python-practice/change/getevents.py&quot;, line 75, in main\\n    start = start[:-9]\\nTypeError: 'NoneType' object is not subscriptable\\n</code></pre>\\n<p>Thanks,\\nSreman</p>\\n\"), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Building a Python shared object binding with cmake, which depends upon external libraries', '<python><c><unix><linker><cmake>', '<p>We have a c file called dbookpy.c, which will provide a Python binding some C functions.</p>\\n\\n<p>Next we decided to build a proper .so with cmake, but it seems we are doing something wrong with regards to linking the external library \\'libdbook\\' in the binding:</p>\\n\\n<p>The CMakeLists.txt is as follows:</p>\\n\\n<pre><code>PROJECT(dbookpy)\\n\\nFIND_PACKAGE(PythonInterp)\\nFIND_PACKAGE(PythonLibs)\\n\\nINCLUDE_DIRECTORIES(${PYTHON_INCLUDE_PATH})\\nINCLUDE_DIRECTORIES(\"/usr/local/include\")\\nLINK_DIRECTORIES(/usr/local/lib)\\nOPTION(BUILD_SHARED_LIBS \"turn OFF for .a libs\" ON)\\n\\nADD_LIBRARY(dbookpy dbookpy)\\nSET_TARGET_PROPERTIES(dbookpy PROPERTIES  IMPORTED_LINK_INTERFACE_LIBRARIES dbook)\\nSET_TARGET_PROPERTIES(dbookpy PROPERTIES LINKER_LANGUAGE C)\\n#SET_TARGET_PROPERTIES(dbookpy PROPERTIES LINK_INTERFACE_LIBRARIES dbook)\\n#SET_TARGET_PROPERTIES(dbookpy PROPERTIES ENABLE_EXPORTS ON)\\n#TARGET_LINK_LIBRARIES(dbookpy LINK_INTERFACE_LIBRARIES dbook)\\n\\nSET_TARGET_PROPERTIES(dbookpy\\nPROPERTIES\\n    SOVERSION 0.1\\n    VERSION 0.1\\n)\\n</code></pre>\\n\\n<p>Then we build:</p>\\n\\n<pre><code>x31% mkdir build\\nx31% cd build \\nx31% cmake ..\\n-- Check for working C compiler: /usr/bin/gcc\\n-- Check for working C compiler: /usr/bin/gcc -- works\\n-- Check size of void*\\n-- Check size of void* - done\\n-- Check for working CXX compiler: /usr/bin/c++\\n-- Check for working CXX compiler: /usr/bin/c++ -- works\\n-- Configuring done\\n-- Generating done\\n-- Build files have been written to: /home/edd/dbook2/dbookpy/build\\nx31% make\\nScanning dependencies of target dbookpy\\n[100%] Building C object CMakeFiles/dbookpy.dir/dbookpy.o\\nLinking C shared library libdbookpy.so\\n[100%] Built target dbookpy\\n</code></pre>\\n\\n<p>So far so good. Test in Python:</p>\\n\\n<pre><code>x31% python\\nPython 2.5.4 (r254:67916, Apr 24 2009, 15:28:40) \\n[GCC 3.3.5 (propolice)] on openbsd4\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n&gt;&gt;&gt; import libdbookpy\\npython:./libdbookpy.so: undefined symbol \\'dbook_isbn_13_to_10\\'\\npython:./libdbookpy.so: undefined symbol \\'dbook_isbn_10_to_13\\'\\npython:./libdbookpy.so: undefined symbol \\'dbook_sanitize\\'\\npython:./libdbookpy.so: undefined symbol \\'dbook_check_isbn\\'\\npython:./libdbookpy.so: undefined symbol \\'dbook_get_isbn_details\\'\\nTraceback (most recent call last):\\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\\nImportError: Cannot load specified object\\n</code></pre>\\n\\n<p>Hmmm. Linker error. Looks like it is not linking libdbook:</p>\\n\\n<pre><code>x31% ldd libdbookpy.so\\nlibdbookpy.so:\\n        Start    End      Type Open Ref GrpRef Name\\n    05ae8000 25aec000 dlib 1    0   0      /home/edd/dbook2/dbookpy/build/libdbookpy.so.0.1\\n</code></pre>\\n\\n<p>No it is not. A proper linkage to libdbook looks like this:</p>\\n\\n<pre><code>x31% ldd /usr/local/bin/dbook-test \\n/usr/local/bin/dbook-test:\\n    Start    End      Type Open Ref GrpRef Name\\n    1c000000 3c004000 exe  1    0   0      /usr/local/bin/dbook-test\\n    08567000 28571000 rlib 0    2   0      /usr/lib/libm.so.5.0\\n    09ef7000 29efb000 rlib 0    1   0      /usr/local/lib/libdbook.so.0.1\\n    053a0000 253d8000 rlib 0    1   0      /usr/lib/libc.so.50.1\\n    0c2bc000 0c2bc000 rtld 0    1   0      /usr/libexec/ld.so\\n</code></pre>\\n\\n<p>Does anyone have any ideas why this is not working?</p>\\n\\n<p>Many thanks.</p>\\n\\n<p>Edd</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n",
            "Row(('Doing .__class__ on various types', '<python><python-3.x>', '<p>Is integer the only type that does not support the <code>.__class__</code> operation? for example:</p>\\n\\n<pre><code>&gt;&gt;&gt; ....__class__\\n&lt;class \\'ellipsis\\'&gt;\\n\\n&gt;&gt;&gt; \\'a\\'.__class__\\n&lt;class \\'str\\'&gt;\\n\\n&gt;&gt;&gt; 2.44.__class__\\n&lt;class \\'float\\'&gt;\\n\\n&gt;&gt;&gt; 1.__class__\\nFile \"&lt;stdin&gt;\", line 1\\n</code></pre>\\n\\n<p>Is there a way to get around this?</p>\\n'), {'Title': 0, 'Tags': 1, 'Body': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "  WITH newIds AS (\n",
        "    WITH ids AS \n",
        "    (SELECT PostId FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "    WHERE TagId = 243)\n",
        "    SELECT TagId, COUNT(*) AS count FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "    JOIN ids\n",
        "      ON ids.PostId = `sotorrent-org.2020_12_31.PostTags`.PostId\n",
        "    GROUP BY TagId)\n",
        "    \n",
        "  SELECT * FROM `sotorrent-org.2020_12_31.Tags`\n",
        "  JOIN newIds\n",
        "    ON newIds.TagId = `sotorrent-org.2020_12_31.Tags`.Id\n",
        "  ORDER BY newIds.count DESC\n",
        "  LIMIT 200;\n",
        "\"\"\"\n",
        "query_job = client.query(query)\n",
        "data = []\n",
        "for row in query_job:\n",
        "  print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1FYC_e4S7zT",
        "outputId": "eab90ef6-d25d-47e1-9ee9-8a88a09f4b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row((243, 'django', 252066, 3625245, 3607538, 243, 252054), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((16, 'python', 1597896, 3624965, 3607014, 16, 127555), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((10742, 'django-models', 32797, 6357582, 6357581, 10742, 31157), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((81949, 'django-rest-framework', 21085, 11442997, 11442996, 81949, 18166), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((23506, 'django-views', 16617, 9296011, 9296010, 23506, 15804), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((15108, 'django-forms', 16423, 7051214, 7051213, 15108, 15611), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((10491, 'django-templates', 15236, 5610106, 5610105, 10491, 14180), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((60010, 'python-3.x', 262833, 4564547, 4564546, 60010, 11289), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3, 'javascript', 2130783, 3624960, 3607052, 3, 8719), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2, 'html', 1038358, 3673183, 3673182, 2, 8577), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((17376, 'django-admin', 8821, 6246254, 6246253, 17376, 8379), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((256, 'postgresql', 128515, 3625247, 3607532, 256, 5993), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((820, 'jquery', 1002527, 3625262, 3607053, 820, 5845), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((21, 'mysql', 613118, 3624969, 3607033, 21, 5088), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((19238, 'django-queryset', 5211, 9296537, 9296536, 19238, 5059), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((49, 'forms', 104457, 5602245, 5602244, 49, 5012), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((363, 'ajax', 213099, 3877045, 3877044, 363, 4789), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((59047, 'python-2.7', 94220, 8171806, 8171805, 59047, 4018), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((8279, 'heroku', 38022, 4966444, 4966443, 8279, 3491), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((30, 'database', 173868, 4973766, 4973765, 30, 3271), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1508, 'json', 306909, 4889848, 4889847, 1508, 3219), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((45273, 'celery', 7328, 4443646, 4443645, 45273, 3171), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((6605, 'nginx', 44775, 5023040, 5023039, 6605, 3142), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((80, 'apache', 88346, 4979625, 4979624, 80, 2961), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((15944, 'django-orm', 3020, 9296703, 9296702, 15944, 2919), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((11464, 'django-urls', 2935, 9299670, 9299669, 11464, 2817), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4, 'css', 694921, 3644670, 3644669, 4, 2476), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1478, 'templates', 48329, 3625006, 3608038, 1478, 2417), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((22, 'sql', 570524, 3625226, 3607304, 22, 2313), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3737, 'model', 16690, 5711627, 5711626, 3737, 2133), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((364, 'rest', 81001, 3624973, 3607594, 364, 2089), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((183, 'authentication', 48304, 5253712, 5253711, 183, 1946), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((90304, 'docker', 88422, 15699487, 15699486, 90304, 1845), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((647, 'orm', 17453, 5253532, 5253531, 647, 1809), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((66772, 'gunicorn', 3453, 8764234, 8764233, 66772, 1667), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1931, 'unit-testing', 72922, 3625025, 3608605, 1931, 1663), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((33388, 'amazon-web-services', 107128, 5063862, 5063861, 33388, 1646), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3372, 'mod-wsgi', 3115, 7539261, 7539260, 3372, 1640), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((121, 'sqlite', 85769, 3625235, 3607650, 121, 1619), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((984, 'google-app-engine', 45472, 3624984, 3609767, 984, 1585), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((365, 'url', 39752, 5147326, 5147325, 365, 1564), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((25874, 'django-authentication', 1564, 9484884, 9484883, 25874, 1507), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1125, 'serialization', 30153, 4913700, 4913699, 1125, 1450), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((72334, 'tastypie', 1634, 7149982, 7149981, 72334, 1433), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((201, 'api', 85600, 4924743, 4924742, 201, 1384), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((88725, 'django-allauth', 1400, 14844010, 14844009, 88725, 1277), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5725, 'foreign-keys', 9918, 6546494, 6546493, 5725, 1264), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((63997, 'django-class-based-views', 1321, 5759472, 5759471, 63997, 1263), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((92497, 'reactjs', 264977, 16880335, 16880334, 92497, 1257), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2438, 'many-to-many', 7621, 5536741, 5536740, 2438, 1238), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((11444, 'amazon-s3', 38220, 4994052, 4994051, 11444, 1196), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((43147, 'django-cms', 1417, 5308409, 5308408, 43147, 1160), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((78022, 'angularjs', 261769, 9580981, 9580980, 78022, 1156), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((14529, 'virtualenv', 6272, 6515154, 6515153, 14529, 1130), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((102023, 'wagtail', 1689, 22398518, 22398517, 102023, 1125), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((30073, 'mongodb', 140321, 4542745, 4542744, 30073, 1103), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((46228, 'django-haystack', 1299, 5413664, 5413663, 46228, 1086), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5307, 'admin', 4153, 7766894, 7766893, 5307, 1057), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((72257, 'web', 41541, 7175470, 7175469, 72257, 1054), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1263, 'datetime', 58176, 5600844, 5600843, 1263, 1045), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((104916, 'django-migrations', 1077, 24056031, 24056030, 104916, 1043), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((186, 'testing', 41643, 4922785, 4922784, 186, 1032), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((65645, 'django-celery', 1444, 6424504, 6424503, 65645, 1003), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((58380, 'uwsgi', 2700, 5892624, 5892623, 58380, 986), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((41749, 'django-south', 1026, 6438073, 6438072, 41749, 986), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((355, 'validation', 61295, 5114527, 5114526, 355, 977), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((904, 'post', 36993, 5599997, 5599996, 904, 966), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((72270, 'twitter-bootstrap', 99906, 7165534, 7165533, 72270, 934), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((51298, 'pycharm', 12738, 6088815, 6088814, 51298, 929), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((146, 'email', 54426, 5483666, 5483665, 146, 924), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((119561, 'django-channels', 1071, 38702897, 38702896, 119561, 917), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((32370, 'django-testing', 974, 13039822, 13039821, 32370, 917), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((20873, 'models', 2427, 15410095, 15410094, 20873, 898), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5119, 'pip', 16523, 5303916, 5303915, 5119, 888), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((70828, 'django-staticfiles', 917, 13161069, 13161068, 70828, 887), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((549, 'ubuntu', 51656, 5022379, 5022378, 549, 881), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((76838, 'django-serializer', 979, 27516297, 27516296, 76838, 870), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((39694, 'django-filter', 931, 12279597, 12279596, 39694, 869), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((18, 'regex', 235211, 3624967, 3607017, 18, 838), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((10052, 'filter', 24747, 8641255, 8641254, 10052, 796), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1763, 'caching', 34723, 5015959, 5015958, 1763, 792), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((688, 'session', 42739, 5088687, 5088686, 688, 782), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5868, 'view', 19835, 7470066, 7470065, 5868, 771), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((190, 'deployment', 21800, 5047602, 5047601, 190, 756), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((24650, 'geodjango', 916, 6158867, 6158866, 24650, 735), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3818, 'wsgi', 2282, 5219868, 5219867, 3818, 726), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((12193, 'internationalization', 10484, 5108232, 5108231, 12193, 718), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((43464, 'redis', 19737, 4742844, 4742843, 43464, 715), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((942, 'logging', 35463, 3812354, 3812352, 942, 697), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4985, 'image', 102953, 5048269, 5048268, 4985, 694), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((10741, 'django-signals', 713, 5904957, 5904956, 10741, 689), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((48085, 'django-settings', 712, 6502200, 6502199, 48085, 687), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((110604, 'docker-compose', 18329, 29064482, 29064481, 110604, 675), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((50077, 'django-users', 703, 10068013, 10068012, 50077, 670), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5210, 'http', 60074, 4924551, 4924550, 5210, 663), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1190, 'redirect', 37072, 6030030, 6030029, 1190, 657), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4209, 'file-upload', 25736, 6228196, 6228195, 4209, 652), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((48047, 'django-registration', 674, 8003186, 8003185, 48047, 646), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((20674, 'jinja2', 7022, 4925701, 4925700, 20674, 644), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((9137, 'csrf', 4003, 5739952, 5739951, 9137, 639), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((97, 'migration', 9235, 7982742, 7982741, 97, 636), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((119, 'git', 128645, 3625234, 3607047, 119, 634), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2218, 'facebook', 84951, 4166421, 4166420, 2218, 633), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((105747, 'amazon-elastic-beanstalk', 7507, 24799042, 24799041, 105747, 631), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((58, 'linux', 198453, 3625112, 3607012, 58, 629), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((73, 'csv', 74167, 4913959, 4913958, 73, 617), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((81770, 'django-crispy-forms', 668, 16421604, 16421603, 81770, 609), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1834, 'dictionary', 59320, 6168485, 6168484, 1834, 609), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((16728, 'modelform', 607, 47204067, 47204066, 16728, 593), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1378, 'pagination', 15434, 6867110, 6867109, 1378, 589), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((12375, 'amazon-ec2', 29976, 5123215, 5123214, 12375, 575), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((40768, 'websocket', 22248, 4174660, 4174659, 40768, 559), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((64388, 'elasticsearch', 47730, 5970741, 5970740, 64388, 559), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((9921, 'request', 14556, 9744259, 9744258, 9921, 542), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((279, 'unicode', 22988, 3625249, 3607542, 279, 540), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((69826, 'django-tables2', 572, 11630497, 11630496, 69826, 523), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((23926, 'formset', 526, 14363336, 14363335, 23926, 513), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1292, 'static', 14992, 6517620, 6517619, 1292, 508), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((359, 'permissions', 15369, 5488863, 5488862, 359, 505), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((292, 'cookies', 31165, 4926401, 4926400, 292, 503), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((35428, 'django-database', 524, 16382508, 16382507, 35428, 498), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((46890, 'django-csrf', 525, 8594240, 8594239, 46890, 494), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((32509, 'django-generic-views', 513, 11397081, 11397080, 32509, 490), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((125866, 'angular', 239190, 43399164, 43399163, 125866, 485), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((64, 'windows', 146089, 3625230, 3609881, 64, 483), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4635, 'views', 4542, 6585295, 6585294, 4635, 473), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1386, 'android', 1311786, 3625001, 3607484, 1386, 469), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((104257, 'vue.js', 69288, 23714172, 23714171, 104257, 458), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4446, 'web-applications', 20958, 5204498, 5204497, 4446, 454), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((598, 'performance', 91135, 5048293, 5048292, 598, 453), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((52620, 'mongoengine', 1684, 7104018, 7104017, 52620, 446), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1104, 'selenium', 81284, 3624992, 3609793, 1104, 446), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((117554, 'bootstrap-4', 23515, 35169617, 35169616, 117554, 446), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3854, 'login', 18434, 6489157, 6489156, 3854, 443), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((926, 'inheritance', 37804, 4913888, 4913887, 926, 442), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((98224, 'python-social-auth', 516, 23365038, 23365037, 98224, 442), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((369, 'macos', 104037, 4979532, 4979531, 369, 439), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((75442, 'python-requests', 15081, 8834498, 8834497, 75442, 431), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5608, 'list', 109989, 5329259, 5329258, 5608, 430), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((47801, 'python-imaging-library', 6684, 13310630, 13310629, 47801, 429), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1695, 'database-design', 22535, 4133665, 4133664, 1695, 421), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((85166, 'mezzanine', 460, 13925544, 13925543, 85166, 420), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((110613, 'django-rest-auth', 519, 29073898, 29073897, 110613, 418), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((816, 'search', 34122, 5609248, 5609247, 816, 415), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5876, 'apache2', 7374, 5953421, 5953420, 5876, 411), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((136, 'security', 51612, 3625053, 3612218, 136, 408), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5, 'php', 1381623, 3624936, 3607050, 5, 402), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((18782, 'manytomanyfield', 420, 16420655, 16420654, 18782, 398), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5310, 'file', 72470, 5253619, 5253618, 5310, 395), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((67719, 'pandas', 180409, 6469623, 6469622, 67719, 395), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((10492, 'django-middleware', 401, 9820052, 9820051, 10492, 389), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((27969, 'rabbitmq', 11569, 5240700, 5240699, 27969, 388), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((641, 'ssl', 44665, 5124516, 5124515, 641, 386), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((107680, 'server', 20941, 26467455, 26467454, 107680, 376), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((72, 'sql-server', 296333, 3625231, 3607030, 72, 373), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1381, 'multithreading', 126773, 4933608, 4933607, 1381, 371), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((90, 'pdf', 44573, 4541006, 4541005, 90, 370), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((38622, 'django-sessions', 383, 11208274, 11208273, 38622, 367), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((23927, 'inline-formset', 371, 12842860, 12842859, 23927, 362), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5002, 'date', 65307, 5004540, 5004539, 5002, 361), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((982, 'timezone', 10554, 5828026, 5828025, 982, 361), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5769, 'oauth', 18441, 4942566, 4942565, 5769, 351), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((58679, 'oauth-2.0', 18642, 7562024, 7562023, 58679, 351), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((81031, 'pythonanywhere', 939, 10956474, 10956473, 81031, 348), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((19086, 'django-apps', 365, 9118315, 9118314, 19086, 348), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((99825, 'django-1.7', 395, 21073927, 21073926, 99825, 347), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((432, 'import', 22136, 7933864, 7933863, 432, 346), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((50128, 'django-socialauth', 382, 9664274, 9664273, 50128, 346), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2361, 'translation', 4350, 8655355, 8655354, 2361, 343), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((277, 'debugging', 46246, 4985314, 4985313, 277, 343), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((94726, 'django-oscar', 379, 18108368, 18108367, 94726, 341), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((129048, 'django-2.0', 429, 46670901, 46670900, 129048, 333), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((65223, 'jwt', 11225, 10822691, 10822690, 65223, 331), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((14158, 'azure', 97044, 4923902, 4923901, 14158, 330), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5471, 'psycopg2', 3224, 5136304, 5136303, 5471, 330), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((48664, 'pytest', 5690, 4738423, 4738422, 48664, 328), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((107276, 'django-1.8', 399, 26103715, 26103714, 107276, 323), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1249, 'memcached', 5077, 5097223, 5097222, 1249, 318), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((43594, 'django-permissions', 330, 16424817, 16424816, 43594, 315), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((46426, 'node.js', 362050, 4238969, 4238968, 46426, 313), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3322, 'postgis', 3745, 6208722, 6208721, 3322, 311), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((91446, 'django-tests', 329, 16336212, 16336211, 91446, 310), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((110749, 'graphql', 13046, 29194759, 29194758, 110749, 307), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3556, 'field', 5431, 9356883, 9356882, 3556, 303), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2481, 'signals', 6402, 6231344, 6231343, 2481, 301), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3550, 'transactions', 14519, 5952739, 5952738, 3550, 299), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((601, 'cron', 15568, 5144066, 5144065, 601, 297), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((5664, 'backend', 4771, 14406380, 14406379, 5664, 296), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((1866, 'solr', 19507, 3625332, 3608751, 1866, 291), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((64142, 'django-template-filters', 298, 16421456, 16421455, 64142, 290), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((23646, 'django-mptt', 307, 9445737, 9445736, 23646, 287), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((658, 'upload', 13356, 8077660, 8077659, 658, 282), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((4984, 'ruby-on-rails', 322364, 3625098, 3607365, 4984, 282), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((29718, 'django-validation', 288, 16449821, 16449820, 29718, 281), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((3995, 'get', 15183, 6164825, 6164824, 3995, 278), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((89020, 'django-i18n', 294, 15836258, 15836257, 89020, 277), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((9964, 'database-migration', 3478, 16449710, 16449709, 9964, 276), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((97102, 'digital-ocean', 2985, 19472165, 19472164, 97102, 271), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((2780, 'localization', 12547, 5241141, 5241140, 2780, 271), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n",
            "Row((65115, 'supervisord', 1429, 10696180, 10696179, 65115, 270), {'Id': 0, 'TagName': 1, 'Count': 2, 'ExcerptPostId': 3, 'WikiPostId': 4, 'TagId': 5, 'count_1': 6})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "      WITH ids AS \n",
        "      (SELECT PostId FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "      WHERE TagId = 16)\n",
        "\n",
        "      SELECT * FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "      JOIN ids\n",
        "        ON ids.PostId = `sotorrent-org.2020_12_31.PostTags`.PostId\n",
        "      LIMIT 200;\n",
        "\"\"\"\n",
        "\n",
        "# query = \"\"\"\n",
        "#     SELECT COUNT(PostId) FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "#     WHERE TagId = 16\n",
        "# \"\"\"\n",
        "\n",
        "query_job = client.query(query)  # Make an API request.\n",
        "# print(query_job)\n",
        "\n",
        "# exit()\n",
        "print(\"The query data:\")\n",
        "for row in query_job:\n",
        "  print(row)\n",
        "  # query = f\"\"\"\n",
        "  #   WITH tags as SELECT TagId FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "  #   WHERE PostId = {row[0]}\n",
        "  #   LIMIT 20;\n",
        "\n",
        "  #   SELECT * FROM `sotorrent-org.2020_12_31.PostTags`\n",
        "  #   JOIN tags\n",
        "  # \"\"\"\n",
        "  # tags = client.query(query)\n",
        "  # print([tag[0] for tag in tags])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeWwbrq3MLui",
        "outputId": "2b5ad6ec-3c59-4810-c0e2-8bdcab3cd3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The query data:\n",
            "Row((16308989, 60010, 16308989), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((42988664, 81490, 42988664), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((55708654, 45137, 55708654), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((56855526, 46457, 56855526), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57658703, 1834, 57658703), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((4462952, 57694, 4462952), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59152894, 109163, 59152894), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((48131804, 67719, 48131804), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60173633, 3496, 60173633), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((34715541, 109163, 34715541), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49209163, 130245, 49209163), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49344251, 8488, 49344251), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((36761902, 46457, 36761902), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((24893848, 15475, 24893848), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51097419, 60010, 51097419), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51486818, 1078, 51486818), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63806409, 5569, 63806409), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((38878504, 1011, 38878504), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52396804, 197, 52396804), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((28226579, 5608, 28226579), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((40637859, 1381, 40637859), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54360311, 122986, 54360311), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54469439, 67719, 54469439), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((1894598, 27, 1894598), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((31073110, 45273, 31073110), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((2264333, 2218, 2264333), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((44097541, 243, 44097541), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((44127250, 243, 44127250), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((44726379, 97726, 44726379), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((18675812, 139, 18675812), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57042638, 390, 57042638), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((46219411, 58, 46219411), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((46378640, 126378, 46378640), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((33819130, 11609, 33819130), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((22306890, 16927, 22306890), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((48316055, 98837, 48316055), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((36318547, 47561, 36318547), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50750156, 96537, 50750156), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((37504769, 5036, 37504769), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((10902899, 243, 10902899), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63380889, 680, 63380889), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63423557, 367, 63423557), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63808939, 11099, 63808939), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((27233788, 103787, 27233788), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((12890652, 1931, 12890652), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((15058379, 81464, 15058379), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54396355, 129048, 54396355), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((55028442, 10315, 55028442), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((56217882, 2936, 56217882), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((3617170, 23400, 3617170), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57022375, 67719, 57022375), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((5234996, 1213, 5234996), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((46081753, 46457, 46081753), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58567529, 139, 58567529), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58722198, 60010, 58722198), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((46806827, 67719, 46806827), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((47694335, 14766, 47694335), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((34884396, 7979, 34884396), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((23489321, 4282, 23489321), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((23511917, 243, 23511917), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((35861099, 109163, 35861099), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((36185757, 60010, 36185757), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50107182, 67719, 50107182), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50279530, 363, 50279530), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((9163940, 44096, 9163940), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((61985619, 46457, 61985619), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62537575, 382, 62537575), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50934089, 46457, 50934089), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51309526, 67719, 51309526), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63100590, 60010, 63100590), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63405801, 15108, 63405801), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((53898579, 5608, 53898579), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64550730, 6159, 64550730), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((40014309, 90848, 40014309), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((14068923, 7003, 14068923), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((846869, 1357, 846869), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((17493219, 5678, 17493219), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57509968, 4912, 57509968), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58871322, 137, 58871322), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((5838025, 345, 5838025), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((47246234, 859, 47246234), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49074258, 9986, 49074258), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60765305, 60010, 60765305), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((61287630, 13925, 61287630), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((61579957, 46457, 61579957), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((61590614, 73, 61590614), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49982676, 125158, 49982676), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((25258332, 67719, 25258332), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((37042043, 8328, 37042043), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((37079830, 1190, 37079830), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((10852255, 241, 10852255), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((25718075, 67719, 25718075), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63501749, 19230, 63501749), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63623308, 6716, 63623308), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63664033, 84917, 63664033), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((39644167, 67719, 39644167), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((28132165, 59047, 28132165), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64689652, 60010, 64689652), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((65129065, 67719, 65129065), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((14115318, 243, 14115318), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((41355683, 60010, 41355683), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((1972877, 1399, 1972877), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((43730107, 11066, 43730107), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((56336327, 123841, 56336327), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((56601407, 33015, 56601407), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((44621359, 1034, 44621359), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((45720425, 67719, 45720425), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((47638267, 60010, 47638267), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((47644176, 73, 47644176), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((22585088, 18, 22585088), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59508419, 82275, 59508419), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59958649, 98224, 59958649), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60025272, 133634, 60025272), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60479135, 243, 60479135), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((34953377, 21797, 34953377), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49178916, 21314, 49178916), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((23739030, 20873, 23739030), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((24489285, 4190, 24489285), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62366097, 5323, 62366097), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51725436, 98880, 51725436), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((53807699, 4075, 53807699), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64308970, 2193, 64308970), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64724476, 67719, 64724476), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64796108, 543, 64796108), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54954601, 121, 54954601), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((43596088, 42162, 43596088), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((43765058, 1381, 43765058), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((30199605, 2529, 30199605), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57064104, 111122, 57064104), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((45796540, 58, 45796540), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((46613031, 259, 46613031), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58495202, 41898, 58495202), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59017085, 60010, 59017085), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((22724986, 5608, 22724986), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49067869, 5600, 49067869), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60588613, 7979, 60588613), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50491303, 46457, 50491303), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((24958557, 49865, 24958557), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62230243, 4190, 62230243), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62251711, 54712, 62251711), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62572369, 73, 62572369), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62616957, 2531, 62616957), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((50915800, 97726, 50915800), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51037737, 81490, 51037737), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((51236252, 82275, 51236252), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52052834, 32371, 52052834), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52114655, 102377, 52114655), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62984477, 92746, 62984477), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63267599, 99304, 63267599), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63403069, 116342, 63403069), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((53201293, 51298, 53201293), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63911398, 48664, 63911398), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64302912, 116693, 64302912), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64946643, 90, 64946643), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((41138426, 64, 41138426), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((14557431, 13898, 14557431), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((41761266, 4075, 41761266), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((42299268, 110850, 42299268), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54877116, 54712, 54877116), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((55054063, 25479, 55054063), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((17499287, 201, 17499287), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((55456911, 102759, 55456911), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((31169430, 8512, 31169430), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((31388499, 432, 31388499), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((44916748, 243, 44916748), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((56745606, 6941, 56745606), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((57709713, 15108, 57709713), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((45954981, 25450, 45954981), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((20157278, 1834, 20157278), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((20271048, 27971, 20271048), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58218261, 78872, 58218261), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((58599272, 113291, 58599272), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((32888553, 121, 32888553), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((6104921, 432, 6104921), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((22482591, 17376, 22482591), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59567905, 134, 59567905), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((59889921, 67719, 59889921), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((60184862, 67719, 60184862), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((8024091, 365, 8024091), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49037989, 60010, 49037989), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((49456831, 126437, 49456831), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((61236796, 522, 61236796), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((25439312, 86280, 25439312), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((62391648, 5002, 62391648), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63189035, 572, 63189035), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((63593201, 67719, 63593201), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52471145, 4190, 52471145), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52712201, 724, 52712201), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((52871603, 131307, 52871603), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((53266636, 67719, 53266636), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((53439133, 67719, 53439133), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((64892459, 15475, 64892459), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((11810826, 39850, 11810826), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((39689667, 59047, 39689667), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((13971489, 1158, 13971489), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((14977038, 90, 14977038), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54688176, 90304, 54688176), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((54928113, 243, 54928113), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((55148453, 13898, 55148453), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n",
            "Row((43703732, 1124, 43703732), {'PostId': 0, 'TagId': 1, 'PostId_1': 2})\n"
          ]
        }
      ]
    }
  ]
}